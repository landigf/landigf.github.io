const EXERCISES = [
  {
    "name": "The Sultan Trail",
    "aka": "MAX # of overlapping intervals",
    "week": "Week 01",
    "methods": "Sweep Line",
    "status": "Completed",
    "problemModel": "We have a vector of intervals [start,end] and want to find the max number of overlapping intervals (in a point).",
    "solutionShort": "We add +1 at each start and remove -1 at each end, we take the maximum.\n\nPay attention to counting the starting before closing.",
    "solution": "#include <iostream>\n#include <vector>\n#include <algorithm>\nusing namespace std;\n\nvoid solve(){\nint n; cin >> n;\nvector<pair<int,int>> sl;\nfor(int i = 0; i < n; ++i){\nint start, end; cin >> start>>end;\nsl.push_back({start, 1});\nsl.push_back({end, -1});\n}\nsort(sl.begin(), sl.end(), [](const pair<int,int>& a, const pair<int,int>& b) {\nif (a.first == b.first) return a.second > b.second; // +1 before -1\nreturn a.first < b.first;\n});\nint maks = 0;\nint count = 0;\nfor(auto &e: sl){\ncount += e.second;\nmaks = max(maks, count);\n}\ncout << maks;\n}\n\nint main(){\nios_base::sync_with_stdio(false);\nint t; cin >> t;\nwhile(t--){\nsolve(); cout << \"\\n\";\n}\n}",
    "link": "https://expert.ethz.ch/solve/cZJ5MF75rZ5N6RngJ"
  },
  {
    "name": "Even Matrix",
    "aka": "Counting even-sum submatrices via prefix-parity aggregation",
    "week": "Week 01",
    "methods": "Combinatorics, Prefix sum",
    "status": "Learn&ShutUp",
    "problemModel": "Given an n x n binary matrix, count how many submatrices (i1..i2, j1..j2) have an even sum of elements. Do this for up to t ≤ 15 test cases, with n ≤ 200.",
    "solutionShort": "\n1. Build 2D prefix sum matrix m so any rectangle sum can be computed in O(1):\nsum(y1..y2, x1..x2) = m[y2][x2] - m[y1-1][x2] - m[y2][x1-1] + m[y1-1][x1-1].\n2. Fix a pair of rows (y1, y2), and consider the 1D array over columns:\nprefix[x] = sum(y1..y2, 1..x) (your sum(y1,y2,1,x2,m)).\n3. Any submatrix spanning rows y1..y2 and columns l..r has sum:\nprefix[r] - prefix[l-1].\n\nThis is even iff prefix[r] and prefix[l-1] have the same parity.\n4. So for each row-pair, count how many prefix parities are even/odd:\n    ◦ You count parity for x=1..n into nEven, nOdd.\n    ◦ There is also the “empty prefix” at x=0 which is even, so total even-prefixes is nEven + 1.\n    ◦ Number of even-sum subarrays = C(nEven+1, 2) + C(nOdd, 2)\n\nwhich expands to exactly what you add:\nC(nEven,2) + nEven + C(nOdd,2).\n5. Sum that over all O(n^2) row pairs.\n",
    "solution": "#include <iostream>\n#include <vector>\n#include <algorithm>\nusing namespace std;\n\nint sum(int y1, int y2, int x1, int x2, const vector<vector<int>>& m){\nreturn m[y2][x2] - m[y1-1][x2] - m[y2][x1-1] + m[y1-1][x1-1];\n}\n\nvoid solve(){\nint n; cin >> n;\nvector<vector<int>> m(n+1,vector<int> (n+1,0));\nfor(int i = 1; i <= n; ++i){\nfor(int j = 1; j <= n; ++j){\nint num; cin >> num;\nm[i][j] = m[i-1][j] + m[i][j-1] - m[i-1][j-1] + num;\n}\n}\nlong long res = 0;\nfor(int y1 = 1; y1 <= n; ++y1){\nfor(int y2 = y1; y2 <= n; ++y2){\nlong long nEven = 0, nOdd = 0;\nfor(int x2 = 1; x2 <= n; ++x2){\nif(sum(y1,y2,1,x2, m)%2) ++nOdd;\nelse ++nEven;\n}\nres += (nEven*(nEven-1))/2 + nEven + nOdd*(nOdd-1)/2;\n}\n}\ncout << res;\n}\n\nint main(){\nios_base::sync_with_stdio(false);\nint t; cin >> t;\nwhile(t--){\nsolve(); cout << \"\\n\";\n}\n}",
    "link": "https://expert.ethz.ch/solve/fWbSHmehcgKXovbpK"
  },
  {
    "name": "Even Pairs",
    "aka": "# of subarrays with even sum",
    "week": "Week 01",
    "methods": "Combinatorics, Prefix sum",
    "status": "Completed",
    "problemModel": "We have a vector of integers, we want to count the number of subarrays with even sum.\n\nSo xi+…+xj = Even Integer.",
    "solutionShort": "Brute force: computer the sum of each subarray → O(n^2)\n\nPrefix sum: precompute the cumulative sum → S_i = x0+..+xi;\nNotice that:\n- Sj - S_i-1 = xi+..+xj\nWhen it’s even ?\n1. both Sj, S_i-1 are even\n2. both are odd\n\nso count all the combination of pairs of indexes were Si,Sj are both even or odd.\n\nOnce we find all indexes pairs, and odd, then we what to know the unique pairs → binomial coefficient: (N 2) = n*(n-1)/2.\n\nsum the pairs of even and odd, starting with #even = 1 because it’s the empty interval → needed to count as subarray also single even number.",
    "solution": "#include <iostream>\n#include <vector>\n#include <algorithm>\nusing namespace std;\n\nvoid solve(){\nint n; cin >> n;\nvector<int> v(n);\nfor(int i = 0; i < n; ++i){\ncin >> v[i];\nif(i != 0) v[i] += v[i-1];\n}\nint nEven = 1, nOdd = 0;\nfor(int i = 0; i < n; ++i){\nif(v[i]%2) ++nOdd;\nelse ++nEven;\n}\ncout << nEven*(nEven-1)/2 + nOdd*(nOdd-1)/2;\n}\n\nint main(){\nios_base::sync_with_stdio(false);\nint t; cin >> t;\nwhile(t--){\nsolve(); cout << \"\\n\";\n}\n}",
    "link": "https://expert.ethz.ch/solve/icuMesQwsrB762q6Q"
  },
  {
    "name": "Dominoes",
    "aka": "Dominoes",
    "week": "Week 01",
    "methods": "Greedy",
    "status": "Completed",
    "problemModel": "We have a vector of positive integers representing the height of dominoes, AT EACH INDEX WE HAVA A PIECE, then we need to see how far dominoes will continue falling starting from left.",
    "solutionShort": "think of each dominoes as a gas station. We start with fuel equal to the height of the first, then for each step we decrement the fuel. At each index if the fuel is ≤ 0 then we need to stop. Otherwise, we get the fuel as the max(current, gasStation).",
    "solution": "#include <iostream>\n#include <vector>\n#include <algorithm>\nusing namespace std;\n\nvoid solve(){\nint n; cin >> n;\nvector<int> v(n);\nfor(int i = 0; i < n; ++i){\ncin >> v[i];\n}\nint hrem = v[0];\nfor(int i = 1; i < n; ++i){\n--hrem;\nif(hrem <= 0) {\ncout << i;\nreturn;\n} else {\nhrem = max(v[i],hrem);\n}\n}\ncout << n;\n}\n\nint main(){\nios_base::sync_with_stdio(false);\nint t; cin >> t;\nwhile(t--){\nsolve(); cout << \"\\n\";\n}\n}",
    "link": "https://expert.ethz.ch/solve/BHCoFa7QqgnvfWJQN"
  },
  {
    "name": "Search Snippets",
    "aka": "Shortest interval covering one occurrence from each of k sorted lists (minimum search snippet)",
    "week": "Week 02",
    "methods": "Greedy, min-heap",
    "status": "Completed",
    "problemModel": "Given a query of n distinct words, you receive for each word a sorted list of positions where it occurs in a document. All positions are distinct across all lists. You must output the minimum snippet length (b − a + 1) of a contiguous interval [a, b] that contains at least one occurrence of every word. \n",
    "solutionShort": "Maintain one “current” chosen position per word and keep the current window spanning them.\n1. Initialize by taking the first position from each word’s list (treat each list as a queue/iterator).\n2. Put these n current positions into a min-heap keyed by position; also track current_max across the n chosen positions.\n3. The current snippet is minpos,currentmaxmin_pos, current_maxminpos,currentmax; update the best length.\n4. To potentially shrink/improve, advance the word that currently has the minimum position: pop heap min (pos, word_id), fetch the next position from that word’s list, push it, and update current_max if needed.\n5. Stop when the popped word has no next position (you can’t keep all n words represented anymore).\n\nThis is the standard “smallest range covering k lists” greedy: only moving the current minimum can reduce the window. ",
    "solution": "#include <iostream>\n#include <vector>\n#include <algorithm>\n#include <queue>\nusing namespace std;\n\nvoid solve(){\nint n; cin >> n;\nvector<int> wcount(n);\nfor(int i = 0; i < n; ++i){\ncin >> wcount[i];\n}\nvector<queue<int>> wpos(n);\nfor(int i = 0; i < n; ++i){\nfor(int j = 0; j < wcount[i]; ++j){\nint pi; cin >> pi;\nwpos[i].push(pi);\n}\n}\npriority_queue<pair<int,int>> pq;\nint curr_max = 0;\nfor(int i = 0; i < n; ++i){\nint curr_pos = wpos[i].front(); wpos[i].pop();\npq.push({-curr_pos, i});\ncurr_max = max(curr_max, curr_pos);\n}\n\nint curr_min = -pq.top().first;\nint res = curr_max - curr_min + 1;\nwhile((int)pq.size() == n){\nint curr_word = pq.top().second; pq.pop();\nif(wpos[curr_word].empty()) break;\nint curr_pos = wpos[curr_word].front(); wpos[curr_word].pop();\npq.push({-curr_pos, curr_word});\ncurr_max = max(curr_max, curr_pos);\nint curr_min = -pq.top().first;\nres = min(res, curr_max - curr_min + 1);\n}\n\ncout << res;\n}\n\nint main(){\nios_base::sync_with_stdio(false);\nint t; cin >> t;\nwhile(t--){\nsolve(); cout << \"\\n\";\n}\nif(cin >> t) cout << \"eoror\\n\";\n}",
    "link": "https://expert.ethz.ch/solve/Rrd9wMDGxHn5mvBkr"
  },
  {
    "name": "Severus Snape",
    "aka": "min number of potions",
    "week": "Week 02",
    "methods": "0/1 Knapsack, Dynamic Programming, Greedy, Prefix sum",
    "status": "Completed",
    "problemModel": "You need to pick a minimum-size subset of potions to reach at least: Power P, Happiness H, Wit W. Start from 0,0,0.\n• Type A potion i gives +pi power and +hi happiness, but decreases wit by exactly a.\n• Type B potion j gives +wj wit, but decreases power by exactly b, happiness unchanged.\n\nNegative power/wit during the process is allowed; only final thresholds matter. Output the minimum number of potions, or -1.",
    "solutionShort": "Key observation: once you fix how many A potions you take (say count_A), the wit requirement becomes a fixed target for B, and the power requirement becomes a fixed “remaining power” after paying B’s penalty.\n1. Preprocess type B (greedy works):\n• Sort wj descending.\n• Build prefix sums prefB[t] = sum of top t wj.\n\nThen for any required wit target W_needed, the minimum number of B potions is the smallest t with prefB[t] ≥ W_needed (found by lower_bound).\n1. Iterate count_A from 0..n. For each count_A:\n• Wit after A decreases by count_A * a, so B must cover:\n\nW_needed = W + count_A * a.\n• Use prefix sums + binary search to get count_B needed (or skip if impossible).\n1. For this count_A, compute the maximum power you can get from choosing exactly count_A A-potions while reaching happiness ≥ H:\n• DP state: “with exactly count_A picks and happiness threshold, what’s the max power?”\n\nBecause happiness is small (≤1024), you can DP over happiness, but power is big, so you maximize power.\n1. Check feasibility:\n• Power available after B penalty is max_power_A − count_B * b.\n\nIf that is ≥ P, update answer with count_A + count_B.\nReturn the minimum over all count_A, else -1. ",
    "solution": "#include <iostream>\n#include <vector>\n#include <algorithm>\n#include <unordered_map>\nusing namespace std;\n\nvoid solve(){\nint n, m; cin >> n >> m;\nlong long a, b; cin >> a >> b;\nlong long P, W; int H;\ncin >> P >> H >> W;\nvector<pair<long long,int>> typeA(n);\nfor(int i = 0; i < n; ++i){\ncin >> typeA[i].first;\ncin >> typeA[i].second;\n}\nvector<long long> typeB(m);\nfor(int i = 0; i < m; ++i){\ncin >> typeB[i];\n}\nsort(typeB.begin(), typeB.end(), greater<>());\nfor(int i = 1; i < m; ++i){\ntypeB[i] += typeB[i-1];\n}\nvector<vector<long long>> dp(n+1, vector<long long> (H+1, -1));\ndp[0][0] = 0;\nfor(int z = 1; z <= n; ++z){\nlong long p = typeA[z-1].first;\nint h = typeA[z-1].second;\nfor(int i = z; i >= 1; --i){\nfor(int j = H; j >= 0; --j){\ndp[i][j] = max(dp[i][j], dp[i-1][j]);\nif(dp[i-1][j] == -1) continue;\nint targetJ = min(H, j+h);\ndp[i][targetJ] = max(dp[i][targetJ], dp[i-1][j]+p);\n}\n}\n}\nlong long res = -1;\nfor(int i = 1; i <= n; ++i){\nif(dp[i][H] == -1) continue;\nlong long Prem = P - dp[i][H];\n\nlong long Wneeded = W + ai;\n// if to slow use a multiset instead of vector\nauto it = lower_bound(typeB.begin(), typeB.end(), Wneeded);\nif(it == typeB.end()) continue;\nint drinked = (int)distance(typeB.begin(),it)+1;\n\nPrem += bdrinked;\nif(Prem <= 0){\nres = i + drinked;\nbreak;\n}\n}\n\ncout << res;\n}\n\nint main(){\nios_base::sync_with_stdio(false);\nint t; cin >> t;\nwhile(t--){\nsolve(); cout << \"\\n\";\n}\n}",
    "link": "https://expert.ethz.ch/solve/eyZXcn6TZZHWNGZSe"
  },
  {
    "name": "San Francisco",
    "aka": "Longest-path-in-exact-steps with free resets from sinks (k-step max-score DP)",
    "week": "Week 02",
    "methods": "Dynamic Programming",
    "status": "Completed",
    "problemModel": "You have a directed graph with n nodes and m directed edges; traversing an edge (u→v) earns p points (p ≥ 0). You start at node 0. A node with outdegree 0 is a “sink”; from a sink you may teleport back to node 0 for free (no move, no score). You have at most k moves. Output the minimum number of moves needed to reach score ≥ x, or Impossible if you can’t reach x within k moves.",
    "solutionShort": "Solution description (iterative / bottom-up DP):\n\nDefine dp[i][v] = maximum score achievable after exactly i moves, ending at node v.\n• Init: dp[0][0] = 0, others = -∞.\n• For i = 0..k−1 and each node u with dp[i][u] valid: for each edge (u→v,p), update:\n    ◦ If v is terminal, next state is node 0: dp[i+1][0] = max(dp[i+1][0], dp[i][u] + p)\n    ◦ Else: dp[i+1][v] = max(dp[i+1][v], dp[i][u] + p)\n• Answer: smallest i with dp[i][0] (or max over nodes, depending on formulation) ≥ x; else Impossible. \nthis (1)\nSolution description (recursive / top-down with memoization, matching your code):\n\nDefine help(movesLeft, node) = maximum additional score achievable starting from “node” with exactly movesLeft moves remaining.\n• Base: if movesLeft == 0 return 0.\n• Memo: memo[movesLeft][node] caches results to avoid recomputation.\n• Transition: try all outgoing edges (node→v, p) and take the best:\n    ◦ If v is terminal: candidate = p + help(movesLeft−1, 0)\n    ◦ Else: candidate = p + help(movesLeft−1, v)\n    ◦ currBest = max over candidates\n• Then compute help(i,0) for i=1..k and return the first i where help(i,0) ≥ x, else Impossible.",
    "solution": "#include <iostream>\n#include <vector>\n#include <algorithm>\n#include <unordered_map>\nusing namespace std;\n\nvoid solve(){\nint n, m; cin >>n>>m;\nlong long x; cin >> x;\nint k; cin >> k;\nvector<unordered_map<int,int>> graph(n);\nfor(int i = 0; i < m; ++i){\nint u, v, p; cin >> u >> v >> p;\nif(graph[u].find(v) != graph[u].end()){\ngraph[u][v] = max(graph[u][v], p);\n} else graph[u][v] = p;\n}\nvector<vector<long long>> dp(k+1, vector<long long> (n, -1));\ndp[0][0] = 0;\nfor(int i = 1; i <= k; ++i){\nfor(int j = 0; j < n; ++j){\nif(dp[i-1][j] == -1) continue;\nfor(auto &e: graph[j]){\nint v = e.first;\nint p = e.second;\ndp[i][v] = max(dp[i][v], dp[i-1][j]+p);\nif(dp[i][v] >= x){\ncout << i;\nreturn;\n}\nif(graph[v].size() == 0){\ndp[i][0] = max(dp[i][0], dp[i][v]);\n}\n}\n}\n}\ncout << \"Impossible\";\n}\n\nint main(){\nios_base::sync_with_stdio(false);\nint t; cin >> t;\nwhile(t--){\nsolve(); cout << \"\\n\";\n}\n}",
    "link": "https://expert.ethz.ch/solve/NqPzfHTTW7wuruuiJ"
  },
  {
    "name": "Greyjoy",
    "aka": "find max length of consecutive nodes with sum = k → in a tree with one node with w branches (root) and all the other node at most one children.",
    "week": "Week 02",
    "methods": "Prefix sum, Two Sum",
    "status": "Completed",
    "problemModel": "We have one root only branches.\nGOAL: max length of consecutive nodes with sum of value of nods equal to K.\n",
    "solutionShort": "first solve for each branche with Two Sum or sliding window, than do Two Sum from different branches, PAY ATTENTION TO CHANGE THE TARGET OF TWO SUM AND REMOVE THE ROOT TO AVOID DOUBLE COUNTING",
    "solution": "#include <iostream>\n#include <vector>\n#include <algorithm>\n#include <unordered_map>\nusing namespace std;\n\nvoid solve(){\nint n, k, w; cin >> n >> k >> w;\nvector<int> c(n);\nfor(int i = 0; i < n; ++i){\ncin >> c[i];\n}\nvector<vector<int>> islands(w);\nfor(int i = 0; i < w; ++i){\nint l; cin >> l;\nfor(int j = 0; j < l; ++j){\nint x; cin >> x;\nislands[i].push_back(x);\n}\n}\nvector<vector<long long>> costs(w);\nfor(int i = 0; i < w; ++i){\nint l = (int)islands[i].size();\ncosts[i].push_back(c[islands[i][0]]);\nfor(int j = 1; j < l; ++j){\ncosts[i].push_back(costs[i][j-1]+c[islands[i][j]]);\n}\n}\nint res = 0;\n// solve for each waterway\nfor(int i = 0; i < w; ++i){\nunordered_map<long long, int> map;\nmap[0] = -1;\nfor(int j = 0; j < (int)islands[i].size(); ++j){\nlong long goal = costs[i][j] - k;\nif(map.find(goal) != map.end()){\nres = max(res, j-map[goal]);\n}\nmap[costs[i][j]] = j;\n}\n}\n// look combinations\nunordered_map<long long, int> map;\nfor(int i = 0; i < w; ++i){\nfor(int j = 0; j < (int)islands[i].size(); ++j){\nlong long goal = k - costs[i][j] + costs[i][0];\nif(map.find(goal) != map.end()){\nres = max(res, j+map[goal]+1);\n}\n}\nfor(int j = 0; j < (int)islands[i].size(); ++j){\nif(map.find(costs[i][j]) != map.end()){\nmap[costs[i][j]] = max(j,map[costs[i][j]]);\n} else map[costs[i][j]] = j;\n}\n}\ncout << res;\n}\n\nint main(){\nios_base::sync_with_stdio(false);\nint t; cin >> t;\nwhile(t--){\nsolve(); cout << \"\\n\";\n}\n}",
    "link": "https://expert.ethz.ch/solve/rsADmS6rf3h3o3ZXC"
  },
  {
    "name": "Burning Coins",
    "aka": "2-player, 2 possible move",
    "week": "Week 02",
    "methods": "2-player, Dynamic Programming",
    "status": "Completed",
    "problemModel": "Given a query of n distinct words, you receive for each word a sorted list of positions where it occurs in a document. All positions are distinct across all lists. You must output the minimum snippet length (b − a + 1) of a contiguous interval [a, b] that contains at least one occurrence of every word.",
    "solutionShort": "For each round i consider base case: just one element, just 2 element, then I need to consider all possible combinations of what could happen\n\n2^n possibilities → TOO MUCH\n\nso memoization :)",
    "solution": "#include <iostream>\n#include <vector>\n#include <algorithm>\nusing namespace std;\ntypedef vector<vector<int>> vvi;\nint me(int i, int j, const vector<int>& coins, vvi& memo);\nint opp(int i, int j, const vector<int>& coins, vvi& memo);\n\nint me(int i, int j, const vector<int>& coins, vvi& memo){\nif(j < i) return 0;\nif(i == j) return coins[i];\nif(i+1 == j) return max(coins[i],coins[j]);\nif(memo[i][j] != -1) return memo[i][j];\nmemo[i][j] =  max(coins[i]+opp(i+1,j,coins,memo),coins[j]+opp(i,j-1,coins,memo));\nreturn memo[i][j];\n}\n\nint opp(int i, int j, const vector<int>& coins, vvi& memo){\nif(j < i) return 0;\nif(i == j) return 0;\nif(i+1 == j) return min(coins[i],coins[j]);\nreturn min(me(i+1,j,coins,memo),me(i,j-1,coins,memo));\n}\n\nvoid solve(){\nint n; cin >> n;\nvector<int> coins(n);\nfor(int i = 0; i < n; ++i){\ncin >> coins[i];\n}\nvvi memo(n, vector<int> (n,-1));\ncout << me(0, n-1, coins, memo);\n}\n\nint main(){\nios_base::sync_with_stdio(false);\nint t; cin >> t;\nwhile(t--){\nsolve(); cout << \"\\n\";\n}\n}",
    "link": "https://expert.ethz.ch/solve/ppZM8mSxuQ3W2WWzZ"
  },
  {
    "name": "First steps with BGL",
    "aka": "Dijkstra + MST",
    "week": "Week 03",
    "methods": "Dijkstra, Minimum Spanning Tree",
    "status": "Completed",
    "problemModel": "Implement Dijkstra and MST",
    "solutionShort": "Implement Dijkstra and MST",
    "solution": "// STL includes\n#include <iostream>\n#include <vector>\nusing namespace std;\n\n// BGL includes\n#include <boost/graph/adjacency_list.hpp>\n#include <boost/graph/kruskal_min_spanning_tree.hpp>\n#include <boost/graph/dijkstra_shortest_paths.hpp>\n\ntypedef boost::adjacency_list<boost::vecS, boost::vecS, boost::undirectedS,\nboost::no_property, boost::property<boost::edge_weight_t, int> >      weighted_graph;\ntypedef boost::property_map<weighted_graph, boost::edge_weight_t>::type weight_map;\ntypedef boost::graph_traits<weighted_graph>::edge_descriptor            edge_desc;\ntypedef boost::graph_traits<weighted_graph>::vertex_descriptor          vertex_desc;\n\n\n\nint dijkstra_dist(const weighted_graph &G, int s, int t) {\nint n = boost::num_vertices(G);\nstd::vector<int> dist_map(n);\n\nboost::dijkstra_shortest_paths(G, s,\nboost::distance_map(boost::make_iterator_property_map(\ndist_map.begin(), boost::get(boost::vertex_index, G))));\nint maks = 0;\nfor(int i = 0; i < n; ++i){\nif(dist_map[i] > maks) maks = dist_map[i];\n}\nreturn maks;\n}\n\nvoid solve(){\nint n, m; cin >> n >> m;\nweighted_graph G(n);\nweight_map weights = boost::get(boost::edge_weight, G);\nedge_desc e;\nfor(int i = 0; i < m; ++i){\nint u, v, c; cin >> u >> v >> c;\ne = boost::add_edge(u, v, G).first; weights[e]=c;\n}\n\nstd::vector<edge_desc> mst;    // vector to store MST edges (not a property map!)\n\nboost::kruskal_minimum_spanning_tree(G, std::back_inserter(mst));\nint res = 0;\nfor (std::vector<edge_desc>::iterator it = mst.begin(); it != mst.end(); ++it) {\nres += weights[*it];\n}\n\ncout << res << \" \" << dijkstra_dist(G, 0, 1);\n}\n\nint main(){\nios_base::sync_with_stdio(false);\nint t; cin >> t;\nwhile(t--){\nsolve(); cout << \"\\n\";\n}\n}",
    "link": "https://expert.ethz.ch/solve/3abMHQP4DFYRnis2H"
  },
  {
    "name": "Important Bridges",
    "aka": "Bridge-finding via biconnected components (critical edges are components of size 1)",
    "week": "Week 03",
    "methods": "Biconnected Graph",
    "status": "Completed",
    "problemModel": "You are given an undirected graph of islands (n nodes) connected by bridges (m edges), with no multi-edges. The graph is connected (you can reach any island from any other). A bridge is critical if removing it disconnects the graph (some pair of islands becomes unreachable). For each test case, output all critical bridges, sorted lexicographically (u < v on each edge, and edges sorted by u then v). ",
    "solutionShort": "Critical bridges are exactly the edges that are not part of any cycle. In a biconnected-components (BCC) edge decomposition, this corresponds to BCCs that contain exactly one edge.\nSteps:\n1. Build the undirected graph.\n2. Run biconnected_components(g, component) which assigns each edge an integer component id (BCC id).\n3. Group edges by their component id; for each component, count how many edges it contains.\n4. Every component with size == 1 corresponds to a bridge; collect that single edge.\n5. Normalize each edge as (min(u,v), max(u,v)), sort lexicographically, print.\nNote: You compute articulation points too, but they aren’t needed for the output; bridges are already identified by “BCC size 1”.",
    "solution": "#include <boost/config.hpp>\n#include <vector>\n#include <list>\n#include <boost/graph/biconnected_components.hpp>\n#include <boost/graph/adjacency_list.hpp>\n#include <iterator>\n#include <iostream>\n#include <algorithm>\nnamespace boost\n{\nstruct edge_component_t\n{\nenum\n{\nnum = 555\n};\ntypedef edge_property_tag kind;\n} edge_component;\n}\n\nvoid solve(){\n\nusing namespace boost;\ntypedef adjacency_list< vecS, vecS, undirectedS, no_property,\nproperty< edge_component_t, std::size_t > >\ngraph_t;\ntypedef graph_traits< graph_t >::vertex_descriptor vertex_t;\nint n, m; std::cin >> n >> m;\ngraph_t g(n);\nfor(int i = 0; i < m; ++i){\nint u,v; std::cin >> u >> v;\nadd_edge(u, v, g);\n}\n\nproperty_map< graph_t, edge_component_t >::type component\n= get(edge_component, g);\n\nstd::size_t num_comps = biconnected_components(g, component);\n//std::cerr << \"Found \" << num_comps << \" biconnected components.\\n\";\nstd::vector<std::vector<std::pair<int,int>>> edges_in_comp((int)num_comps);\n\nstd::vector< vertex_t > art_points;\narticulation_points(g, std::back_inserter(art_points));\n//std::cerr << \"Found \" << art_points.size() << \" articulation points.\\n\";\n\ngraph_traits< graph_t >::edge_iterator ei, ei_end;\nfor (boost::tie(ei, ei_end) = edges(g); ei != ei_end; ++ei){\nint a1 = source(*ei, g);\nint b1 = target(*ei, g);\nif(b1 < a1) swap(a1,b1);\nedges_in_comp[component[*ei]].push_back({a1,b1});\n}\nstd::vector<std::pair<int,int>> res;\nfor(int i = 0; i < (int)num_comps; ++i){\nif(edges_in_comp[i].size() == 1) res.push_back(edges_in_comp[i][0]);\n}\nstd::sort(res.begin(), res.end());\nif((int)res.size() == 0){\nstd::cout << 0<<\"\\n\"; return;\n}\nstd::cout << (int)res.size()<<\"\\n\";\nfor(int i = 0; i < (int)res.size(); ++i){\nstd::cout << res[i].first << \" \" << res[i].second<<\"\\n\";\n}\n}\n\nint main(){\nstd::ios_base::sync_with_stdio(false);\nint t; std::cin >> t;\nwhile(t--){\nsolve();\n}\n}",
    "link": "https://expert.ethz.ch/solve/4WGoT8H9DYhB4uk6v"
  },
  {
    "name": "Ant Challenge",
    "aka": "Multi-species shortest path on union of Prim-MST networks (MST per species + Dijkstra)",
    "week": "Week 03",
    "methods": "Dijkstra, Minimum Spanning Tree",
    "status": "Completed",
    "problemModel": "Forest is an undirected connected graph with n trees and e edges. Each edge has a travel time per species (s species). Each species can only traverse edges in its private network, which was built by exploring from its hive by repeatedly adding the next tree that is fastest to reach from the already explored set (unique choice guaranteed). You must transport a breadcrumb from start node a to finish node b using edges that are in at least one private network; along each used edge you may choose the species that traverses that edge fastest among those whose private network contains it. Output the minimum total travel time. \n",
    "solutionShort": "\n1. Build each species’ private network as an MST.\n\nThe exploration rule is exactly Prim’s algorithm behavior (growing a tree by repeatedly taking the cheapest edge that connects the explored set to a new vertex; uniqueness ensures determinism). So for each species i, run Prim (or Kruskal) using that species’ edge weights, producing an MST Ti with n−1 edges. \nthis (4)\n2. Merge the MSTs into a single usable graph.\n\nFor every original edge (u,v), if it appears in at least one MST, include it in a merged graph G’. Set its weight to:\n• w’(u,v) = min over species i where (u,v) ∈ Ti of w_i(u,v).\n\nEdges that are in no private network are excluded.\n1. Shortest path on the merged graph.\n\nRun Dijkstra from a to compute dist[b] in G’. That distance is the optimal total time, because any valid route must use only edges covered by at least one network, and per edge you are always best off picking the minimum available species time.",
    "solution": "// STL includes\n#include <iostream>\n#include <vector>\n#include <algorithm>\nusing namespace std;\n// BGL includes\n#include <boost/graph/adjacency_list.hpp>\n#include <boost/graph/kruskal_min_spanning_tree.hpp>\n#include <boost/graph/dijkstra_shortest_paths.hpp>\n\ntypedef boost::adjacency_list<boost::vecS, boost::vecS, boost::undirectedS,\nboost::no_property, boost::property<boost::edge_weight_t, int> >      weighted_graph;\ntypedef boost::property_map<weighted_graph, boost::edge_weight_t>::type weight_map;\ntypedef boost::graph_traits<weighted_graph>::edge_descriptor            edge_desc;\ntypedef boost::graph_traits<weighted_graph>::vertex_descriptor          vertex_desc;\n\nvoid kruskal(const weighted_graph &G) {\nstd::vector<edge_desc> mst;    // vector to store MST edges (not a property map!)\n\nboost::kruskal_minimum_spanning_tree(G, std::back_inserter(mst));\n\nfor (std::vector<edge_desc>::iterator it = mst.begin(); it != mst.end(); ++it) {\nstd::cout << boost::source(*it, G) << \" \" << boost::target(*it, G) << \"\\n\";\n}\n}\n\nint dijkstra_dist(const weighted_graph &G, int s, int t) {\nint n = boost::num_vertices(G);\nstd::vector<int> dist_map(n);\n\nboost::dijkstra_shortest_paths(G, s,\nboost::distance_map(boost::make_iterator_property_map(\ndist_map.begin(), boost::get(boost::vertex_index, G))));\n\nreturn dist_map[t];\n}\n\nvoid solve(){\nint n,e,s,a,b; cin>>n>>e>>s>>a>>b;\nvector<weighted_graph> networks(s, weighted_graph(n));\nvector<weight_map> wmaps(s);\nfor(int i = 0; i < s; ++i){\nwmaps[i] = boost::get(boost::edge_weight, networks[i]);\n}\nfor(int i = 0; i < e; ++i){\nint t1,t2; cin >> t1 >> t2;\nfor(int j = 0; j < s; ++j){\nint wi; cin >> wi;\nedge_desc ed;\ned = boost::add_edge(t1, t2, networks[j]).first; wmaps[j][ed]=wi;\n}\n}\nfor(int i = 0; i < s; ++i){\nint hi; cin >> hi;\n}\nvector<vector<int>> best_w(n, vector<int> (n,-1));\nfor(int i = 0; i < s; ++i){\nstd::vector<edge_desc> mst;    // vector to store MST edges (not a property map!)\nboost::kruskal_minimum_spanning_tree(networks[i], std::back_inserter(mst));\n\nfor (std::vector<edge_desc>::iterator it = mst.begin(); it != mst.end(); ++it) {\nint t1 = boost::source(*it, networks[i]);\nint t2 = boost::target(*it, networks[i]);\nif(best_w[t1][t2] == -1) best_w[t1][t2] = wmaps[i][*it];\nelse best_w[t1][t2] = min(best_w[t1][t2], wmaps[i][*it]);\nbest_w[t2][t1] = best_w[t1][t2];\n}\n}\nweighted_graph G(n);\nweight_map weights = boost::get(boost::edge_weight, G);\nfor(int t1 = 0; t1 < n; ++t1){\nfor(int t2 = t1+1; t2 < n; ++t2){\nif(best_w[t1][t2] == -1) continue;\nedge_desc e;\ne = boost::add_edge(t1, t2, G).first; weights[e]=best_w[t1][t2];\n}\n}\nstd::cout << dijkstra_dist(G, a, b);\n}\n\nint main(){\nios_base::sync_with_stdio(false);\nint t; cin >> t;\nwhile(t--){\nsolve(); cout << \"\\n\";\n}\nif(cin >> t) cout << \"\\n\";\n}",
    "link": "https://expert.ethz.ch/solve/k2FMzXKo7QYwr2mNG"
  },
  {
    "name": "Buddy Selection",
    "aka": "Threshold graph perfect matching (build edges by “similarity > f” and test if perfect matching exists)",
    "week": "Week 03",
    "methods": "Maximum matching",
    "status": "Completed",
    "problemModel": "You have n (even) students, each described by exactly c distinct keywords. Dr. Fuzzman’s pairing guarantees that the minimum number of shared keywords among all buddy pairs is f. Decide whether there exists a pairing of all students into n/2 disjoint pairs such that every pair shares strictly more than f keywords. Output not optimal if such a pairing exists, else optimal.",
    "solutionShort": "\n1. Compute common-keyword counts for every pair (i,j).\n\nBuild an inverted index: map each keyword to the list of students containing it.\n\nFor each keyword’s list L, for every pair (u,v) in L, increment common[u][v].\n\nThis avoids comparing all c keywords for all n^2 pairs directly and is fast enough at n=400.\n2. Build a graph of “allowed buddy pairs”.\n\nCreate an undirected graph G with one vertex per student.\n\nAdd edge (i,j) iff common[i][j] > f.\n\nNow the question becomes: does G contain a perfect matching?\n3. Run maximum matching in a general graph.\n\nUse Edmonds’ Blossom algorithm to compute maximum cardinality matching in G.\n• If matching_size == n/2 ⇒ we can pair everyone with >f common keywords ⇒ output not optimal.\n• Else output optimal.",
    "solution": "// STL includes\n#include <iostream>\n#include <vector>\n#include <algorithm>\n#include <unordered_map>\n#include <string>\nusing namespace std;\n// BGL includes\n#include <boost/graph/adjacency_list.hpp>\n#include <boost/graph/max_cardinality_matching.hpp>\n\ntypedef boost::adjacency_list<boost::vecS, boost::vecS, boost::undirectedS> graph;\ntypedef boost::graph_traits<graph>::vertex_descriptor                       vertex_desc;\n\nint maximum_matching(const graph &G) {\nint n = boost::num_vertices(G);\nstd::vector<vertex_desc> mate_map(n);  // exterior property map\n\nboost::edmonds_maximum_cardinality_matching(G,\nboost::make_iterator_property_map(mate_map.begin(), boost::get(boost::vertex_index, G)));\nint res = boost::matching_size(G,\nboost::make_iterator_property_map(mate_map.begin(), boost::get(boost::vertex_index, G)));\nreturn res;\n\n}\n\nvoid solve(){\nint n, c, f; cin >> n >> c >> f;\nunordered_map<string, vector<int>> um;\nvector<vector<string>> interests(n, vector<string> (c));\nfor(int i = 0; i < n; ++i){\nfor(int j = 0; j < c; ++j){\nstring car; cin >> car;\num[car].push_back(i);\ninterests[i][j] = car;\n}\n}\nvector<vector<int>> common(n, vector<int> (n));\nfor(int i = 0; i < n; ++i){\nfor(string str: interests[i]){\nfor(int j: um[str]){\n++common[i][j];\n}\n}\n}\n\ngraph G(n);\nfor(int i = 0; i < n; ++i){\nfor(int j = i+1; j < n; ++j){\nif(common[i][j] > f) boost::add_edge(i, j, G);\n}\n}\nif(maximum_matching(G)*2 == n) cout << \"not optimal\";\nelse cout << \"optimal\";\n}\n\nint main(){\nios_base::sync_with_stdio(false);\nint t; cin >> t;\nwhile(t--){\nsolve(); cout << \"\\n\";\n}\n}",
    "link": "https://expert.ethz.ch/solve/7mrSJzRR6oZT6H8Ri"
  },
  {
    "name": "Lord Voldemort",
    "aka": "Maximum total length of exactly m disjoint k-sum subarrays (weighted interval scheduling with fixed count)",
    "week": "Week 03",
    "methods": "Dynamic Programming, Prefix sum, Sliding Window",
    "status": "Rewrite it",
    "problemModel": "You have an array v[0..n−1] of positive integers (evil per Horcrux). There are exactly m wizards, each must destroy a non-empty contiguous segment whose sum is exactly k. Segments must be pairwise disjoint. Goal: maximize the total number of Horcruxes destroyed (sum of segment lengths). Output that maximum, or fail if it’s impossible to assign m disjoint k-sum segments.",
    "solutionShort": "\n1. Enumerate all candidate segments with sum exactly k\n\nBecause all vi are positive, use a sliding window: expand right pointer, shrink left pointer when sum > k, record an interval (l,r) whenever sum == k.\n\nImportant: with strictly positive values, each l participates in at most one k-sum interval, so the number of recorded intervals L is O(n).\n2. Convert to weighted intervals\n\nFor each found interval i:\n• start[i], end[i]\n• weight[i] = end[i] − start[i] + 1 (how many Horcruxes destroyed)\n1. Sort intervals by end (increasing)\n\nCompute prev[i]: the index of the last interval that ends strictly before start[i] (i.e., end[prev[i]] < start[i]).\n\nYou can compute prev via binary search over the sorted end[] array.\n2. DP: pick exactly m disjoint intervals maximizing total weight\n\nLet dp[j][i] = maximum total destroyed length using exactly j intervals among the first i intervals in sorted order (1-based i).\n\nTransition (classic weighted scheduling with count constraint):\n• Skip interval i: dp[j][i] = dp[j][i−1]\n• Take interval i: dp[j][i] = max(dp[j][i], weight[i] + dp[j−1][prev[i]])\n\nAnswer is dp[m][L]. If dp[m][L] is “impossible” (e.g., −inf), output fail.",
    "solution": "#include <iostream>\n#include <vector>\n#include <algorithm>\n#include <unordered_map>\n\nusing namespace std;\n\n// Structure to hold segment information\nstruct Segment {\nint start, end, length;\n\n// Custom comparator to sort segments by their end point\nbool operator<(const Segment& other) const {\nreturn end < other.end;\n}\n};\n\nvoid solve() {\nint n, m;\nlong long k;\ncin >> n >> m >> k;\n\nvector<int> v(n);\nfor (int i = 0; i < n; i++) {\ncin >> v[i];\n}\n\n// --- FIX 1: Find all segments in O(N) using a hash map ---\nvector<Segment> segments;\nunordered_map<long long, vector<int>> prefix_sum_map;\nprefix_sum_map[0].push_back(-1); // Base case for segments starting at index 0\n\nlong long current_sum = 0;\nfor (int i = 0; i < n; i++) {\ncurrent_sum += v[i];\nlong long target = current_sum - k;\n\nif (prefix_sum_map.count(target)) {\n// For every time we've seen the target sum, a valid segment exists\nfor (int start_index : prefix_sum_map[target]) {\nsegments.push_back({start_index + 1, i, i - (start_index + 1) + 1});\n}\n}\nprefix_sum_map[current_sum].push_back(i);\n}\n\nif (segments.empty()) {\ncout << \"fail\" << endl;\nreturn;\n}\n\n// Sort segments by their end point to enable binary search\nsort(segments.begin(), segments.end());\n\nint s = segments.size();\n\n// dp[i][j] = maximum horcruxes using exactly j wizards from first i segments (sorted by end point)\nvector<vector<int>> dp(s + 1, vector<int>(m + 1, -1));\nfor(int i=0; i<=s; ++i) {\ndp[i][0] = 0; // Base case: 0 wizards = 0 horcruxes\n}\n\nfor (int i = 1; i <= s; i++) {\nSegment& cur = segments[i-1];\n\n// --- FIX 2: Find last non-overlapping segment in O(log i) using binary search ---\nint last_non_overlapping_idx = -1;\n\n// We need a segment that ends before the current one starts.\n// We search for the first segment that ends at or after cur.start.\nauto it = lower_bound(segments.begin(), segments.begin() + i - 1, cur.start,\n[](const Segment& seg, int val) {\nreturn seg.end < val;\n});\n\n// The index we want is the one right before the iterator 'it'.\nif (it != segments.begin()) {\nlast_non_overlapping_idx = distance(segments.begin(), it - 1);\n}\n\nfor (int j = 1; j <= m; j++) {\n// Option 1: Don't take the current segment i.\nint option1 = dp[i-1][j];\n\n// Option 2: Take the current segment i.\nint option2 = -1;\n// The result is the length of the current segment plus the best result\n// from j-1 wizards using segments that don't overlap with the current one.\nint prev_dp_idx = (last_non_overlapping_idx == -1) ? 0 : last_non_overlapping_idx + 1;\n\nif (dp[prev_dp_idx][j-1] != -1) {\noption2 = dp[prev_dp_idx][j-1] + cur.length;\n}\n\ndp[i][j] = max(option1, option2);\n}\n}\n\nif (dp[s][m] <= 0) { // Check for <=0 since -1 is used for impossible\ncout << \"fail\" << endl;\n} else {\ncout << dp[s][m] << endl;\n}\n}\n\nint main() {\nios_base::sync_with_stdio(false);\ncin.tie(NULL);\nint t;\ncin >> t;\nwhile (t--) {\nsolve();\n}\nreturn 0;\n}",
    "link": "https://expert.ethz.ch/ide2/67fF4wzx4jHAsyArS"
  },
  {
    "name": "Fighting Pits of Meereen",
    "aka": "Two-track scheduling with bounded imbalance and short memory (DP over histories + score)",
    "week": "Week 04",
    "methods": "Dynamic Programming, Encoding",
    "status": "Learn&ShutUp",
    "problemModel": "You have a queue of n fighters (each has a type in 0..k−1). Each round you must send the next fighter either to the north or south entrance. Round excitement is:\n• \n    ◦ 1000 × (number of distinct types among the last min(m,q) fighters sent through that chosen entrance, including the current one)\n• − 2^|p−q| where p and q are the total fighters sent through north and south up to now\n\nEvery round’s excitement must be non-negative, otherwise the schedule is invalid. Maximize the total excitement over all rounds. ",
    "solutionShort": "Use DP over the queue index, the imbalance, and the last m fighters sent through each entrance.\n1. Bound the imbalance:\n\nThe penalty term is 2^|p−q|, while the positive part is at most 1000·m ≤ 3000.\n\nSo once |p−q| is large enough (e.g., ≥ 12), the penalty dominates and the round score becomes negative no matter what, meaning such states are useless. Cap diff = p−q to a small range like [-12, 12].\n2. Encode “memory” per entrance:\n\nYou must know the last m types for north and for south to compute “distinct types”.\n\nBecause k ≤ 4 and m ≤ 3, store history as an integer in base (k+1) using 0 as “empty” and 1..k for types.\n\nThis gives at most (k+1)^m ≤ 5^3 = 125 states per entrance.\n3. DP state and transition:\n\nLet dp[i][hn][hs][d] = maximum total excitement after processing first i fighters, where hn/hs are encoded histories for north/south and d is the capped imbalance.\n\nTransition by sending fighter i to north or to south:\n• Decode/update the chosen entrance history by shifting in the new type\n• Update imbalance d±1\n• Compute round excitement from (distinct in updated history) and penalty 2^|new_d|\n• Only allow transition if round excitement ≥ 0\n\nTake the max over choices.\nAnswer is the maximum dp[n][][][*].",
    "solution": "#include <bits/stdc++.h>\ntypedef std::vector<int> VI;\ntypedef std::vector<VI> VVI;\ntypedef std::vector<VVI> VVVI;\ntypedef std::vector<VVVI> VVVVI;\n\nstruct fq{int f1, f2, f3;};\nint n, k, m;\n\nint distinct(fq f, int m){\nif (m == 2) return std::unordered_set<int>({0, f.f1, f.f2}).size() - 1;\nelse return std::unordered_set<int>({0, f.f1, f.f2, f.f3}).size() - 1;\n}\n\nint solve(int curr, VVVVI& dp, VI& fighters, fq& north, fq& south, int diff){\nif (curr == n) return 0;\nif (diff > 12) return INT_MIN;\nint encn = north.f15 + north.f2;\nint encs = south.f15 + south.f2;\nint diffp = diff + 12;\nint value = dp[curr][encn][encs][diffp];\nif (value != -1) return value;\nint nextf = fighters[curr];\nfq nnorth = {nextf, north.f1, north.f2};\nfq ssouth = {nextf, south.f1, south.f2};\nint best = 0;\nint north_exc = 1000distinct(nnorth, m) - pow(2, std::abs(diff + 1));\nint south_exc = 1000distinct(ssouth, m) - pow(2, std::abs(diff - 1));\nif (north_exc > 0) best = north_exc + solve(curr + 1, dp, fighters, nnorth, south, diff + 1);\nif (south_exc > 0) best = std::max(best, south_exc + solve(curr + 1, dp, fighters, north, ssouth, diff - 1));\ndp[curr][encn][encs][diffp] = best;\nreturn best;\n}\n\nvoid solve(){\nstd::cin >> n >> k >> m;\nVI fighters(n);\nfor (int i = 0; i < n; i++){\nint x; std::cin >> x;\nfighters[i] = x + 1;\n}\nfq north = {0, 0, 0};\nfq south = {0, 0, 0};\nVVVVI dp(n, VVVI(25, VVI(25, VI(25, -1))));\nstd::cout << solve(0, dp, fighters, north, south, 0) << '\\n';\n}\n\nint main(){\nstd::ios_base::sync_with_stdio(false);\nint t; std::cin>>t;\nwhile(t--) solve();\n}",
    "link": "https://expert.ethz.ch/solve/9RHRajXhHaoSxqd8p"
  },
  {
    "name": "Hiking Maps",
    "aka": "Minimum-length contiguous subsequence covering all path legs (triangle containment + sliding window)",
    "week": "Week 04",
    "methods": "Computational Geometry, Sliding Window",
    "status": "Rewrite it",
    "problemModel": "You have a hiking path with m points p0..p(m−1), forming m−1 legs (segments pi–p(i+1)). You also have n triangular map parts t0..t(n−1). You are only allowed to buy a contiguous block of map parts tb..t(e−1) at cost (e−b). The block is valid if every leg of the hike is fully contained in at least one triangle in the block. Output the minimum possible cost. Instances are guaranteed solvable by taking all parts.",
    "solutionShort": "\n1. For each triangle, precompute which legs it covers.\n\nA triangle is given by 3 edges, but each edge is described by two points lying on that edge. You first normalize each edge direction so that “not right_turn(edge_start, edge_end, point)” means “point is inside or on boundary”.\n\nThen for each path point pk, test if it is inside the triangle by checking it is not to the “right” of any of the 3 directed edges.\n\nBecause a triangle is convex, a leg pj–p(j+1) is fully inside iff both endpoints are inside. Store all such leg indices j in tr_covers_leg[i].\n2. Find the minimum contiguous block of triangles covering all legs (two pointers).\n\nMaintain a window [l, r] over triangles. Keep an array covered[leg] counting how many triangles in the current window cover that leg, and a counter count = number of legs with covered[leg] > 0.\n• Extend r to the right, adding triangle r’s covered legs.\n• While count == m−1 (all legs covered), shrink from the left to minimize window length and update best = min(best, r−l+1).\n\nThis yields the minimal cost because cost equals number of triangles bought.",
    "solution": "#include <CGAL/Exact_predicates_inexact_constructions_kernel.h>\ntypedef CGAL::Exact_predicates_inexact_constructions_kernel K;\n#include <iostream>\n#include <vector>\n#include <algorithm>\n#include <set>\nusing namespace std;\n\nstruct triangle {\nvector<K::Point_2> points;\n};\n\nvoid solve() {\nint n, m; cin >> m >> n;\nvector<K::Point_2> legs_points(m);\nfor(int i = 0; i < m; ++i){\nK::FT x, y;\ncin >> x >> y;\nlegs_points[i] = K::Point_2(x,y);\n}\nvector<triangle> triangles(n);\nvector<vector<int>> tr_covers_leg(n);\nfor(int i = 0; i < n; ++i){\ntriangles[i].points.resize(7);\nfor(int j = 0; j < 6; ++j){\nint x, y; cin >> x >> y;\ntriangles[i].points[j] = K::Point_2(x,y);\n}\ntriangles[i].points[6] = triangles[i].points[0];\nfor(int z = 0; z <=4; z+=2){\nif(CGAL::right_turn(triangles[i].points[z],\ntriangles[i].points[z+1],\ntriangles[i].points[z+2]))\nswap(triangles[i].points[z],triangles[i].points[z+1]);\n}\nvector<bool> point_is_inside(m, true);\nfor (int k = 0; k < m; ++k) {\n// Un punto è dentro se sta dallo stesso lato (o sul bordo)\n// rispetto a tutti e 3 i lati del triangolo\nfor(int z = 0; z <=4; z+=2){\nif(CGAL::right_turn(triangles[i].points[z],\ntriangles[i].points[z+1],\nlegs_points[k]))\npoint_is_inside[k] = false;\n}\n}\nfor (int j = 0; j < m - 1; ++j) {\nif (point_is_inside[j] && point_is_inside[j+1]) {\ntr_covers_leg[i].push_back(j);\n}\n}\n}\nint best = n+1;\nvector<int> covered(m-1, 0);\nint l = 0, r = 0;\nint count = 0;\nwhile(r < n){\nfor(int leg: tr_covers_leg[r]) {\nif(covered[leg] == 0) ++count;\n++covered[leg];\n}\nwhile(count == m-1 && l < n){\nbest = min(best, r-l+1);\nfor(int leg: tr_covers_leg[l]) {\n--covered[leg];\nif(covered[leg] == 0) --count;\n}\n++l;\n}\n++r;\n}\ncout << best;\n}\n\nint main(){\nios_base::sync_with_stdio(false);\nint t; cin >> t;\nwhile(t--){\nsolve(); cout << \"\\n\";\n}\nif(cin >> t) cout << \"erorroo\\n\";\n}",
    "link": "https://expert.ethz.ch/solve/3Pa2nyMpSAHA39qsR"
  },
  {
    "name": "Hit",
    "aka": "Ray–segment intersection detection (early-exit CGAL geometry)",
    "week": "Week 04",
    "methods": "Computational Geometry",
    "status": "Completed",
    "problemModel": "Given a ray starting at (x,y) and passing through (a,b), and n obstacle segments (each with endpoints (r,s) and (t,u)), determine whether the ray intersects at least one segment (endpoints count as part of the segment). For each test case, output yes if any intersection exists, otherwise no. Multiple test cases until a line 0. Coordinates are large (|coord| < 2^51), so 32-bit ints are unsafe.",
    "solutionShort": "Represent the laser path as a CGAL Ray_2.For each segment: build a Segment_2 and call CGAL::do_intersect(ray, seg).If any call returns true, print yes. Otherwise after all segments, print no.Micro-optimization used: once hit == true, the code still consumes input lines but skips CGAL construction/intersection tests.",
    "solution": "#include <iostream>\n#include <vector>\n#include <CGAL/intersections.h>\n#include <CGAL/Exact_predicates_inexact_constructions_kernel.h>\n\ntypedef CGAL::Exact_predicates_inexact_constructions_kernel K;\ntypedef K::Point_2 Point;\ntypedef K::Ray_2 Ray;\ntypedef K::Segment_2 Segment;\n\nvoid solve(int n){\nK::FT x, y, a, b;\nstd::cin >> x >> y >> a >> b;\nRay ray(Point(x,y), Point(a,b));\nbool hit = false;\nfor(int i = 0; i < n; ++i){\nif(hit){\nlong long h,j,k,l;\nstd::cin >> h >> j >> k >> l;\n} else {\nK::FT r, s, t, u;\nstd::cin >> r >> s >> t >> u;\nSegment seg(Point(r,s), Point(t,u));\nif(!hit && CGAL::do_intersect(ray, seg)){\nhit = true;\n}\n}\n}\nif(hit) std::cout << \"yes\";\nelse std::cout << \"no\";\n}\n\nint main(){\nstd::ios_base::sync_with_stdio(false);\nint n;\nwhile(true){\nstd::cin >> n;\nif(n == 0) break;\nsolve(n);\nstd::cout << \"\\n\";\n}\n}",
    "link": "https://expert.ethz.ch/solve/MHNvZQgvkchbaAnmC"
  },
  {
    "name": "Antenna",
    "aka": "Minimum enclosing circle (smallest radius covering all points)",
    "week": "Week 04",
    "methods": "Minimum enclosing circle",
    "status": "Rewrite it",
    "problemModel": "Given n citizen home coordinates (xi, yi), choose a transmitter location anywhere in the plane and a transmission radius R so that all points are within distance R from the transmitter. Output the smallest integer radius that guarantees coverage (i.e., ceil of the optimal real-valued radius). Multiple test cases end with 0.",
    "solutionShort": "\n• The optimal transmitter radius is the radius of the minimum enclosing circle of the point set. The circle is defined by 2 or 3 boundary points.\n• Use CGAL Min_circle_2 to compute the minimum enclosing circle from all points (internally randomized incremental).\n• Extract the circle’s squared radius, take the exact square root (exact kernel with sqrt), then output the smallest integer ≥ radius using a safe ceil_to_double routine (fixes double conversion edge cases).\n",
    "solution": "#include <CGAL/Exact_predicates_exact_constructions_kernel_with_sqrt.h>\n#include <CGAL/Min_circle_2.h>\n#include <CGAL/Min_circle_2_traits_2.h>\n#include <vector>\n#include <bits/stdc++.h>\n// typedefs\ntypedef  CGAL::Exact_predicates_exact_constructions_kernel_with_sqrt K;\ntypedef  CGAL::Min_circle_2_traits_2<K>  Traits;\ntypedef  CGAL::Min_circle_2<Traits>      Min_circle;\n\n\ndouble ceil_to_double(const K::FT& x) {\ndouble a = std::ceil(CGAL::to_double(x));\nwhile(a < x) a += 1;\nwhile(a-1 >= x) a -= 1;\nreturn a;\n}\n\nvoid solve(int n){\nstd::vector<K::Point_2> P;\nfor (int i = 0; i < n; ++i){\nK::FT x, y; std::cin >> x >> y;\nP.push_back(K::Point_2(x,y));\n}\n\nif (n == 1) {\nstd::cout << 0;\nreturn;\n}\n\nMin_circle mc(P.begin(), P.end(), true);\nTraits::Circle c = mc.circle();\nK::FT r = CGAL::sqrt(c.squared_radius());\nstd::cout << ceil_to_double(r);\n}\n\nint main(){\nstd::ios_base::sync_with_stdio(false);\nint n; std::cin >> n;\nwhile(n != 0){\nsolve(n); std::cout << \"\\n\";\nstd::cin >> n;\n}\n}",
    "link": "https://expert.ethz.ch/solve/xZRJCxKxuumWM2Qb8"
  },
  {
    "name": "First Hit",
    "aka": "Nearest ray–segment intersection (first hit) with pruning (exact CGAL)",
    "week": "Week 04",
    "methods": "Computational Geometry",
    "status": "Rewrite it",
    "problemModel": "Given a ray starting at (x,y) going through (a,b), and n obstacle segments, find the first intersection point along the ray with any segment (segments include endpoints). If there is no intersection, output no. Otherwise output the intersection coordinates rounded down (floor) to integers. Multiple test cases until 0. Coordinates are integers with absolute value < 2^51 (so you must avoid 32-bit overflow and precision issues).",
    "solutionShort": "Read all segments; shuffle them. Shuffling is not required for correctness, but it increases the chance of finding a near intersection early, making later pruning effective.Maintain has_hit and the currently best (closest) intersection point best_p.For each segment:\n• If no hit yet: test do_intersect(ray, seg).\n• If hit already: build a finite search segment from ray start to best_p, and test do_intersect(search_seg, seg). This prunes any segment that only intersects the ray beyond the current best hit.\n• Only if the predicate says “intersects”, compute the actual intersection via CGAL::intersection(ray, seg) (this is the expensive step).\n• Intersection can be:\n    ◦ a point: candidate hit = that point\n    ◦ a segment (collinear overlap): candidate hit = closer endpoint of the overlap to the ray origin\n• Update best_p if candidate is closer to the origin (use has_smaller_distance_to_point).If no hit found, print no. Otherwise print floor(best_p.x) floor(best_p.y) using a safe floor_to_double routine to avoid rounding bugs with exact-to-double conversion.",
    "solution": "#include <bits/stdc++.h>\n#include <CGAL/Exact_predicates_exact_constructions_kernel.h>\n\n// CGAL type definitions\nusing K = CGAL::Exact_predicates_exact_constructions_kernel;\nusing P = K::Point_2;\nusing R = K::Ray_2;\nusing S = K::Segment_2;\n\n// Custom function to correctly floor the exact CGAL number type to a double.\n// This is necessary to handle potential floating-point inaccuracies.\ndouble floor_to_double(const K::FT& x) {\ndouble a = floor(CGAL::to_double(x));\nwhile (a > x) a -= 1;\nwhile (a + 1 <= x) a += 1;\nreturn a;\n}\n\nint main() {\n// Fast I/O\nstd::ios::sync_with_stdio(false);\nstd::cin.tie(nullptr);\n\nint n;\nwhile (std::cin >> n && n != 0) {\nlong x, y, a, b;\nstd::cin >> x >> y >> a >> b;\n\nP source_p(x, y);\nR ray(source_p, P(a, b));\n\nstd::vector<S> segs;\nsegs.reserve(n);\nfor (int i = 0; i < n; ++i) {\nlong r, s, t, u;\nstd::cin >> r >> s >> t >> u;\nsegs.emplace_back(P(r, s), P(t, u));\n}\n\n// Shuffling the segments increases the chance of finding a close hit early,\n// which makes our optimization more effective.\nstd::random_shuffle(segs.begin(), segs.end());\n\nbool has_hit = false;\nP best_p;\n\nfor (const auto& seg : segs) {\n// --- OPTIMIZATION START ---\n// The key improvement is to change the intersection test based on whether\n// we have already found a potential intersection point.\nbool potential_closer_hit;\nif (has_hit) {\n// If we have a hit, we only care about new intersections that are closer.\n// We create a temporary segment from the ray's start to the current best point.\n// Checking for intersection with this shorter segment is much faster because\n// it prunes any segments that hit the ray beyond our current best point.\nS search_seg(source_p, best_p);\npotential_closer_hit = CGAL::do_intersect(search_seg, seg);\n} else {\n// If we haven't found any hit yet, we must check against the infinite ray.\npotential_closer_hit = CGAL::do_intersect(ray, seg);\n}\n\nif (!potential_closer_hit) {\ncontinue; // Skip the expensive calculation below.\n}\n// --- OPTIMIZATION END ---\n\n// This part is the expensive \"construction\" of the intersection point.\n// We only run it if the faster \"predicate\" check above passes.\nauto inter = CGAL::intersection(ray, seg);\nif (!inter) continue; // Should not happen if do_intersect passed, but good for safety.\n\nif (const P* p = boost::get<P>(&*inter)) {\n// The intersection is a single point.\nif (!has_hit || CGAL::has_smaller_distance_to_point(source_p, *p, best_p)) {\nbest_p = p;\nhas_hit = true;\n}\n} else if (const S s = boost::get<S>(&*inter)) {\n// The ray and segment are collinear and overlap. The intersection is a segment.\n// We need to find which endpoint of the overlap is closer to the ray's start.\nP p1 = s->source(), p2 = s->target();\nP closer = (CGAL::has_smaller_distance_to_point(source_p, p1, p2)) ? p1 : p2;\nif (!has_hit || CGAL::has_smaller_distance_to_point(source_p, closer, best_p)) {\nbest_p = closer;\nhas_hit = true;\n}\n}\n}\n\nif (!has_hit) {\nstd::cout << \"no\\n\";\n} else {\nstd::cout << (long)floor_to_double(best_p.x()) << \" \"\n<< (long)floor_to_double(best_p.y()) << \"\\n\";\n}\n}\nreturn 0;\n}",
    "link": "https://expert.ethz.ch/solve/JkBRJwrTXcfYu4xEb"
  },
  {
    "name": "Boats",
    "aka": "Maximum non-overlapping intervals with anchored points (boats on rings greedy)",
    "week": "Week 05",
    "methods": "Greedy",
    "status": "Rewrite it",
    "problemModel": "There are n boats, boat i has length l and must be placed on a line so that its assigned ring position p lies somewhere on the boat (including endpoints). Boats may touch but must not overlap. Each ring position is unique. Find the maximum number of boats that can be placed simultaneously.",
    "solutionShort": "Sort boats by ring position p increasing. Place boats left-to-right while keeping them as far left as possible.\nFor a boat (l, p) that must start after some previous end prev_end, the best (leftmost) feasible placement is:\n• left = max(prev_end, p − l)\n• right = left + l = max(prev_end + l, p)\nGreedy invariant:\n• pp_end = end position of the last boat that is already fixed in the solution\n• p_end = the smallest possible end position of the “current/last” boat for the same number of selected boats (you keep one boat “flexible” and keep tightening it)\nFor each boat in increasing p:\n1. Compute best_curr = max(pp_end + l, p) (the right endpoint if this boat becomes the current flexible last boat after pp_end).\n2. If best_curr < p_end, it means this boat can replace the current last boat and end earlier → update p_end = best_curr (tighten).\n3. Else if p_end <= p, then this boat cannot improve the current last boat anymore and is far enough to start a new one: commit the current one (pp_end = p_end), increase answer, and set the new p_end = max(p_end + l, p).\nThis achieves the maximum count because you always keep the chosen boats ending as early as possible, which leaves maximal room for future boats.\n",
    "solution": "",
    "link": "https://expert.ethz.ch/solve/ugjqDKeCT7JCLgKkf"
  },
  {
    "name": "Asterix the Gaul",
    "aka": "Meet-in-the-middle subset selection with a monotone “potion boost” parameter (Split&List + binary search)",
    "week": "Week 05",
    "methods": "Binary Search, Split&List",
    "status": "Learn&ShutUp",
    "problemModel": "You have n possible movements; each can be used at most once. Movement j takes time tj and covers distance dj. If Astérix drinks i gulps of potion before starting, each selected movement gets an extra +s_i distance (same boost for every chosen move). Astérix must reach distance ≥ D in strictly less than T seconds. Find the minimum i (0..m) that makes it possible; if impossible even with m gulps, print Panoramix captured.",
    "solutionShort": "\n1. Binary search the number of gulps i.\n\nFeasibility is monotone: larger i means larger per-move boost s_i, so if i works then any i’ > i works.\n2. Feasibility check for a fixed i (meet-in-the-middle):\n\nSplit the n movements into two halves of sizes n1 and n2 (~15 each).\n\nEnumerate all subsets in each half:\n• For a subset S, compute:\n    ◦ total_time = sum(tj)\n    ◦ total_dist = sum(dj + s_i)  (only for chosen moves)\n• Discard subsets with total_time ≥ T (strictly less required).\n• If any subset already has total_dist ≥ D, return feasible immediately.\nThis produces two lists:\n• part1 = all (dist, time) from first half\n• part2 = all (dist, time) from second half\n1. Combine halves efficiently:\n\nSort part2 by time descending. Then preprocess it so that for decreasing time thresholds you keep the maximum distance achievable (dominance compression):\n• After sorting by time, sweep from back to front:\n    ◦ part2[i].dist = max(part2[i].dist, part2[i+1].dist)\nNow for each (d1, t1) in part1:\n• remaining time is (T − t1)\n• find in part2 the best distance among subsets with time < remaining_time\n    ◦ done with upper_bound on the time-sorted structure\n• if d1 + d2 ≥ D, feasible.\n1. Output the smallest i found by binary search; else Panoramix captured.\n\nTime complexity:\n\nLet N = n, with halves N/2.\n• Subset enumeration: O(2^(N/2) * N) per half in your implementation (you recompute sums inside loops). With N ≤ 30 this is still fine.\n• Sorting part2: O(2^(N/2) log 2^(N/2))\n• Combining: O(|part1| log |part2|) = O(2^(N/2) log 2^(N/2))\n• Binary search over i: O(log m) feasibility checks, with m ≤ 1e5 ⇒ ~17 checks.\n\nOverall: O(log m · 2^(N/2) · (N + log 2^(N/2))), feasible for N=30.\nYour recorded solve time:\n• Start: 13:00\n• End: 14:00\n• Total: 60 minutesSources\n",
    "solution": "//start 13: 00\n#include <bits/stdc++.h>\nusing namespace std;\n\n\n// the number of cominatios of movements is 2^30\n// but D is to big 2^50, so we can't DP\n// 2^30 is to much for brute force but ok for split&list\ntypedef vector<pair<long long, long long>> vpll;\ntypedef vector<long long> vll;\ntypedef pair<long long, long long> pll;\ntypedef long long ll;\n\nauto comp = [](pll p1, pll p2){\nreturn p1.second > p2.second;\n};\n\nbool split_list(int start, int end, const vpll& movements, ll D, ll T, ll addDist, vpll& res){\nint size = end-start;\nfor(int i = 0; i < (1<<size); ++i){\nlong long totD = 0;\nlong long totT = 0;\nfor(int j = 0; j < size; ++j){\nif(i & (1 << j)){\ntotD += (movements[start+j].first + addDist);\ntotT += movements[start+j].second;\n}\n}\nif(totT >= T) continue;\nif(totD >= D) return true;\nres.push_back({totD, totT});\n}\nreturn false;\n}\n\nbool help(const vpll& movements, const vll& pots,\nlong long addDist, long long D, long long T, int n){\nvpll part1, part2;\nif(split_list(0, n/2, movements, D, T, addDist, part1)) return true;\nif(split_list(n/2, n, movements, D, T, addDist, part2)) return true;\nsort(part2.begin(), part2.end(), comp);\nfor(int i = (int)part2.size()-2; i >= 0; --i)\npart2[i].first = max(part2[i].first, part2[i+1].first);\nfor(auto comb: part1){\nll di = comb.first;\nll ti = comb.second;\npll key = {-1, T-ti};\nauto it = upper_bound(part2.begin(), part2.end(), key ,comp);\nif(it != part2.end() && (di + it->first >= D)) return true;\n}\nreturn false;\n}\n\n\nvoid solve(){\nint n, m;\nlong long D, T;\ncin >> n >> m >> D >> T;\nvector<pair<long long, long long>> movements(n);\nfor(int i = 0; i < n; ++i){\nlong long di,ti; cin >> di >> ti;\nmovements[i] = {di,ti};\n}\nvector<long long> pots(m+1,0);\nfor(int i = 1; i <= m; ++i) cin >> pots[i];\nint left = 0, right = m;\nint res = m+1;\nwhile(left <= right){\nint mid = left + (right-left)/2;\nlong long addDist = pots[mid];\n/*\nbool help(const vpll& movements, const vll& pots,\nlong long addDist, long long D, long long T, int n){\n*/\nif(help(movements, pots, addDist, D, T, n)) {\nres = mid;\nright = mid-1;\n}\nelse left = mid+1;\n}\nif(res > m) cout << \"Panoramix captured\";\nelse cout << res;\n}\n\nint main(){\nios_base::sync_with_stdio(0);\nint t; cin >> t;\nwhile(t--){ solve(); cout << \"\\n\";}\n}\n// end 14:00",
    "link": "https://expert.ethz.ch/solve/HYMnEFkSPfGL77LhX"
  },
  {
    "name": "Attack of the Clones",
    "aka": "Circular interval scheduling via low-congestion cut",
    "week": "Week 05",
    "methods": "Greedy, Sweep Line",
    "status": "HARD",
    "problemModel": "You have n circular intervals on segments 1..m (wrap-around allowed). Pick the largest subset of pairwise disjoint intervals.\nConstraints (from statement): n ≤ 5·10^4, m ≤ 10^9, t ≤ 40, and there exists a segment s covered by at most 10 intervals. \nthis (20)\nWhy brute force is impossible: checking subsets is 2^n (hopeless for n=50k), and anything proportional to m is also impossible (m up to 1e9).",
    "solutionShort": "Key idea\nBecause there exists a segment s covered by ≤ 10 Jedi intervals:\n• In any valid solution, you can pick at most one interval that covers s (two would overlap on segment s).\n• Therefore, the optimum is the best among:\n    1. pick none of the intervals covering s\n    2. pick exactly one of them (≤ 10 trials)\nOnce s is fixed, you cut the circle at s and turn all intervals not covering s into standard linear intervals, then solve by the classic greedy “earliest finishing time”.\nStep-by-step method\n1) Find a segment s with minimum coverage (sweep-line)\nYou build a difference map on the circle:\n• For non-wrapping [a,b] (a ≤ b): +1 at a, -1 at b+1\n• For wrapping [a,b] (a > b): split into [a,m] and [1,b]:\n    ◦ +1 at a, -1 at m+1, and +1 at 1, -1 at b+1\nThen scan events in order and track the position with smallest current load → that’s your s.\nTime: O(n log n) because of the ordered map of events.\n2) Partition intervals into:\n• covering_s: intervals that contain s (guaranteed ≤ 10)\n• others: intervals that do not contain s\n3) Linearize (“cut”) the circle at s\nUse a shift so s becomes position 0:\nCorrect shift (this matters):\n\nshift(x) = (x - s + m) % m;   // result in [0, m-1]\n\nFor any interval not covering s, after shifting you get a non-wrapping linear interval [a', b'] with a' <= b'.\n4) Solve maximum non-overlapping on a line (greedy)\nSort others by increasing b', then greedily take an interval if a' > last_end.\nThis is optimal for linear interval scheduling.\n5) Case split (≤ 11 runs)\n• Trial 0: choose none from covering_s → greedy on all others\n• Trial for each interval J in covering_s: pick J, then among others only intervals that fit in the remaining gap (the part not intersecting J)\nIn shifted coordinates, a covering interval J becomes a wrapping one (aJ' > bJ'). The allowed region for others is exactly:\n• take intervals with a' > bJ' and b' < aJ'\nThen run greedy on those.\nComplexity\nLet n = #intervals:\n• Sweep to find s: O(n log n)\n• Build & sort linearized others: O(n log n)\n• Greedy pass: O(n)\n• Case split over ≤ 10 covering intervals: O(10n)\nTotal: O(n log n) time, O(n) memory.\n\nWorks comfortably for n=5·10^4.\nImportant issues in your posted code (real bugs)\nYour logic is correct, but your linearization is wrong in edge cases:\n1. Shift formula is incorrect when a == s or b == s:\n\nYou used:\n\nint new_a = (a > s) ? (a - s) : (a + m - s);\n\nIf a == s, this returns m, but you need 0.\n✅ Fix:\n\nint new_a = (a - s + m) % m;\nint new_b = (b - s + m) % m;\n\n1. Your solve_linear(1, m, others) assumes coordinates in [1, m], but after shifting you should be in [0, m-1].\n\nSo the greedy should run with start = 0 and no artificial end filter, or use [0, m) consistently.\n2. Off-by-one / inclusivity: the original problem uses segments as discrete and intervals are inclusive. Your greedy check interval.first > last_finishing_time is fine as long as you interpret “disjoint” as not sharing any segment; if endpoints are inclusive, the “compatible” condition should indeed be next_start > last_end.",
    "solution": "",
    "link": "https://expert.ethz.ch/solve/KQfugMNiPfDK8jDhd"
  },
  {
    "name": "Moving Books",
    "aka": "Binary search on minimum feasible makespan with greedy feasibility check",
    "week": "Week 05",
    "methods": "Binary Search, Greedy",
    "status": "Completed",
    "problemModel": "You have n friends with strengths si (max weight they can lift) and m boxes with weights wi. A friend can carry one box at a time, and boxes can’t be carried jointly. Carrying a box downstairs takes 2 minutes, returning upstairs takes 1 minute. Initially all friends are upstairs; at the end, they do not need to be upstairs. Compute the minimum total time to move all boxes, or output impossible if some box is too heavy for every friend.",
    "solutionShort": "Sort friends’ strengths descending and boxes’ weights descending.Quick impossibility check: if heaviest box > strongest friend ⇒ impossible.Binary search the minimum number of rounds R (1..m).\n• Feasibility check for a candidate R:\n    ◦ Each friend can carry at most R boxes (one per round).\n    ◦ Greedily try to assign the heaviest remaining boxes to the strongest available friend, counting up to R boxes per friend.\n    ◦ If all m boxes can be assigned ⇒ feasible; otherwise infeasible.Convert rounds to time: time = 3*R − 1 minutes.\n• Each round costs 2 (down) + 1 (up) = 3, but after the last carried box there is no need to return upstairs, hence “−1”.",
    "solution": "// start time: 12:40\n#include <bits/stdc++.h>\nusing namespace std;\n\nvoid solve(){\nint n, m; cin >> n >> m;\nvector<int> friends(n);\nfor(int i = 0; i < n; ++i) cin >> friends[i];\nvector<int> boxes(m);\nfor(int i = 0; i < m; ++i) cin >> boxes[i];\nsort(friends.rbegin(), friends.rend());\nsort(boxes.rbegin(), boxes.rend());\nif(boxes[0] > friends[0]){\ncout << \"impossible\"; return;\n}\nint left = 1, right = m;\nint res = m+1;\nwhile(left <= right){\nint mid = left + (right-left)/2;\n// mid :  num of round\nint bidx = 0, pidx = 0;\nint currTrip = 0;\nwhile(bidx < m && pidx < n){\nif(currTrip == mid) {\n++pidx; currTrip = 0;\n} else{\nif(friends[pidx] >= boxes[bidx]) {\n++bidx; ++currTrip;\n}\nelse {\n++pidx; currTrip = 0;\n}\n}\n}\nif(bidx != m) left = mid+1;\nelse {\nres = min(res, mid);\nright = mid-1;\n}\n}\ncout << res*3-1;\n}\n\nint main(){\nios_base::sync_with_stdio(false);\nint t; cin >> t;\nwhile(t--){\nsolve(); cout << \"\\n\";\n}\n}\n//end time: 12:54",
    "link": "https://expert.ethz.ch/solve/d4Ycy2PoWL8D9vGok"
  },
  {
    "name": "Planet Express",
    "aka": "Multi-source Dijkstra (add new source connecting to old sources, with cost 0)\n\nFind shortest path from one of the sources to a target node + a network of teleportation",
    "week": "Week 05",
    "methods": "Dijkstra, Strongly Connected Components",
    "status": "Completed",
    "problemModel": "You have a directed weighted graph of n planets and m travel edges (cost in microseconds). You may start from any of the k warehouses at nodes 0..k−1. Destination is node n−1. Additionally, T planets are in a teleport network: two teleport planets u and v are “linked” if they are mutually reachable using only normal travel (no teleport), i.e., they lie in the same SCC. From teleport planet u you can teleport to any other linked teleport planet v in cost t(u), where t(u) equals the number of teleport planets linked with u (size of that teleport set). Find the shortest delivery time; if it exceeds 1,000,000 microseconds (1 second), print no, else print the time. ",
    "solutionShort": "\n1. Compute SCCs on the original directed graph (ignoring teleports).\n\nTwo teleport nodes are linked iff they are in the same SCC. Count, for each SCC, how many teleport nodes it contains: sizeTele[SCC].\n2. Build an augmented graph for Dijkstra without quadratic teleport edges.\n\nFor each SCC that contains teleport nodes, create one extra “hub” vertex H_scc.\n\nFor each teleport node u in that SCC:\n• add edge u → H_scc with weight 0\n• add edge H_scc → u with weight (sizeTele[scc] − 1)\n\nWhy it works: to go from u to v (u≠v) inside the same SCC via teleport, take u→H (0), then H→v (size−1). That exactly equals t(u) because t(u) is the number of linked teleport planets, and “linked” here means “teleport nodes in same SCC”.\n1. Add a super-source to handle “start from any warehouse”.\n\nCreate S and connect S → i with weight 0 for i=0..k−1.\n2. Copy all original travel edges into the augmented graph with their weights.\n3. Run Dijkstra from S to target (n−1).\n\nIf dist[n−1] > 1,000,000 (or unreachable), print no, else print dist.",
    "solution": "// STL includes\n#include <iostream>\n#include <vector>\nusing namespace std;\n// BGL includes\n#include <boost/graph/adjacency_list.hpp>\n#include <boost/graph/strong_components.hpp>\n\ntypedef boost::adjacency_list<boost::vecS, boost::vecS, boost::directedS> graph;\ntypedef boost::graph_traits<graph>::edge_iterator                         edge_it;\n\n\n// BGL includes\n#include <boost/graph/adjacency_list.hpp>\n#include <boost/graph/dijkstra_shortest_paths.hpp>\n\ntypedef boost::adjacency_list<boost::vecS, boost::vecS, boost::directedS,\nboost::no_property, boost::property<boost::edge_weight_t, long> >      weighted_graph;\ntypedef boost::property_map<weighted_graph, boost::edge_weight_t>::type weight_map;\ntypedef boost::graph_traits<weighted_graph>::edge_descriptor            edge_desc;\ntypedef boost::graph_traits<weighted_graph>::vertex_descriptor          vertex_desc;\n\nlong dijkstra_dist(const weighted_graph &G, int s, int t) {\nint n = boost::num_vertices(G);\nstd::vector<long> dist_map(n);\n\nboost::dijkstra_shortest_paths(G, s,\nboost::distance_map(boost::make_iterator_property_map(\ndist_map.begin(), boost::get(boost::vertex_index, G))));\n\nreturn dist_map[t];\n}\n\nvoid testcase() {\nint n, m, k, T;\nstd::cin >> n >> m >> k >> T;\nvector<int> isTelep(T, false);\nfor(int i = 0; i < T; ++i){\ncin >> isTelep[i];\n}\ngraph G(n);\nstruct edge {\nint u, v;\nlong c;\n};\nvector<edge> edges(m);\nfor (int i = 0; i < m; ++i) {\nint u, v;\nlong c;\nstd::cin >> u >> v >> c;\nedges[i] = {u,v,c};\nboost::add_edge(u, v, G);\n}\n\n// scc_map[i]: index of SCC containing i-th vertex\nstd::vector<int> scc_map(n);  // exterior property map\n// nscc: total number of SCCs\nint nscc = boost::strong_components(G,\nboost::make_iterator_property_map(scc_map.begin(), boost::get(boost::vertex_index, G)));\n\nweighted_graph G_dj(n+nscc+1);\nweight_map weights = boost::get(boost::edge_weight, G_dj);\nedge_desc e;\nconst int v_source = n+nscc;\nfor(int i = 0; i < k; ++i){\ne = boost::add_edge(v_source, i, G_dj).first; weights[e]=0;\n}\nedge_it ebeg, eend;\nvector<int> sizes(nscc, 0);\n\nfor(int node: isTelep){\n++sizes[scc_map[node]];\n}\nfor(int i: isTelep){\ne = boost::add_edge(i, n+scc_map[i], G_dj).first; weights[e]=0;\ne = boost::add_edge(n+scc_map[i], i, G_dj).first; weights[e]=sizes[scc_map[i]]-1;\n}\n\nfor (int i = 0; i < m; ++i) {\nint u, v;\nlong long c;\nu = edges[i].u;\nv = edges[i].v;\nc = edges[i].c;\ne = boost::add_edge(u, v, G_dj).first; weights[e]=c;\n}\n\nlong long res = dijkstra_dist(G_dj, v_source, n-1);\nif(res > 1000000) cout << \"no\";\nelse cout << res;\n}\n\nint main()\n{\nios_base::sync_with_stdio(false);\nint T;\nstd::cin >> T;\n\nwhile(T--) {\ntestcase(); cout << \"\\n\";\n}\n\nreturn 0;\n}",
    "link": "https://expert.ethz.ch/solve/Q2qjBgStjkxoEjBX2"
  },
  {
    "name": "Knights",
    "aka": "Max flow with vertex capacities and unit edge capacities",
    "week": "Week 06",
    "methods": "MaxFlow, Vertex Capacity",
    "status": "Completed",
    "problemModel": "The cave is an m×n grid graph of intersections. Each knight starts at a given intersection (all distinct). Whenever a knight traverses a hallway segment, that segment collapses immediately, so it can be used by at most one knight. Intersections are stronger: an intersection collapses after C knights have been there, so each intersection can be used by at most C knights total. All boundary hallway ends connect to the outside (escape). Compute the maximum number of knights that can escape. ",
    "solutionShort": "Model the situation as a flow network where each unit of flow = one escaping knight.\n1. Node-splitting for intersection capacity C\n\nFor each grid cell v, create two nodes: v_in and v_out.\n\nAdd edge v_in → v_out with capacity C.\n\nThis enforces: at most C knights can “use” that intersection.\n2. Hallway segment capacity 1\n\nFrom v_out, for each of the 4 directions:\n• If neighbor u is inside the grid: add edge v_out → u_in with capacity 1 (that corridor segment can be used by one knight).\n• If stepping outside the grid: add edge v_out → sink with capacity 1 (escaping via that boundary segment; corners correctly have two distinct exit segments, hence two sink edges).\n1. Multiple starting positions\n\nAdd a super source S. For each knight start cell s: add S → s_in with capacity 1 (each start has one knight).\n2. Run max flow\n\nCompute max flow from S to sink. The flow value equals the maximum number of knights that can reach outside while respecting:\n• per-segment capacity 1 (collapse behind),\n• per-intersection capacity C.",
    "solution": "//start: 12:21\n// Algolab BGL Tutorial 2 (Max flow, by mailto:taubnert@ethz.ch)\n// Flow example demonstrating how to use push_relabel_max_flow using a custom edge adder\n// to manage the interior graph properties required for flow algorithms\n#include <iostream>\n#include <bits/stdc++.h>\nusing namespace std;\n// BGL include\n#include <boost/graph/adjacency_list.hpp>\n\n// BGL flow include NEW\n#include <boost/graph/push_relabel_max_flow.hpp>\n\n// Graph Type with nested interior edge properties for flow algorithms\ntypedef boost::adjacency_list_traits<boost::vecS, boost::vecS, boost::directedS> traits;\ntypedef boost::adjacency_list<boost::vecS, boost::vecS, boost::directedS, boost::no_property,\nboost::property<boost::edge_capacity_t, long,\nboost::property<boost::edge_residual_capacity_t, long,\nboost::property<boost::edge_reverse_t, traits::edge_descriptor>>>> graph;\n\ntypedef traits::vertex_descriptor vertex_desc;\ntypedef traits::edge_descriptor edge_desc;\n\n// Custom edge adder class, highly recommended\nclass edge_adder {\ngraph &G;\n\npublic:\nexplicit edge_adder(graph &G) : G(G) {}\n\nvoid add_edge(int from, int to, long capacity) {\nauto c_map = boost::get(boost::edge_capacity, G);\nauto r_map = boost::get(boost::edge_reverse, G);\nconst auto e = boost::add_edge(from, to, G).first;\nconst auto rev_e = boost::add_edge(to, from, G).first;\nc_map[e] = capacity;\nc_map[rev_e] = 0; // reverse edge has no capacity!\nr_map[e] = rev_e;\nr_map[rev_e] = e;\n}\n};\nint totcol;\nint totrow;\nint transform(int coli, int rowj){\nreturn colitotrow + rowj;\n}\nvoid make_it_flow() {\nint m, n, k, c; cin >> m >> n >> k >> c;\ntotcol = m;\ntotrow = n;\ngraph G(nm2);\nedge_adder adder(G);\nconst int shift = nm;\nconst vertex_desc v_source = boost::add_vertex(G);\nconst vertex_desc v_sink = boost::add_vertex(G);\nfor(int i = 0; i < k; ++i){\nint coli, rowj; cin >> coli >> rowj;\nadder.add_edge(v_source, transform(coli,rowj), 1);\n}\nvector<pair<int,int>> moves = {{1,0},{0,1},{-1,0},{0,-1}};\nfor(int i = 0; i < m; ++i){\nfor(int j = 0; j < n; ++j){\nint idx = transform(i,j);\nadder.add_edge(idx, shift+idx, c);\nfor(auto move: moves){\nint newi = i+move.first;\nint newj = j+move.second;\nif(newi >= 0 && newi < m && newj >= 0 && newj < n)\nadder.add_edge(shift+idx, transform(newi,newj), 1);\nelse adder.add_edge(shift+idx, v_sink, 1);\n}\n}\n}\n// - edge_capacity, edge_reverse (read access),\n// - edge_residual_capacity (read and write access).\nlong flow = boost::push_relabel_max_flow(G, v_source, v_sink);\nstd::cout << flow;\n\n}\n\nint main() {\nios_base::sync_with_stdio(false);\nint t; cin >> t;\nwhile(t--){\nmake_it_flow(); cout << \"\\n\";\n}\n\n\nreturn 0;\n}\n//end : 12:33",
    "link": "https://expert.ethz.ch/solve/TmFaTbNReatKYvc2y"
  },
  {
    "name": "Tiles",
    "aka": "Perfect matching feasibility in a bipartite grid graph",
    "week": "Week 06",
    "methods": "Maximum matching",
    "status": "Completed",
    "problemModel": "You are given a w×h grid where . cells must be tiled and x cells must remain empty. A domino tile covers exactly two orthogonally adjacent cells (horizontal or vertical). Decide if all . cells can be covered exactly once by dominoes (unlimited supply). Output yes or no. ",
    "solutionShort": "Give every . cell a unique id (0..n−1). Let n be the number of free cells.If n is odd, immediately output no (dominoes cover 2 cells each).Build an undirected graph G with n vertices: add an edge between two vertices iff their corresponding cells are orthogonally adjacent and both are ..Compute a maximum cardinality matching in G (Edmonds’ algorithm via BGL).If the matching size is exactly n/2, then a perfect matching exists, which corresponds to a valid domino tiling ⇒ yes. Otherwise ⇒ no.",
    "solution": "// STL includes\n#include <iostream>\n#include <vector>\nusing namespace std;\n// BGL includes\n#include <boost/graph/adjacency_list.hpp>\n#include <boost/graph/max_cardinality_matching.hpp>\n\ntypedef boost::adjacency_list<boost::vecS, boost::vecS, boost::undirectedS> graph;\ntypedef boost::graph_traits<graph>::vertex_descriptor                       vertex_desc;\n\nint maximum_matching(const graph &G) {\nint n = boost::num_vertices(G);\nstd::vector<vertex_desc> mate_map(n);  // exterior property map\n\nboost::edmonds_maximum_cardinality_matching(G,\nboost::make_iterator_property_map(mate_map.begin(), boost::get(boost::vertex_index, G)));\nreturn boost::matching_size(G,\nboost::make_iterator_property_map(mate_map.begin(), boost::get(boost::vertex_index, G)));\n}\n\nvoid solve(){\nint w, h; cin >> w >> h;\nvector<vector<int>> matrix(h, vector<int> (w,-1));\nint n = 0;\nfor(int i = 0; i < h; ++i){\nfor(int j = 0; j < w; ++j){\nchar c; cin >> c;\nif(c == '.') {\nmatrix[i][j] = n;\n++n;\n}\n}\n}\nif(n%2){\ncout << \"no\"; return;\n}\ngraph G(n);\nvector<pair<int,int>> moves = {{1,0},{0,1},{-1,0},{0,-1}};\nfor(int i = 0; i < h; ++i){\nfor(int j = 0; j < w; ++j){\nif(matrix[i][j] == -1) continue;\nfor(auto move: moves){\nint newi = i+move.first;\nint newj = j+move.second;\nif(newi >= 0 && newi < h && newj >= 0 && newj < w && matrix[newi][newj] != -1){\nboost::add_edge(matrix[i][j], matrix[newi][newj], G);\n}\n}\n}\n}\n\nif(2*maximum_matching(G) == n) cout << \"yes\";\nelse cout << \"no\";\n}\n\nint main(){\nios_base::sync_with_stdio(false);\nint t; cin >> t;\nwhile(t--){\nsolve(); cout << \"\\n\";\n}\n}",
    "link": "https://expert.ethz.ch/solve/koeZJPBREr7CdHE5v"
  },
  {
    "name": "Coin Tossing Tournament",
    "aka": "Feasibility of fixed marginals via max flow",
    "week": "Week 06",
    "methods": "MaxFlow",
    "status": "Completed",
    "problemModel": "There are n players and m rounds. Each round is between players a and b. If the winner is known, that winner gets 1 point. If unknown (c=0), exactly one of the two must get 1 point. You are given a final scoreboard s0..s(n−1). Decide if there exists an assignment of outcomes for all unknown rounds so that every player ends with exactly si points. Output yes or no.",
    "solutionShort": "\n1. Compute current known scores.\n\nFor each match:\n• c=1 → increment score[a]\n• c=2 → increment score[b]\n• c=0 → treat as an “unresolved match” that must give 1 point to either endpoint.\n1. Convert unresolved matches into a flow problem.\n\nCreate a directed flow network with:\n• A node for each unresolved match (index 0..u−1 in your code, reusing i for matches with c=0)\n• A node for each player (offset by m in your code: m+i)\n• Source S and sink T\nAdd edges:\n• S → matchNode with capacity 1 (each unresolved match contributes exactly 1 point total)\n• matchNode → player a with cap 1 and matchNode → player b with cap 1 (that point can go to either player)\n• player i → T with cap (si − current_score[i]) (how many additional points player i still needs)\n1. Early impossibility checks (important):\n• If si − current_score[i] < 0 for some i → already exceeded scoreboard → no.\n• Let U be #unresolved matches. Total remaining points needed is sum(si − current_score[i]). Must equal U, otherwise no (since each unresolved match contributes exactly one point).\n1. Run max flow and verify.\n\nCompute max flow from S to T.\n• If flow == total_remaining_needed → assignment exists → yes\n• Else → no\n\nThis works because each unit of flow corresponds to choosing the winner of an unresolved match.",
    "solution": "//sratt 11:23\n// Algolab BGL Tutorial 2 (Max flow, by mailto:taubnert@ethz.ch)\n// Flow example demonstrating how to use push_relabel_max_flow using a custom edge adder\n// to manage the interior graph properties required for flow algorithms\n#include <iostream>\n#include <bits/stdc++.h>\nusing namespace std;\n// BGL include\n#include <boost/graph/adjacency_list.hpp>\n\n// BGL flow include NEW\n#include <boost/graph/push_relabel_max_flow.hpp>\n\n// Graph Type with nested interior edge properties for flow algorithms\ntypedef boost::adjacency_list_traits<boost::vecS, boost::vecS, boost::directedS> traits;\ntypedef boost::adjacency_list<boost::vecS, boost::vecS, boost::directedS, boost::no_property,\nboost::property<boost::edge_capacity_t, long,\nboost::property<boost::edge_residual_capacity_t, long,\nboost::property<boost::edge_reverse_t, traits::edge_descriptor>>>> graph;\n\ntypedef traits::vertex_descriptor vertex_desc;\ntypedef traits::edge_descriptor edge_desc;\n\n// Custom edge adder class, highly recommended\nclass edge_adder {\ngraph &G;\n\npublic:\nexplicit edge_adder(graph &G) : G(G) {}\n\nvoid add_edge(int from, int to, long capacity) {\nauto c_map = boost::get(boost::edge_capacity, G);\nauto r_map = boost::get(boost::edge_reverse, G);\nconst auto e = boost::add_edge(from, to, G).first;\nconst auto rev_e = boost::add_edge(to, from, G).first;\nc_map[e] = capacity;\nc_map[rev_e] = 0; // reverse edge has no capacity!\nr_map[e] = rev_e;\nr_map[rev_e] = e;\n}\n};\n\nvoid make_it_flow() {\nint n, m; cin >> n >> m;\nvector<long> curr_scores(n,0);\ngraph G(m+n);\nedge_adder adder(G);\nconst vertex_desc v_source = boost::add_vertex(G);\nconst vertex_desc v_sink = boost::add_vertex(G);\nint match_rem = 0;\nfor(int i = 0; i < m; ++i){\nint a, b, c; cin >> a >> b >> c;\nif(c == 1) ++curr_scores[a];\nelse if(c == 2) ++curr_scores[b];\nelse if(c == 0){\nadder.add_edge(v_source, i, 1);\nadder.add_edge(i, m+a, 1);\nadder.add_edge(i, m+b, 1);\n++match_rem;\n}\n}\nvector<long> lb(n);\nfor(int i = 0; i < n; ++i){\ncin >> lb[i];\n}\nlong tot_rem = 0;\nfor(int i = 0; i < n; ++i){\nlong rem =  lb[i]-curr_scores[i];\nif(rem < 0){\ncout << \"no\"; return;\n} else adder.add_edge(m+i, v_sink, rem);\ntot_rem += rem;\n}\nif(match_rem != tot_rem) {\ncout << \"no\"; return;\n}\n\n\n// The flow algorithm uses the interior properties (managed in the edge adder)\n// - edge_capacity, edge_reverse (read access),\n// - edge_residual_capacity (read and write access).\nlong flow = boost::push_relabel_max_flow(G, v_source, v_sink);\nif(flow == tot_rem) cout << \"yes\";\nelse cout << \"no\";\n}\n\nint main() {\nios_base::sync_with_stdio(0);\nint t; cin >> t;\nwhile(t--){\nmake_it_flow(); cout << \"\\n\";\n}\n\n\nreturn 0;\n}\n//end 11:40",
    "link": "https://expert.ethz.ch/solve/o6cyW5DLWT5AEhDRs"
  },
  {
    "name": "Motorcycles",
    "aka": "Two-pass dominance filtering after sorting (envelope / skyline selection)",
    "week": "Week 06",
    "methods": "Sort by y0, Two-pass dominance filtering",
    "status": "Rewrite it",
    "problemModel": "There are n bikers starting at (0, y0) with distinct y0. Biker i rides along the ray through (x1, y1) with x1>0 (direction only). All move at the same speed. If a biker reaches a point that was already visited earlier by another biker, she stops. If two bikers reach the same point at the same time, the one coming “from the right” continues and the other stops. Output the indices of bikers that never meet anyone’s tracks (ride forever), sorted increasingly.",
    "solutionShort": "\n1. For each biker compute the slope of the ray: slope = (y1 − y0) / x1 as an exact rational (Gmpq).\n2. Sort bikers by starting y0 decreasing (top to bottom).\n3. Mark everyone as “forever” initially, then eliminate bikers that must collide using slope dominance.\nIntuition: when you order by y0, a biker can only be blocked by bikers starting above or below depending on whether her ray goes “up” or “down”. The surviving riders are those whose slopes form a kind of monotone “envelope” when scanned.\nYour implementation does two scans:\n• Top-down scan (i = 1..n−1): keep a running min_slope in terms of absolute value (your condition abs(slopes[i]) <= abs(min_slope) updates it). If a biker’s slope is too steep upward compared to what’s already “protecting” from above (slopes[i] > min_slope in your code), she’s marked not-forever.\n• Bottom-up scan (i = n−2..0): similarly keep the current best limiting slope from below (min_slope = slopes[n−1]) with careful tie-handling on equal absolute value. If a biker slopes too far downward compared to the limiter (slopes[i] < min_slope), she’s eliminated.\n1. Collect indices still marked forever and sort them for output.\n(Important for correctness at this scale: you use exact rationals for slope comparisons, avoiding precision bugs with near-parallel lines.)",
    "solution": "#include <bits/stdc++.h>\n#include <CGAL/Gmpq.h>\n#include <CGAL/Exact_predicates_inexact_constructions_kernel.h>\ntypedef CGAL::Exact_predicates_inexact_constructions_kernel K;\nusing namespace std;\n\ntypedef CGAL::Gmpq IT;\n\nvoid solve(){\nint n; cin >> n;\nstruct biker{\nlong y0;\nIT slope;\nint idx;\n};\nvector<biker> bikers(n);\nfor(int i = 0; i < n; ++i){\nlong y0, x1, y1; cin >> y0 >> x1 >> y1;\nbikers[i] = {y0,IT(y1-y0, x1),i};\n}\nsort(bikers.begin(), bikers.end(), [&](biker b1, biker b2){\nreturn b1.y0 > b2.y0;\n});\nvector<bool> forever(n, true);\n\nvector<IT> slopes(n);\nfor(int i = 0; i < n; ++i) slopes[i] = bikers[i].slope;\n\nIT min_slope = slopes[0];\nfor(int i = 1; i < n; ++i){\nif(abs(slopes[i]) <= abs(min_slope)) min_slope = slopes[i];\nelse if(slopes[i] > min_slope) forever[i] = false;\n}\n\nmin_slope = slopes[n-1];\nfor(int i = n-2; i >= 0; --i){\nif(abs(slopes[i]) < abs(min_slope)) min_slope = slopes[i];\nelse if(abs(slopes[i]) == abs(min_slope) && slopes[i] > min_slope) min_slope = slopes[i];\nelse if(slopes[i] < min_slope) forever[i] = false;\n}\n\nvector<int> res;\nfor(int i = 0; i < n; ++i){\nif(forever[i]) res.push_back(bikers[i].idx);\n}\nsort(res.begin(), res.end());\nfor(int i: res) cout << i << \" \";\n\n}\n\nint main(){\nios_base::sync_with_stdio(false);\nint t; cin >> t;\nwhile(t--){\nsolve(); cout << \"\\n\";\n}\nif(cin >> t) cout << \"jieufeifw\\n\";\n}",
    "link": "https://expert.ethz.ch/solve/E2zprburo9XkhJ9Rb"
  },
  {
    "name": "London",
    "aka": "Feasibility of aggregated two-choice resources via max flow\n(or shorter: “Two-choice supply feasibility via max flow”)",
    "week": "Week 06",
    "methods": "Frequency counting, MaxFlow",
    "status": "Completed",
    "problemModel": "A newspaper page has a front and a back, each an h×w grid of capital letters. Cutting the page into 1×1 tiles gives pieces with a letter on the front and a (fixed) corresponding letter on the back (due to the physical alignment and mirroring). You may flip each piece. Given a target note string, decide if you can assemble it using some/all tiles (each tile at most once). Output Yes or No. ",
    "solutionShort": "\n1. Count required letters.\n\nCompute objective[L] = how many times each letter L appears in the note.\n2. Compute available tile pair counts.\n\nRead front grid normally. Read back grid with the required mirroring: back line i corresponds to front line (h−1−i), and within a line j maps to (w−1−j). Your code implements this by storing back[i][w-j-1].\n\nFor each tile position, you get an unordered pair (f,b). Since you can flip, the tile can provide either f or b.\n\nCount:\n• source_to_letter[f]++ (how many tiles have front letter f; used as supply into node f)\n• to_give[f][b]++ (how many tiles have front f and back b)\n1. Flow model on 26 letters:\n• Source S → node i with capacity = number of tiles whose front is i (source_to_letter[i])\n• For every ordered pair (i,j), edge i → j with capacity = number of tiles (front=i, back=j). This represents “use one such tile and possibly flip to output j”.\n• Node i → sink T with capacity = objective[i] (need that many of letter i).\n\nRun max flow; if total flow equals note length, you can satisfy all demands.\nIntuition: Each unit of flow corresponds to picking one physical tile: it enters at its front letter node i (consuming supply), travels along i→j (choosing which back letter it can become), and exits at demanded letter j. Capacities enforce that each tile is used at most once.",
    "solution": "//start 11:50\n// Algolab BGL Tutorial 2 (Max flow, by mailto:taubnert@ethz.ch)\n// Flow example demonstrating how to use push_relabel_max_flow using a custom edge adder\n// to manage the interior graph properties required for flow algorithms\n#include <iostream>\n#include <bits/stdc++.h>\nusing namespace std;\n// BGL include\n#include <boost/graph/adjacency_list.hpp>\n\n// BGL flow include NEW\n#include <boost/graph/push_relabel_max_flow.hpp>\n\n// Graph Type with nested interior edge properties for flow algorithms\ntypedef boost::adjacency_list_traits<boost::vecS, boost::vecS, boost::directedS> traits;\ntypedef boost::adjacency_list<boost::vecS, boost::vecS, boost::directedS, boost::no_property,\nboost::property<boost::edge_capacity_t, long,\nboost::property<boost::edge_residual_capacity_t, long,\nboost::property<boost::edge_reverse_t, traits::edge_descriptor>>>> graph;\n\ntypedef traits::vertex_descriptor vertex_desc;\ntypedef traits::edge_descriptor edge_desc;\n\n// Custom edge adder class, highly recommended\nclass edge_adder {\ngraph &G;\n\npublic:\nexplicit edge_adder(graph &G) : G(G) {}\n\nvoid add_edge(int from, int to, long capacity) {\nauto c_map = boost::get(boost::edge_capacity, G);\nauto r_map = boost::get(boost::edge_reverse, G);\nconst auto e = boost::add_edge(from, to, G).first;\nconst auto rev_e = boost::add_edge(to, from, G).first;\nc_map[e] = capacity;\nc_map[rev_e] = 0; // reverse edge has no capacity!\nr_map[e] = rev_e;\nr_map[rev_e] = e;\n}\n};\n\nvoid make_it_flow() {\nint h, w; cin >> h >> w;\nstring target; cin >> target;\nlong res_target = target.size();\nint size = (int)('Z'-'A');\n++size;\nvector<int> objective(size,0);\nfor(char c: target){\nint idx = (int)(c-'A');\n++objective[idx];\n}\n\ngraph G(size);\nedge_adder adder(G);\n\n// Add special vertices source and sink\nconst vertex_desc v_source = boost::add_vertex(G);\nconst vertex_desc v_sink = boost::add_vertex(G);\nfor(int i = 0; i < size; ++i){\nif(objective[i] > 0) adder.add_edge(i, v_sink, objective[i]);\n}\n\nvector<vector<char>> front(h, vector<char> (w));\nfor(int i = 0; i < h; ++i){\nfor(int j = 0; j < w; ++j){\ncin >> front[i][j];\n}\n}\nvector<vector<char>> back(h, vector<char> (w));\nfor(int i = 0; i < h; ++i){\nfor(int j = 0; j < w; ++j){\ncin >> back[i][w-j-1];\n}\n}\nvector<int> source_to_letter(size,0);\nvector<vector<int>> to_give(size, vector<int> (size,0));\nfor(int i = 0; i < h; ++i){\nfor(int j = 0; j < w; ++j){\nchar f = front[i][j];\nchar b = back[i][j];\nint fidx = f-'A';\nint bidx = b-'A';\nsource_to_letter[fidx] += 1;\nto_give[fidx][bidx] += 1;\n}\n}\nfor(int i = 0; i < size; ++i){\nif(source_to_letter[i] > 0) adder.add_edge(v_source, i, source_to_letter[i]);\n}\nfor(int i = 0; i < size; ++i){\nfor(int j = 0; j < size; ++j){\nif(to_give[i][j] > 0) adder.add_edge(i, j, to_give[i][j]);\n}\n}\n\n// Calculate flow from source to sink\n// The flow algorithm uses the interior properties (managed in the edge adder)\n// - edge_capacity, edge_reverse (read access),\n// - edge_residual_capacity (read and write access).\nlong flow = boost::push_relabel_max_flow(G, v_source, v_sink);\nif(flow == res_target) cout << \"Yes\";\nelse cout << \"No\";\n\n}\n\nint main() {\nios_base::sync_with_stdio(0);\nint t; cin >> t;\nwhile(t--){\nmake_it_flow(); cout << \"\\n\";\n}\n\n\nreturn 0;\n}\n//end: 12:18",
    "link": "https://expert.ethz.ch/solve/SbpvKZD3wG6mEmPGN"
  },
  {
    "name": "Bistro",
    "aka": "Nearest-neighbor queries in 2D via Delaunay triangulation",
    "week": "Week 07",
    "methods": "Delaunay triangulation",
    "status": "Completed",
    "problemModel": "Given n existing points (restaurant locations) and then m query points (candidate locations), output for each query the squared Euclidean distance to the closest existing point. Multiple test cases; input ends with 0. \n",
    "solutionShort": "\n1. Read the n existing points and build a Delaunay triangulation over them (with vertex info storing indices if needed).\n2. For each query point q:\n    ◦ Use t.nearest_vertex(q) to get the nearest triangulation vertex (nearest existing point).\n    ◦ Compute CGAL::squared_distance(q, nearest_point) and print it.\n\nDelaunay triangulation supports nearest-neighbor queries efficiently in practice; squared distance avoids floating issues from square roots.\n",
    "solution": "// ETH AlgoLab example code: Compute a Euclidean minimum spanning tree (EMST)\n// for n points p_0,...,p_{n-1} in O(n log n) time. Output the edges as ordered\n// pairs of vertex indices (smaller first) together with the squared length; for\n// instance, an edge between p_4=(0,0) and p_2=(1,2) is printed as \"2 4 5\".\n\n#include <CGAL/Exact_predicates_inexact_constructions_kernel.h>\n#include <CGAL/Delaunay_triangulation_2.h>\n#include <CGAL/Triangulation_vertex_base_with_info_2.h>\n#include <CGAL/Triangulation_face_base_2.h>\n#include <boost/pending/disjoint_sets.hpp>\n#include <vector>\n#include <tuple>\n#include <algorithm>\n#include <iostream>\n\n// Epic kernel is enough, no constructions needed, provided the squared distance\n// fits into a double (!)\ntypedef CGAL::Exact_predicates_inexact_constructions_kernel K;\n// we want to store an index with each vertex\ntypedef std::size_t                                            Index;\ntypedef CGAL::Triangulation_vertex_base_with_info_2<Index,K>   Vb;\ntypedef CGAL::Triangulation_face_base_2<K>                     Fb;\ntypedef CGAL::Triangulation_data_structure_2<Vb,Fb>            Tds;\ntypedef CGAL::Delaunay_triangulation_2<K,Tds>                  Delaunay;\n\n// As edges are not explicitly represented in the triangulation, we extract them\n// from the triangulation to be able to sort and process them. We store the\n// indices of the two endpoints, first the smaller, second the larger, and third\n// the squared length of the edge. The i-th entry, for i=0,... of a tuple t can\n// be accessed using std::get<i>(t).\ntypedef std::tuple<Index,Index,K::FT> Edge;\ntypedef std::vector<Edge> EdgeV;\n\n\n\nvoid compute_emst(std::size_t n) {\n//std::cout <<\"\\nNEW, t: \"<<n<<\"\\n\\n\";\n// read points: first, we read all points and store them into a vector,\n// together with their indices\ntypedef std::pair<K::Point_2,Index> IPoint;\nstd::vector<IPoint> points;\npoints.reserve(n);\nfor (Index i = 0; i < n; ++i) {\nint x, y;\nstd::cin >> x >> y;\n//std::cout << \"x: \"<<x<<\" - y: \"<<y<<\"\\n\";\npoints.emplace_back(K::Point_2(x, y), i);\n}\n// then we build the Delaunay triangulation in one shot, so as to leave the\n// choice of an efficient insertion order to the triangulation structure. By\n// giving the points paired with the indices, these indices are used to\n// initialize the vertex info accordingly.\n// This step takes O(n log n) time (for constructing the triangulation).\nDelaunay t;\nt.insert(points.begin(), points.end());\n\n\nint m; std::cin >> m;\nfor(int i = 0; i < m; ++i){\nint x, y;\nstd::cin >> x >> y;\nK::Point_2 new_loc(x, y);\nK::Point_2 closest = t.nearest_vertex(new_loc)->point();\nK::FT dist = CGAL::squared_distance(new_loc, closest);\nstd::cout << dist << \"\\n\";\n}\n}\n\nint main()\n{\nstd::ios_base::sync_with_stdio(false);\nstd::cout << std::setiosflags(std::ios::fixed) << std::setprecision(0);\nstd::size_t t;\nwhile(true){\nstd::cin >> t;\nif(t == 0) return 0;\ncompute_emst(t);\n}\nreturn 0;\n}",
    "link": "https://expert.ethz.ch/solve/YqyDKsHaYFBP8iZ8x"
  },
  {
    "name": "Clues",
    "aka": "Unit Disk Graph Bipartiteness + Connectivity Queries",
    "week": "Week 07",
    "methods": "IsBipartite, Strongly Connected Components",
    "status": "Learn&ShutUp",
    "problemModel": "You are given n stations as points in the plane and a communication radius r. Build the unit disk graph (UDG): an (undirected) edge exists between two stations iff their Euclidean distance is ≤ r.\nTwo tasks:\n1. Feasibility (interference constraint)\n\nCheck whether the UDG is bipartite (i.e., stations can be colored with 2 frequencies so that every interfering pair (distance ≤ r) gets different colors).\n\nIf it is not bipartite, the network is “broken” and every query answer is n.\n2. m connectivity queries\n\nEach query gives two arbitrary points a and b (Holmes/Watson). They can communicate if:\n    ◦ either a and b are directly within r, or\n    ◦ both can reach some station within r, and those two stations lie in the same connected component of the (valid) station graph.\nOutput per query: y if communication is possible, else n.\nCore underlying model: Unit disk graph bipartiteness + component connectivity with nearest-neighbor attachment queries.",
    "solutionShort": "1) Replace the full UDG by “enough edges” via Delaunay\nBuilding the full UDG is O(n2)O(n^2)O(n2). Instead:\n• Build Delaunay triangulation of the station points in O(nlog⁡n)O(n \\log n)O(nlogn).\n• Only consider Delaunay edges whose squared length ≤ r2r^2r2, and add them to a BGL graph G.\nKey fact used in these problems: for disk graphs, the Delaunay edges contain all edges necessary to preserve connectivity and to detect short-range conflicts efficiently, so you can avoid the quadratic blowup.\n2) Check bipartiteness on this sparse graph\nRun boost::is_bipartite(G, ...):\n• If false: the interference constraint cannot be satisfied → print n for every query.\n• If true: you also obtain a valid 2-coloring (stored in partition).\n3) Validate the coloring really has no same-color interference\nEven if the Delaunay-edge graph is bipartite, you must ensure there is no missing short edge (non-Delaunay) connecting two vertices of the same color within distance ≤ r.\nYour code handles this by:\n• Splitting vertices into two sets by the bipartite coloring: points_1 and points_2.\n• Building a Delaunay triangulation for each set.\n• Checking if either triangulation contains an edge of length ≤ r (meaning two same-colored points are within range) → then mark without_interference = false.\nThis is the “final safety check” that upgrades “bipartite on sparse proxy graph” into “bipartite on the real UDG”.\n4) Compute connected components once\nRun boost::connected_components(G, component_map) on the same sparse graph (Delaunay edges ≤ r).\n\nThis gives component IDs for each station.\n5) Answer each query in O(log n)\nFor each query points a and b:\n1. If !without_interference: output n.\n2. If dist(a,b) ≤ r: output y (direct communication).\n3. Find nearest stations:\n    ◦ va = nearest_vertex(a)\n    ◦ vb = nearest_vertex(b)\n4. If dist(a, va) > r or dist(b, vb) > r: output n (can’t attach to the network).\n5. Else if component_map[va] == component_map[vb]: output y, else n.\nComplexities:\n• Triangulation: O(nlog⁡n)O(n \\log n)O(nlogn)\n• Graph edges: O(n)O(n)O(n)\n• Bipartite + CC: O(n)O(n)O(n)\n• Each query: nearest neighbor + a few distance checks O(log⁡n)O(\\log n)O(logn)",
    "solution": "",
    "link": "https://expert.ethz.ch/solve/rmmZFJ7CkgFsifyTX"
  },
  {
    "name": "Germs",
    "aka": "Growing disks, event times via Delaunay triangulation and edge sorting",
    "week": "Week 07",
    "methods": "Delaunay triangulation",
    "status": "Completed",
    "problemModel": "You have n bacteria as points inside an axis-aligned rectangle. Each bacterium is a disk with initial radius 0.5 and growth radius rho(t) = t^2 + 0.5 (t in hours). A bacterium “dies” the instant it touches either (a) another bacterium or (b) the dish boundary. In the simplified simulation, bacteria keep growing even after death (so you only care about the first touch event per bacterium). Output three times (rounded up to the next integer hour): when the first bacterium dies, when alive drops below 50%, and when the last bacterium dies.",
    "solutionShort": "For each bacterium i, the death event happens when its radius reaches the smallest “blocking radius” among:\n• distance from its center to the closest dish wall, and\n• half the distance to its closest other bacterium.\n\n(Because both disks grow at the same rate and touch when 2*rho(t) equals center distance.)Candidate closest neighbors can be restricted to Delaunay edges: the nearest neighbor of a point is always among its Delaunay triangulation neighbors (so you don’t need all pairs).Build an edge list containing:\n• For each bacterium i: one “boundary edge” with weight 4 * (min wall distance)^2 (so sqrt(weight/4) equals the wall distance).\n• For each Delaunay edge (i,j): one “pair edge” with weight (center distance)^2 (so sqrt(weight/4) equals half the center distance).Sort all edges by weight increasing. Sweep them in order and assign death times:\n• When you encounter the smallest edge that involves bacterium i, that edge determines i’s first touch, so i’s death time is fixed then.\n• If the edge is between two bacteria and both are still unassigned, both die at that same time (simultaneous touch).Convert blocking radius R to time:\n• If R ≤ 0.5 → time 0\n• Else time = ceil( sqrt(R − 0.5) )\n\nThis matches rho(t)=t^2+0.5 and the required “round up to next integer hour” rule. \nthis (7)Because the sweep assigns deaths in chronological order, you can output:\n• first death = times[0]\n• “alive < 50%” moment = times[n/2]\n• last death = times[n−1]",
    "solution": "// ETH AlgoLab example code: Compute a Euclidean minimum spanning tree (EMST)\n// for n points p_0,...,p_{n-1} in O(n log n) time. Output the edges as ordered\n// pairs of vertex indices (smaller first) together with the squared length; for\n// instance, an edge between p_4=(0,0) and p_2=(1,2) is printed as \"2 4 5\".\n\n#include <CGAL/Exact_predicates_inexact_constructions_kernel.h>\n#include <CGAL/Delaunay_triangulation_2.h>\n#include <CGAL/Triangulation_vertex_base_with_info_2.h>\n#include <CGAL/Triangulation_face_base_2.h>\n#include <boost/pending/disjoint_sets.hpp>\n#include <vector>\n#include <tuple>\n#include <algorithm>\n#include <iostream>\nusing namespace std;\n#include <CGAL/Exact_predicates_exact_constructions_kernel_with_sqrt.h>\ntypedef CGAL::Exact_predicates_exact_constructions_kernel_with_sqrt K_sqrt;\n\n\n// Epic kernel is enough, no constructions needed, provided the squared distance\n// fits into a double (!)\ntypedef CGAL::Exact_predicates_inexact_constructions_kernel K;\n// we want to store an index with each vertex\ntypedef std::size_t                                            Index;\ntypedef CGAL::Triangulation_vertex_base_with_info_2<Index,K>   Vb;\ntypedef CGAL::Triangulation_face_base_2<K>                     Fb;\ntypedef CGAL::Triangulation_data_structure_2<Vb,Fb>            Tds;\ntypedef CGAL::Delaunay_triangulation_2<K,Tds>                  Delaunay;\n\n// As edges are not explicitly represented in the triangulation, we extract them\n// from the triangulation to be able to sort and process them. We store the\n// indices of the two endpoints, first the smaller, second the larger, and third\n// the squared length of the edge. The i-th entry, for i=0,... of a tuple t can\n// be accessed using std::get<i>(t).\ntypedef std::tuple<Index,Index,K::FT> Edge;\ntypedef std::vector<Edge> EdgeV;\n\ndouble ceil_to_double(const K::FT& x){\ndouble a = std::ceil(CGAL::to_double(x));\nwhile (a < x) a += 1;\nwhile (a-1 >= x) a -= 1;\nreturn a;\n}\n\nvoid compute_emst(Index n) {\nK::FT l, b, r, top; cin >> l >> b >> r >> top;\n\n// read points: first, we read all points and store them into a vector,\n// together with their indices\ntypedef std::pair<K::Point_2,Index> IPoint;\nstd::vector<IPoint> points;\npoints.reserve(n);\nEdgeV edges;\nfor (Index i = 0; i < n; ++i) {\nK::FT x, y;\nstd::cin >> x >> y;\nK::Point_2 bact(x,y);\npoints.emplace_back(K::Point_2(x, y), i);\nK::FT min_x = min(r-x,x-l);\nK::FT min_y = min(top-y,y-b);\nK::FT target_x, target_y;\nif(min_x <= min_y){\ntarget_y = y;\nif(r-x <= x-l) target_x = r;\nelse target_x = l;\n} else {\ntarget_x = x;\nif(top-y <= y-b) target_y = top;\nelse target_y = b;\n}\nedges.emplace_back(i, i+n, 4*CGAL::squared_distance(bact,K::Point_2(target_x,target_y)));\n}\n// then we build the Delaunay triangulation in one shot, so as to leave the\n// choice of an efficient insertion order to the triangulation structure. By\n// giving the points paired with the indices, these indices are used to\n// initialize the vertex info accordingly.\n// This step takes O(n log n) time (for constructing the triangulation).\nDelaunay t;\nt.insert(points.begin(), points.end());\n// extract edges and sort by (squared) length\n// This step takes O(n log n) time (for the sorting).\n\nfor (auto e = t.finite_edges_begin(); e != t.finite_edges_end(); ++e) {\nIndex i1 = e->first->vertex((e->second+1)%3)->info();\nIndex i2 = e->first->vertex((e->second+2)%3)->info();\n// ensure smaller index comes first\nif (i1 > i2) std::swap(i1, i2);\nedges.emplace_back(i1, i2, t.segment(e).squared_length());\n}\nstd::sort(edges.begin(), edges.end(),\n[](const Edge& e1, const Edge& e2) -> bool {\nreturn std::get<2>(e1) < std::get<2>(e2);\n});\n\n// Compute EMST using Kruskal's algorithm. This step takes O(n alpha(n)) time\n// in theory; for all practical purposes alpha(n) is constant, so linear time.\n\n// setup and initialize union-find data structure\nvector<K::FT> times(n,-1);\nvector<bool> isDead(n,false);\nint num_dead = 0;\nfor (EdgeV::const_iterator e = edges.begin(); e != edges.end(); ++e) {\n// determine components of endpoints\nIndex u = std::get<0>(*e);\nIndex v = std::get<1>(*e);\n\nif(u >= n && v >= n) continue;\nif(v >= n){\nif(isDead[u]) continue;\nK::FT radius = CGAL::sqrt(std::get<2>(*e)/4.0);\nK::FT time_curr;\nif(radius <= 0.5) time_curr = 0;\nelse time_curr = ceil_to_double(CGAL::sqrt(radius - 0.5));\ntimes[num_dead] = time_curr;\nisDead[u] = true;\n++num_dead;\ncontinue;\n}\nif(isDead[u] && isDead[v]) continue;\nK::FT radius = CGAL::sqrt(std::get<2>(*e)/4.0);\nK::FT time_curr;\nif(radius <= 0.5) time_curr = 0;\nelse time_curr = ceil_to_double(CGAL::sqrt(radius - 0.5));\nif(isDead[v]){\ntimes[num_dead] = time_curr;\nisDead[u] = true;\n++num_dead;\n} else if(isDead[u]){\ntimes[num_dead] = time_curr;\nisDead[v] = true;\n++num_dead;\n} else {\ntimes[num_dead] = time_curr;\nisDead[u] = true;\n++num_dead;\ntimes[num_dead] = time_curr;\nisDead[v] = true;\n++num_dead;\n}\n\nif(times[n-1] != -1) break;\n}\ncout << times[0] << \" \"<<times[n/2] << \" \"<<times[n-1];\ncout << \"\\n\";\n}\n\nint main()\n{\nstd::ios_base::sync_with_stdio(false);\nstd::cout << std::setiosflags(std::ios::fixed) << std::setprecision(0);\nIndex n; cin >> n;\nwhile(n != 0){\ncompute_emst(n);\ncin >> n;\n}\nif(cin >> n) cout << \"HFBHFIFBI\\n\";\nreturn 0;\n}",
    "link": "https://expert.ethz.ch/solve/ZH8nwxwvT9ANjNDMn"
  },
  {
    "name": "H1N1",
    "aka": "Maximum bottleneck path to a boundary (widest-path / max–min reachability)",
    "week": "Week 07",
    "methods": "Delaunay triangulation, Voronoi diagram",
    "status": "Completed",
    "problemModel": "You are given n infected people as points in the plane. For each user query (x, y, d), decide whether the user can go arbitrarily far away (escape to infinity) while never getting closer than sqrt(d) to any infected person (distance exactly sqrt(d) is allowed). Each query is independent. Output a string of ‘y’/‘n’. Constraints: n up to 6·10^4, m up to 4·10^4. \n",
    "solutionShort": "Core idea: interpret “keep distance sqrt(d)” as moving in the plane outside disks around infected points. The relevant “channels” between disks are captured by the Delaunay triangulation: moving between two neighboring Voronoi cells is blocked by the Delaunay edge between the two sites, and the clearance of that passage depends on that edge length.\n1. Build Delaunay triangulation of infected points.\n2. Work on the dual graph of faces (triangulation faces as nodes). Two faces are adjacent if they share a Delaunay edge.\n    ◦ Assign each adjacency an “edge capacity” = squared length of the shared Delaunay edge.\n    ◦ A path can pass through that face adjacency while keeping distance sqrt(d) iff the shared Delaunay edge has length ≥ 2*sqrt(d), i.e. squared length ≥ 4d.\n3. Precompute for every face f a value f.info = best bottleneck capacity to infinity:\n    ◦ Initialize all infinite faces with capacity = +infinity (you are already at the outside).\n    ◦ Run a priority-queue widest-path algorithm on faces:\n        ▪ Pop face with currently highest capacity.\n        ▪ For each neighbor across shared edge with squared length L: candidate = min(current_capacity, L).\n        ▪ If candidate improves neighbor, update it.\n\nThis yields, for each face, the maximum possible minimum-edge capacity along any route from that face to infinity.\n4. Answer each query (x, y, d):\n    ◦ Immediate fail check: if the query point is too close to the nearest infected person, you already violate the distance rule at time 0.\n        ▪ Compute squared distance to nearest_vertex(q); if it is < d, output n.\n    ◦ Otherwise locate the face containing q with t.locate(q).\n        ▪ If it’s an infinite face: output y.\n        ▪ Else: output y iff face.info >= 4d, else n.\n\nThis matches your code exactly: nearest check first, then use precomputed face “escape capacity”.",
    "solution": "//start 17:15\n#include <CGAL/Exact_predicates_inexact_constructions_kernel.h>\n#include <CGAL/Delaunay_triangulation_2.h>\n#include <CGAL/Triangulation_vertex_base_with_info_2.h>\n#include <CGAL/Triangulation_face_base_with_info_2.h>\n#include <boost/pending/disjoint_sets.hpp>\n#include <vector>\n#include <tuple>\n#include <algorithm>\n#include <iostream>\n#include <bits/stdc++.h>\nusing namespace std;\n\n// Epic kernel is enough, no constructions needed, provided the squared distance\n// fits into a double (!)\ntypedef CGAL::Exact_predicates_inexact_constructions_kernel K;\n// we want to store an index with each vertex\ntypedef std::size_t                                            Index;\ntypedef CGAL::Triangulation_vertex_base_with_info_2<Index,K>   Vb;\ntypedef CGAL::Triangulation_face_base_with_info_2<K::FT,K>     Fb;\ntypedef CGAL::Triangulation_data_structure_2<Vb,Fb>            Tds;\ntypedef CGAL::Delaunay_triangulation_2<K,Tds>                  Delaunay;\ntypedef Delaunay::Face_handle FaceHandle;\n\n// As edges are not explicitly represented in the triangulation, we extract them\n// from the triangulation to be able to sort and process them. We store the\n// indices of the two endpoints, first the smaller, second the larger, and third\n// the squared length of the edge. The i-th entry, for i=0,... of a tuple t can\n// be accessed using std::get<i>(t).\ntypedef std::tuple<Index,Index,K::FT> Edge;\ntypedef std::vector<Edge> EdgeV;\n\n\nvoid compute_emst(Index n) {\n// read points: first, we read all points and store them into a vector,\n// together with their indices\ntypedef std::pair<K::Point_2,Index> IPoint;\nstd::vector<IPoint> points;\npoints.reserve(n);\nfor (Index i = 0; i < n; ++i) {\nint x, y;\nstd::cin >> x >> y;\npoints.emplace_back(K::Point_2(x, y), i);\n}\n// then we build the Delaunay triangulation in one shot, so as to leave the\n// choice of an efficient insertion order to the triangulation structure. By\n// giving the points paired with the indices, these indices are used to\n// initialize the vertex info accordingly.\n// This step takes O(n log n) time (for constructing the triangulation).\nDelaunay t;\nt.insert(points.begin(), points.end());\n\npriority_queue<pair<K::FT,FaceHandle>> pq;\nfor(auto face = t.all_faces_begin(); face != t.all_faces_end(); ++face){\nif(t.is_infinite(face)){\npq.push({LLONG_MAX, face});\nface->info() = LLONG_MAX;\n} else {\nface->info() = -1;\n}\n}\nwhile(!pq.empty()){\nauto top = pq.top(); pq.pop();\nK::FT dad_max = top.first;\nauto f = top.second;\nfor(int i = 0; i < 3; ++i){\nauto next = f->neighbor(i);\nif(t.is_infinite(next)) continue;\nauto v1 = f->vertex((i+1)%3);\nauto v2 = f->vertex((i+2)%3);\nK::FT curr_dist = CGAL::squared_distance(v1->point(), v2->point());\nK::FT curr_max = min(dad_max, curr_dist);\nif(curr_max > next->info()){\nnext->info() = curr_max;\npq.push({curr_max, next});\n}\n}\n}\n\nIndex m; cin >> m;\nfor (Index i = 0; i < m; ++i) {\nint x, y; K::FT d;\nstd::cin >> x >> y >> d;\nK::Point_2 q(x,y);\nif(CGAL::squared_distance(q, t.nearest_vertex(q)->point()) < d){\ncout << \"n\"; continue;\n}\nauto face = t.locate(q);\nif(t.is_infinite(face)) {\ncout << \"y\"; continue;\n}\nif(face->info() >= 4*d){\ncout << \"y\";\n} else {\ncout << \"n\";\n}\n}\n}\n\nint main()\n{\nstd::ios_base::sync_with_stdio(false);\nstd::cout << std::setiosflags(std::ios::fixed) << std::setprecision(0);\nstd::size_t t; cin >> t;\nwhile(t != 0){\ncompute_emst(t); cout << \"\\n\";\ncin >> t;\n}\nif(cin >> t)cout << \"UFIUFUIFNU\\n\";\nreturn 0;\n}\n//end 17:40",
    "link": "https://expert.ethz.ch/solve/C3hPvWkdCnjCrmygW"
  },
  {
    "name": "Worm Kingdom",
    "aka": "Balanced partition via subset-sum with one allowable split",
    "week": "Week 07",
    "methods": "SubsetSum, Tree DP",
    "status": "ASK SOLUTION",
    "problemModel": "There are k burrows. Each burrow is a tree of rooms with sizes sr. You must partition all rooms into two groups W and G such that: (1) both groups are non-empty, (2) each group is connected, and (3) there is exactly one tunnel between W and G. You may build new tunnels at cost p each. Minimize:\nabsolute(total_size(W) − total_size(G)) + p · (#new tunnels built).",
    "solutionShort": "\n1. Observation about tunnel cost: Any valid “nice partition” needs exactly k−1 new tunnels overall (to connect components inside W and inside G, plus ensure exactly one cross-connection), so the term p*(k−1) is constant; optimization reduces to minimizing the size difference. \nthis (5)\n2. What choices exist inside each burrow (tree):\n\nBecause each burrow is a tree, if a burrow is “split” between W and G while keeping both sides connected and allowing only one cross-tunnel overall, then the split must be along one tree edge, producing two connected parts with sums sum(subtree) and total-sum(subtree). All other burrows can be assigned wholly to one side.\n3. Subset-sum DP over achievable W-sums:\n\nLet S = total sum of all room sizes. Target is to find a W-sum as close as possible to S/2.\nMaintain two boolean DP arrays up to S/2:\n• dp_whole[x]: achievable W-sum x using only whole burrows so far.\n• dp_split[x]: achievable W-sum x where we may have used (or may still use) one split in some burrow.\nFor each burrow i with total total[i]:\n• Add the option “take the whole burrow into W” to both DP layers.\n• Run a DFS to compute every subtree sum sum in that burrow. For each edge-cut producing parts (sum, total[i]-sum), add both options into dp_split (since this represents choosing which side of the cut goes to W). This is exactly what the dfs() + add_to_dp(dp_split, dp_whole, sum/other_sum) does.\n1. Pick best achievable sum:\n\nScan dp_split[j] for j from floor(S/2) down to 0 and take the best (closest to half). The minimal difference is S − 2*j. Final answer is (S − 2*j) + p*(k−1).",
    "solution": "#include <bits/stdc++.h>\n\nvoid solve() {\nint k, p; std::cin >> k >> p;\nstd::vector<std::vector<std::vector<int>>> burrows(k);\nstd::vector<std::vector<int>> rooms(k);\nstd::vector<int> total(k);\nint sumsum = 0;\nfor (int i = 0; i < k; i++) {\nint n; std::cin >> n;\nburrows[i].resize(n);\nrooms[i].resize(n);\nfor (int j = 0; j < (int)rooms[i].size()-1; j++) {\nint u, v; std::cin >> u >> v;\nburrows[i][u].push_back(v); // don't need back edge\n}\ntotal[i] = 0;\nfor (int j = 0; j < (int)rooms[i].size(); j++) {\nstd::cin >> rooms[i][j];\ntotal[i] += rooms[i][j];\n}\nsumsum += total[i];\n}\n\nint sz = sumsum/2+1;\nstd::vector<bool> dp_whole(sz, 0);\nstd::vector<bool> dp_split(sz, 0);\ndp_whole[0] = dp_split[0] = 1;\n\nauto add_to_dp = [&](std::vector<bool> &dp1, std::vector<bool> &dp2, int val)  {\nfor (int j = sz-val-1; j >= 0; j--) {\ndp1[j+val] = dp1[j+val] || dp2[j];\n}\n};\n\nstd::function<int(int,int)> dfs = [&](int i, int v) -> int {\nint sum = rooms[i][v];\nfor (auto u: burrows[i][v]) {\nsum += dfs(i, u);\n}\nint other_sum = total[i]-sum;\nif (other_sum) {\nadd_to_dp(dp_split, dp_whole, sum);\nadd_to_dp(dp_split, dp_whole, other_sum);\n}\nreturn sum;\n};\n\nfor (int i = 0; i < k; i++) {\nadd_to_dp(dp_split, dp_split, total[i]);\ndfs(i, 0);\nadd_to_dp(dp_whole, dp_whole, total[i]);\n}\n\nfor (int j = sz-1; j >= 0; j--) {\nif (dp_split[j]) {\nstd::cout << (sumsum - 2j) + p(k-1) << \"\\n\";\nreturn;\n}\n}\n\n}\n\nint main() {\nstd::ios::sync_with_stdio(0);\nint t; std::cin >> t;\nwhile (t--) solve();\nreturn 0;\n}",
    "link": "https://expert.ethz.ch/solve/YoBdn38gMPdHN2J8z"
  },
  {
    "name": "Casterly Rock",
    "aka": "LP feasibility + minimax optimization with shared slope coupling",
    "week": "Week 08",
    "methods": "Line Separation, Linear Programming",
    "status": "Completed",
    "problemModel": "You must place two infinite straight “canals” that cross at 90°. Each house connects to the sewer canal with a horizontal pipe and to the water canal with a vertical pipe. Constraints:\n1. Sewer line must separate points: all nobles on one side (or on the line) and all commoners on the other side.\n2. Total length of all sewer pipes (horizontal distances to sewer line) ≤ s (or s = ∞ if input −1).\n\nGoal: among all valid layouts, minimize the maximum length of a water pipe (vertical distance to water line), output rounded up.",
    "solutionShort": "Use a coupled parameter b to enforce the right angle between lines:\n• Sewer canal: x + b*y + c = 0\n\nHorizontal sewer pipe length from house (x,y) is |x + b*y + c|.\n\nCersei constraint becomes linear if you force the sign:\n    ◦ nobles: x + b*y + c ≤ 0\n    ◦ commons: x + b*y + c ≥ 0\n\nYour code writes these as b*y + c ≤ -x and -b*y - c ≤ x.\n1. Check Cersei separability (variables b,c only).\n\nIf infeasible → output “Y”.\n2. Add Tywin budget (if s != −1).\n\nBecause the signs are fixed, the absolute values drop and the total sewer length becomes:\n(sum_common(x + b*y + c)) - (sum_noble(x + b*y + c)) ≤ s\n\nwhich is exactly the linear constraint you add using the precomputed sums.\n\nIf infeasible → output “B”.\n• Water canal (perpendicular to sewer): y = b*x + K\n\nVertical water pipe length is |y - (b*x + K)|.\n\nIntroduce variable L and enforce for every house:\ny - L ≤ b*x + K ≤ y + L\n\n(your two inequalities with K and L).\n\nMinimize L with L ≥ 0. Output ceil(L) (your floor_to_double helper actually computes a safe ceiling).",
    "solution": "",
    "link": "https://expert.ethz.ch/solve/xZ3HkmRgcMPuQFj47"
  },
  {
    "name": "Maximize it!",
    "aka": "Parametric linear programming with feasibility/unboundedness detection",
    "week": "Week 08",
    "methods": "Linear Programming",
    "status": "Completed",
    "problemModel": "For each test case you get p a b with p ∈ {1,2} and parameters a,b. You must output the optimal value of one of two small LPs, or no if infeasible, or unbounded if the objective can grow without bound (or decrease without bound for minimization). For type 1, round the optimum down; for type 2, round it up. \nthis (11)\n• (1) Maximization: maximize b*y − a*x\n\nsubject to x,y ≥ 0, x+y ≤ 4, 4x+2y ≤ a*b, −x+y ≤ 1. \nthis (11)\n• (2) Minimization: minimize a*x + b*y + z\n\nsubject to x,y,z ≤ 0, x+y ≥ −4, 4x+2y+z ≥ −a*b, −x+y ≥ −1.",
    "solutionShort": "CGAL’s solver minimizes with constraints of the form A x ≤ b, so both problems are rewritten into that standard form.\n",
    "solution": "// example: how to solve a simple explicit LP\n#include <CGAL/QP_models.h>\n#include <CGAL/QP_functions.h>\n#include <CGAL/Gmpz.h>\n#include <bits/stdc++.h>\nusing namespace std;\n\n// choose input type (input coefficients must fit)\ntypedef int IT;\n// choose exact type for solver (CGAL::Gmpz or CGAL::Gmpq)\ntypedef CGAL::Gmpz ET;\n\n// program and solution types\ntypedef CGAL::Quadratic_program<IT> Program;\ntypedef CGAL::Quadratic_program_solution<ET> Solution;\n\nvoid solve(int p){\nint a, b; cin >> a >> b;\nif(p == 1){\nProgram lp (CGAL::SMALLER, true, 0, false, 0);\n\n// set the coefficients of A and b\nconst int X = 0;\nconst int Y = 1;\nlp.set_a(X, 0,  1); lp.set_a(Y, 0, 1); lp.set_b(0, 4);  //  x + y  <= 7\nlp.set_a(X, 1, 4); lp.set_a(Y, 1, 2); lp.set_b(1, ab);  // -x + 2y <= 4\nlp.set_a(X, 2, -1); lp.set_a(Y, 2, 1); lp.set_b(2, 1);\n// set upper bound\n// objective function\nlp.set_c(Y, -b);\nlp.set_c(X, a);\n\n// solve the program, using ET as the exact type\nSolution s = CGAL::solve_linear_program(lp, ET());\nassert(s.solves_linear_program(lp));\n\nif(s.is_infeasible()) cout << \"no\";\nelse if(s.is_unbounded()) cout << \"unbounded\";\nelse{\ndouble res = floor(CGAL::to_double(-s.objective_value()));\ncout << res;\n}\n} else {\nProgram lp (CGAL::SMALLER, false, 0, true, 0);\n\n// set the coefficients of A and b\nconst int X = 0;\nconst int Y = 1;\nconst int Z = 2;\nlp.set_a(X, 0,  -1); lp.set_a(Y, 0, -1); lp.set_b(0, 4);  //  x + y  <= 7\nlp.set_a(X, 1, -4); lp.set_a(Y, 1, -2); lp.set_a(Z, 1, -1); lp.set_b(1, ab);  // -x + 2y <= 4\nlp.set_a(X, 2, 1); lp.set_a(Y, 2, -1); lp.set_b(2, 1);\n// set upper bound\n// objective function\nlp.set_c(Y, b);\nlp.set_c(X, a);\nlp.set_c(Z, 1);\n\n// solve the program, using ET as the exact type\nSolution s = CGAL::solve_linear_program(lp, ET());\nassert(s.solves_linear_program(lp));\n\nif(s.is_infeasible()) cout << \"no\";\nelse if(s.is_unbounded()) cout << \"unbounded\";\nelse{\nint res = ceil(CGAL::to_double(s.objective_value()));\ncout << res;\n}\n}\n// create an LP with Ax <= b, lower bound 0 and no upper bounds\n\n}\n\nint main(){\nios_base::sync_with_stdio(0);\nint p; cin >> p;\nwhile(p != 0){\nsolve(p); cout << \"\\n\";\ncin >> p;\n}\nif(cin >> p) cout << \"IJFIFB\\n\";\nreturn 0;\n}\n",
    "link": "https://expert.ethz.ch/solve/6r6xAmSD2XwK7TgpE"
  },
  {
    "name": "Diet",
    "aka": "Linear programming with interval constraints (min-cost feasible vector)",
    "week": "Week 08",
    "methods": "Linear Programming",
    "status": "Completed",
    "problemModel": "Given n nutrients, each must be consumed between mini and maxi per day. There are m foods; food j costs pj per unit and provides Cj,i units of nutrient i per unit. Choose nonnegative (fractional) amounts of foods to minimize total cost while meeting all nutrient intervals. Output the minimum cost rounded down, or No such diet. if infeasible.",
    "solutionShort": "Let decision variables be xj ≥ 0 = amount of food j.\nFor each nutrient i you need:\n• sum_j Cj,i * xj ≥ mini\n• sum_j Cj,i * xj ≤ maxi\nCGAL expects constraints as A x ≤ b, so:\n• Lower bound becomes: -sum_j Cj,i * xj ≤ -mini\n• Upper bound stays: sum_j Cj,i * xj ≤ maxi\nObjective:\n• minimize sum_j pj * xj\nSolve LP with CGAL.\n• If infeasible or unbounded: print No such diet. (unbounded won’t really occur here because costs are minimized with x ≥ 0, but the check is fine).\n• Else print floor(optimal_cost).",
    "solution": "//start 20:07\n//floor res\n// example: how to solve a simple explicit LP\n#include <CGAL/QP_models.h>\n#include <CGAL/QP_functions.h>\n#include <CGAL/Gmpq.h>\n#include <bits/stdc++.h>\nusing namespace std;\n// choose input type (input coefficients must fit)\ntypedef double IT;\n// choose exact type for solver (CGAL::Gmpz or CGAL::Gmpq)\ntypedef CGAL::Gmpq ET;\n\n// program and solution types\ntypedef CGAL::Quadratic_program<IT> Program;\ntypedef CGAL::Quadratic_program_solution<ET> Solution;\n\nvoid solve(int n, int m){\n// create an LP with Ax <= b, lower bound 0 and no upper bounds\nProgram lp (CGAL::SMALLER, true, 0, false, 0);\nfor(int i = 0; i < n; ++i){\ndouble mini, maxi; cin >> mini >> maxi;\nlp.set_b(i, -mini);\nlp.set_b(i+n, maxi);\n}\nfor(int i = 0; i < m; ++i){\ndouble pi; cin >> pi;\nlp.set_c(i, pi);\nfor(int j = 0; j < n; ++j){\ndouble nutj; cin >> nutj;\nlp.set_a(i, j, -nutj);\nlp.set_a(i, j+n, nutj);\n}\n}                                 // +64\n\n// solve the program, using ET as the exact type\nSolution s = CGAL::solve_linear_program(lp, ET());\nassert(s.solves_linear_program(lp));\nif(s.is_infeasible() || s.is_unbounded()) cout << \"No such diet.\";\nelse {\nauto res = floor(CGAL::to_double(s.objective_value()));\ncout << res;\n}\n}\n\nint main(){\nios_base::sync_with_stdio(false);\nint n, m; cin >> n >> m;\nwhile(!(n == 0 && m == 0)){\nsolve(n,m); cout << \"\\n\";\ncin >> n >> m;\n}\nif(cin >> n) cout << \"jifwif\\n\";\n}\n//end 20:24",
    "link": "https://expert.ethz.ch/solve/xghhJjmyE7SGqWvCe"
  },
  {
    "name": "Inball",
    "aka": "Maximum-margin feasibility LP (largest inscribed ball in a polyhedron)",
    "week": "Week 08",
    "methods": "Linear Programming",
    "status": "Completed",
    "problemModel": "A cave is a convex polyhedron in d dimensions given by n linear inequalities a_i^T x ≤ b_i. Find the maximum integer radius r of a d-dimensional ball that fits entirely inside the cave. Output none if the cave is empty, inf if the ball can be arbitrarily large, else the maximum integer r.",
    "solutionShort": "A ball of radius r centered at x fits in the cave iff it stays inside every halfspace.\n\nFor one inequality a^T x ≤ b, the worst point of the ball in direction a is at distance r * ||a|| along a, so the constraint becomes:\na^T x + r * ||a|| ≤ b\nDecision variables: the center coordinates x1..xd (free) and the radius r (with r ≥ 0).\n\nObjective: maximize r.\nCGAL solves minimization with ≤, so you set:\n• Variables 0..d−1 = x-coordinates (unbounded)\n• Variable d = r, with lower bound 0\n• For each constraint i: set coefficients a_ij on xj, and ||a_i|| on r, RHS b_i.\n• Set objective c_r = -1 (minimize −r == maximize r).\nThen:\n• If infeasible → none (cave empty)\n• If unbounded → inf (radius can grow arbitrarily)\n• Else optimal r* exists; output floor(r*) because you need the maximum integer radius.",
    "solution": "//start 20:33\n// example: how to solve a simple explicit LP\n#include <CGAL/QP_models.h>\n#include <CGAL/QP_functions.h>\n#include <CGAL/Gmpz.h>\n#include <bits/stdc++.h>\nusing namespace std;\n\n// choose input type (input coefficients must fit)\ntypedef long IT;\n// choose exact type for solver (CGAL::Gmpz or CGAL::Gmpq)\ntypedef CGAL::Gmpz ET;\n\n// program and solution types\ntypedef CGAL::Quadratic_program<IT> Program;\ntypedef CGAL::Quadratic_program_solution<ET> Solution;\n\nvoid solve(int n){\nint d; cin >> d;\n// create an LP with Ax <= b, lower bound 0 and no upper bounds\nProgram lp (CGAL::SMALLER, false, 0, false, 0);\nfor(int i = 0; i < n; ++i){\nlong long norm = 0;\nfor(int j = 0; j < d; ++j){\nlong  ai; cin >> ai;\nnorm += ai*ai;\nlp.set_a(j, i, ai);\n}\nlp.set_a(d, i, sqrt(norm));\nlong  bi; cin >> bi;\nlp.set_b(i, bi);\n}\nlp.set_l(d,true,0);\nlp.set_c(d, -1);\n\n// solve the program, using ET as the exact type\nSolution s = CGAL::solve_linear_program(lp, ET());\nassert(s.solves_linear_program(lp));\n\nif(s.is_infeasible()) cout << \"none\";\nelse if(s.is_unbounded()) cout << \"inf\";\nelse {\ndouble res = floor(CGAL::to_double(-s.objective_value()));\ncout << res;\n}\n\n}\n\nint main(){\nios_base::sync_with_stdio(false);\nint n; cin >> n;\nwhile(n != 0){\nsolve(n); cout << \"\\n\";\ncin >> n;\n}\nif(cin >> n) cout << \"RJIUUIR\\n\";\n}\n//end 20:52",
    "link": "https://expert.ethz.ch/solve/or7p8ot669xWDfphZ"
  },
  {
    "name": "Kingdom Defense",
    "aka": "Feasible circulation with lower/upper bounds via max flow",
    "week": "Week 08",
    "methods": "Circulation Problem, MaxFlow",
    "status": "Completed",
    "problemModel": "You have a directed network of locations. Location i starts with gi soldiers and must end with at least di soldiers. Each directed path j = (f→t) must be traversed between cj and Cj times (a traversal corresponds to sending 1 unit of “soldier flow” along that arc; soldiers may traverse multiple times). Decide if there exists a movement plan satisfying all node defense requirements and all edge min/max traversal constraints. Output yes/no. \n",
    "solutionShort": "\n1. Convert node requirements into balances.\n\nStart with balance[i] = gi − di.\n\nPositive means net supply can leave; negative means net inflow is needed.\n2. Remove lower bounds on edges.\n\nFor each directed edge u→v with lower cmin and upper cmax:\n• Force the lower bound by “pre-sending” cmin units:\n    ◦ balance[u] -= cmin\n    ◦ balance[v] += cmin\n• Add a residual-capacity edge u→v with capacity (cmax − cmin).\n1. Build a standard max-flow feasibility check.\n\nAdd super source S and super sink T:\n• If balance[i] > 0 (net supply), add S → i with capacity balance[i].\n• If balance[i] < 0 (net demand), add i → T with capacity −balance[i] and accumulate tot_req += −balance[i].\n\nRun max flow from S to T. Feasible iff flow == tot_req.\nWhy equality matters: after lower-bound adjustment, total supply must exactly cover total demand through the directed residual network; otherwise some node requirement or min-traversal constraint cannot be satisfied.",
    "solution": "// start: 19:45\n\n// Algolab BGL Tutorial 2 (Max flow, by mailto:taubnert@ethz.ch)\n// Flow example demonstrating how to use push_relabel_max_flow using a custom edge adder\n// to manage the interior graph properties required for flow algorithms\n#include <iostream>\n#include <bits/stdc++.h>\nusing namespace std;\n// BGL include\n#include <boost/graph/adjacency_list.hpp>\n\n// BGL flow include NEW\n#include <boost/graph/push_relabel_max_flow.hpp>\n\n// Graph Type with nested interior edge properties for flow algorithms\ntypedef boost::adjacency_list_traits<boost::vecS, boost::vecS, boost::directedS> traits;\ntypedef boost::adjacency_list<boost::vecS, boost::vecS, boost::directedS, boost::no_property,\nboost::property<boost::edge_capacity_t, long,\nboost::property<boost::edge_residual_capacity_t, long,\nboost::property<boost::edge_reverse_t, traits::edge_descriptor>>>> graph;\n\ntypedef traits::vertex_descriptor vertex_desc;\ntypedef traits::edge_descriptor edge_desc;\n\n// Custom edge adder class, highly recommended\nclass edge_adder {\ngraph &G;\n\npublic:\nexplicit edge_adder(graph &G) : G(G) {}\n\nvoid add_edge(int from, int to, long capacity) {\nauto c_map = boost::get(boost::edge_capacity, G);\nauto r_map = boost::get(boost::edge_reverse, G);\nconst auto e = boost::add_edge(from, to, G).first;\nconst auto rev_e = boost::add_edge(to, from, G).first;\nc_map[e] = capacity;\nc_map[rev_e] = 0; // reverse edge has no capacity!\nr_map[e] = rev_e;\nr_map[rev_e] = e;\n}\n};\n\nvoid make_it_flow() {\nint l, p; cin >> l >> p;\nvector<long> soldiers(l,0);\nfor(int i = 0; i < l; ++i){\nlong gi, di; cin >> gi >> di;\nsoldiers[i] = gi-di;\n}\ngraph G(l);\nedge_adder adder(G);\nfor(int i = 0; i < p;  ++i){\nint u, v; long cmin, cmax;\ncin >> u >> v >> cmin >> cmax;\nsoldiers[u] -= cmin;\nsoldiers[v] += cmin;\nadder.add_edge(u, v, cmax-cmin);\n}\n\nconst vertex_desc v_source = boost::add_vertex(G);\nconst vertex_desc v_sink = boost::add_vertex(G);\nlong tot_req = 0;\nfor(int i = 0; i < l; ++i){\nif(soldiers[i] > 0) adder.add_edge(v_source, i, soldiers[i]);\nelse if(soldiers[i] < 0) {\nadder.add_edge(i, v_sink, -soldiers[i]);\ntot_req += -soldiers[i];\n}\n}\n\n\nlong flow = boost::push_relabel_max_flow(G, v_source, v_sink);\nif(flow == tot_req) cout << \"yes\";\nelse cout << \"no\";\n\n}\n\nint main() {\nios_base::sync_with_stdio(false);\nint t; cin >> t;\nwhile(t--){\nmake_it_flow(); cout << \"\\n\";\n}\nif(cin >> t) cout << \"DBIFBIF\\n\";\n\n\nreturn 0;\n}\n//end 19:52",
    "link": "https://expert.ethz.ch/solve/8CzNn6Y4KYHSNAANY"
  },
  {
    "name": "Real Estate Market",
    "aka": "",
    "week": "Week 09",
    "methods": "MinCostMaxFlow",
    "status": "Completed",
    "problemModel": "N buyers making one offer for each of the M houses\nM houses disposed in S different sets\nEach set has a max # of sellable houses\n\nComputer max # of house sold to maximize profit  ",
    "solutionShort": "3 layered graph\n0) Source → buyers, cap:1, cost:0\n1) N buyers connecting to each house with cap:1, cost:(MO-offer)\n2) M houses connecting to S sets with cap:1, cost: 0\n3) S sets connecting to sink with cap: Limit_i, cost:0\n\ntot_cost = MO*flow_tot - cost",
    "solution": "",
    "link": "https://expert.ethz.ch/solve/vBDRyxYKEfxiZ8HRG"
  },
  {
    "name": "Placing Knights",
    "aka": "Maximum Independent Set of a Bipartite Graph",
    "week": "Week 09",
    "methods": "Bipartite Graphs, Maximum Independent Set",
    "status": "Completed",
    "problemModel": "In a grid nxn find the max number of knights not attaching each other",
    "solutionShort": "Maximum Independent Set (NP)\nBut the grid is a bipartite graph (black/white cell) so:\n1) Edge in Maximum Matching == Minimum Vertex Cover\n2) Max Indp. Set = V / MVC\n\np.s. Max flow == max matching in bipartite graphs",
    "solution": "",
    "link": "https://expert.ethz.ch/solve/G3QrEzWEByurx8PBC"
  },
  {
    "name": "Canteen",
    "aka": "MinCostMaxFlow + MaxCostMaxFlow",
    "week": "Week 09",
    "methods": "MinCostMaxFlow",
    "status": "Completed",
    "problemModel": "N produces buying quantity qi at cost ci\nN consumer buy from each producer, each for a quantity si and prize pi\n\nIf one consumer has more product than required, it could give to the producer to its right for a max quantity fi and a cost ei so that the next producer can decide to buy from it instead of the market",
    "solutionShort": "MinCostMaxFlow\nOne layer of N nodes, connected to source and sink adding the relative buy and sell, and n-1 each node to its right node\n\nThe problem is how to not write negative cost, put the price for selling MAX-pi, and the cost: ci\n\nHOW TO AVOID NEGATIVE COST:\n1) if a quantity is to minimize: leave it unchanged\n2) else if is to maximize, put MAX_of_it - qi\n\nif you have different things to maximize, use the MAX of all of them\n\nP.S. This technique works only iff in all paths we apply this shift the same number of times.\n\nLike here we apply it only at the end, one final edge, it’s impossible to cross more edges with that shift.\n\nFor example we could not use that shift between producers, because the flow could follow different paths, if not use the one with negative costs",
    "solution": "// ALGOLAB BGL Tutorial 3\n// Code demonstrating\n// - MinCostMaxFlow with arbitrary edge costs using cycle_canceling\n// - MinCostMaxFlow with non-negative edge costs using successive_shortest_path_nonnegative_weights\n\n#include <iostream>\n#include <boost/graph/adjacency_list.hpp>\n#include <boost/graph/cycle_canceling.hpp>\n#include <boost/graph/push_relabel_max_flow.hpp>\n#include <boost/graph/successive_shortest_path_nonnegative_weights.hpp>\n#include <boost/graph/find_flow_cost.hpp>\nusing namespace std;\n\n// graph Type with nested interior edge properties for Cost Flow Algorithms\ntypedef boost::adjacency_list_traits<boost::vecS, boost::vecS, boost::directedS> traits;\ntypedef boost::adjacency_list<boost::vecS, boost::vecS, boost::directedS, boost::no_property,\nboost::property<boost::edge_capacity_t, long,\nboost::property<boost::edge_residual_capacity_t, long,\nboost::property<boost::edge_reverse_t, traits::edge_descriptor,\nboost::property <boost::edge_weight_t, long> > > > > graph; // new! weightmap corresponds to costs\n\ntypedef boost::graph_traits<graph>::edge_descriptor             edge_desc;\ntypedef boost::graph_traits<graph>::out_edge_iterator           out_edge_it; // Iterator\n\n// custom edge adder class\nclass edge_adder {\ngraph &G;\n\npublic:\nexplicit edge_adder(graph &G) : G(G) {}\nvoid add_edge(int from, int to, long capacity, long cost) {\nauto c_map = boost::get(boost::edge_capacity, G);\nauto r_map = boost::get(boost::edge_reverse, G);\nauto w_map = boost::get(boost::edge_weight, G); // new!\nconst edge_desc e = boost::add_edge(from, to, G).first;\nconst edge_desc rev_e = boost::add_edge(to, from, G).first;\nc_map[e] = capacity;\nc_map[rev_e] = 0; // reverse edge has no capacity!\nr_map[e] = rev_e;\nr_map[rev_e] = e;\nw_map[e] = cost;   // new assign cost\nw_map[rev_e] = -cost;   // new negative cost\n}\n};\n\nvoid solve(){\nint n; cin >> n;\ngraph G(n + 2); // n + 2\nedge_adder adder(G);\nconst int v_source = n;\nconst int v_target = n+1;\nfor(int i = 0; i < n; ++i){\nint a, c; cin >> a >> c;\nadder.add_edge(v_source, i, a, c);\n}\nconst int MAX_COST = 20;\nlong long totStudents = 0;\nfor(int i = 0; i < n; ++i){\nint s, p; cin >> s >> p;\ntotStudents += s;\nadder.add_edge(i, v_target, s, MAX_COST - p);\n}\nfor(int i = 0; i+1 < n; ++i){\nint v, e; cin >> v >> e;\nadder.add_edge(i, i+1, v, e);\n}\n\n\nauto c_map = boost::get(boost::edge_capacity, G);\nauto rc_map = boost::get(boost::edge_residual_capacity, G);\n\n// run the algorithm\n\n// Option 2: Min Cost Max Flow with successive_shortest_path_nonnegative_weights\nboost::successive_shortest_path_nonnegative_weights(G, v_source, v_target);\nlong long cost2 = boost::find_flow_cost(G);\n// iterate over all edges leaving the source to sum up the flow values\n\n// or, equivalently, sum at the sink with reversed edges\nlong long t_flow = 0;\nout_edge_it e, eend;\nfor (boost::tie(e, eend) = boost::out_edges(boost::vertex(v_target,G), G); e != eend; ++e) {\nlong long selled = rc_map[*e] - c_map[e];\nt_flow += selled;\n}\n\nif(t_flow < totStudents){\ncout << \"impossible\";\n} else cout <<\"possible\";\ncout << \" \";\ncout << t_flow << \" \" << t_flowMAX_COST - cost2;\n}\n\nint main(){\nios_base::sync_with_stdio(false);\nint t; cin >> t;\nwhile(t--){\nsolve(); cout << \"\\n\";\n}\nif(cin >> t) cout<<\"ERORR\\n\";\n}",
    "link": "https://expert.ethz.ch/solve/WqAAoh9eCqGpxvkJ4"
  },
  {
    "name": "Algocoon",
    "aka": "We want to cut the graph with the min cost",
    "week": "Week 09",
    "methods": "Minimum Cut",
    "status": "Completed",
    "problemModel": "We have n nodes and m undirected edges.\nEach edge has an associated cost that need to be payed to cut it.\n\nwe want the find the min cost to cut the graph in 2 arbitrary parts (having at least 1 node each)",
    "solutionShort": "Fix a node, then run maxflow (mincut) from that node (0) to the other n-1 nodes.\nRun also the max flow from 0→x, x→0 and take the min.\n\nWhy we need also the viceversa? Because the edges are directed, if they were undirected then we would have to split the cost in 2 edge and run just one maxflow",
    "solution": "#include <iostream>\n#include <climits>\n#include <boost/graph/adjacency_list.hpp>\n#include <boost/graph/push_relabel_max_flow.hpp>\n\ntypedef boost::adjacency_list_traits<boost::vecS, boost::vecS, boost::directedS> traits;\ntypedef boost::adjacency_list<boost::vecS, boost::vecS, boost::directedS, boost::no_property,\nboost::property<boost::edge_capacity_t, long,\nboost::property<boost::edge_residual_capacity_t, long,\nboost::property<boost::edge_reverse_t, traits::edge_descriptor>>>> graph;\n\ntypedef traits::vertex_descriptor vertex_desc;\ntypedef traits::edge_descriptor edge_desc;\n\nclass edge_adder {\ngraph &G;\n\npublic:\nexplicit edge_adder(graph &G) : G(G) {}\n\nvoid add_edge(int from, int to, long capacity) {\nauto c_map = boost::get(boost::edge_capacity, G);\nauto r_map = boost::get(boost::edge_reverse, G);\nconst auto e = boost::add_edge(from, to, G).first;\nconst auto rev_e = boost::add_edge(to, from, G).first;\nc_map[e] = capacity;\nc_map[rev_e] = 0;\nr_map[e] = rev_e;\nr_map[rev_e] = e;\n}\n};\n\nvoid solve(){\nint n, m; std::cin >> n >> m;\ngraph G(n); edge_adder adder(G);\nfor (int i = 0; i < m; i++){\nint a, b, c; std::cin >> a >> b >> c;\nadder.add_edge(a, b, c);\n}\nlong min_cut = LONG_MAX;\nfor (int i = 1; i < n; i++){\nlong ff = boost::push_relabel_max_flow(G, 0, i);\nlong fb = boost::push_relabel_max_flow(G, i, 0);\nmin_cut = std::min({min_cut, ff, fb});\n}\nstd::cout << min_cut << '\\n';\n}\n\nint main(){\nstd::ios_base::sync_with_stdio(false);\nint t; std::cin >> t;\nwhile(t--) solve();\n}",
    "link": "https://expert.ethz.ch/solve/HQoQis2MLWtvNKt44"
  },
  {
    "name": "Idefix",
    "aka": "Connectivity-threshold sweep in geometric disk graphs (Delaunay + union-find)",
    "week": "Week 09",
    "methods": "Delaunay triangulation, EMST, Union Find",
    "status": "Rewrite it",
    "problemModel": "You have n center points (trees) and m item points (bones). A walk is allowed only inside the union of equal-radius disks centered at the n points.\n\nYou must output:\n1. a = the maximum number of item points that can be visited in a single walk (i.e., within one connected component of the union) using the given radius r (input provides s = 4r²).\n2. q = 4b² where b is the smallest radius that makes it possible to visit at least k item points in one walk. ",
    "solutionShort": "Model the union-of-disks connectivity as a disk graph: two trees are connected when their disks overlap, i.e. when squared center distance dist² ≤ (2r)², which equals dist² ≤ s because s = 4r².\n1. Build Delaunay triangulation on tree centers.\n\nDisk-graph edges that matter for connectivity changes appear among Delaunay edges (sparse O(n)).\n2. Create an edge list and sort by “required radius” (as squared threshold):\n• For every Delaunay edge (u,v): add edge with weight dist²(u,v) (this is the threshold on 4r² for disks to overlap).\n• For every bone point x: connect it to the nearest tree u and add edge (u, bone) with weight 4*dist²(u,x).\n\nThis works because if a bone is within radius r of any tree, then it’s within radius r of its nearest tree; and if multiple trees are within r, they must be in the same connected disk component anyway.\n1. Sweep edges in increasing weight with DSU on tree nodes, carrying “bone count per component”:\n• If the current edge is tree–tree, union the components and sum their bone counts.\n• If the current edge is tree–bone, increment the bone count of that tree’s current component.\n1. Answer (a):\n\nWhile edge weight ≤ s (given radius), track the maximum bone count across components → that’s a.\n2. Answer (q = 4b²):\n\nDuring the same sweep, the first time any component reaches bone count ≥ k, record the current edge weight as q (minimal threshold where it becomes possible).",
    "solution": "#include <bits/stdc++.h>\n#include <CGAL/Exact_predicates_inexact_constructions_kernel.h>\n#include <CGAL/Delaunay_triangulation_2.h>\n#include <CGAL/Triangulation_vertex_base_with_info_2.h>\n#include <CGAL/Triangulation_face_base_2.h>\n#include <boost/pending/disjoint_sets.hpp>\n\ntypedef CGAL::Exact_predicates_inexact_constructions_kernel K;\ntypedef CGAL::Triangulation_vertex_base_with_info_2<int,K>   Vb;\ntypedef CGAL::Triangulation_face_base_2<K>                     Fb;\ntypedef CGAL::Triangulation_data_structure_2<Vb,Fb>            Tds;\ntypedef CGAL::Delaunay_triangulation_2<K,Tds>                  Delaunay;\ntypedef K::Point_2 P;\ntypedef std::tuple<int,int,K::FT> Edge;\ntypedef std::vector<Edge> EdgeV;\ntypedef std::pair<K::Point_2,int> IPoint;\n\nvoid solve() {\nint n, m, k; long s; std::cin >> n >> m >> s >> k;\nstd::vector<IPoint> points;\npoints.reserve(n);\nfor (int i = 0; i < n; ++i) {\nint x, y; std::cin >> x >> y;\npoints.emplace_back(P(x, y), i);\n}\nDelaunay t;\nt.insert(points.begin(), points.end());\nEdgeV edges_ext;\nedges_ext.reserve(m);\nstd::vector<int> sizes(n, 0);\nfor (int i = 0; i < m; i++) {\nint x, y; std::cin >> x >> y;\nauto v = t.nearest_vertex(P(x, y));\nK::FT dis  = 4CGAL::squared_distance(v->point(), P(x, y));\nif (dis <= s) sizes[v->info()]++;\nedges_ext.emplace_back(v->info(), n + i, dis);\n}\nEdgeV edges;\nedges.reserve(3n);\nfor (auto e = t.finite_edges_begin(); e != t.finite_edges_end(); ++e) {\nint i1 = e->first->vertex((e->second+1)%3)->info();\nint i2 = e->first->vertex((e->second+2)%3)->info();\nif (i1 > i2) std::swap(i1, i2);\nedges.emplace_back(i1, i2, t.segment(e).squared_length());\n}\nstd::sort(edges.begin(), edges.end(),\n[](const Edge& e1, const Edge& e2) -> bool {\nreturn std::get<2>(e1) < std::get<2>(e2);\n});\nboost::disjoint_sets_with_storage<> uf(n);\nint n_components = n;\nfor (EdgeV::const_iterator e = edges.begin(); e != edges.end(); ++e) {\nint c1 = uf.find_set(std::get<0>(*e));\nint c2 = uf.find_set(std::get<1>(*e));\nK::FT dis = std::get<2>(*e);\nif (dis <= s && c1 != c2) {\nint s1 = sizes[c1], s2 = sizes[c2];\nuf.link(c1, c2);\nint c3 = uf.find_set(c1);\nsizes[c3] = s1 + s2;\nif (--n_components == 1) break;\n}\nif (dis > s) break;\n}\nlong a = *std::max_element(sizes.begin(), sizes.end());\n\nstd::vector<long> sizes_q(n + m, 0);\nfor (int i = 0; i < m; i++){\nedges.push_back(edges_ext[i]);\nsizes_q[n + i] = 1;\n}\nstd::sort(edges.begin(), edges.end(),\n[](const Edge& e1, const Edge& e2) -> bool {\nreturn std::get<2>(e1) < std::get<2>(e2);\n});\nboost::disjoint_sets_with_storage<> uf_ext(n + m);\nn_components = n + m;\nK::FT q;\nfor (EdgeV::const_iterator e = edges.begin(); e != edges.end(); ++e) {\nint c1 = uf_ext.find_set(std::get<0>(*e));\nint c2 = uf_ext.find_set(std::get<1>(*e));\nif (c1 != c2) {\nint s1 = sizes_q[c1], s2 = sizes_q[c2];\nuf_ext.link(c1, c2);\nint c3 = uf_ext.find_set(c1);\nsizes_q[c3] = s1 + s2;\nif (sizes_q[c3] >= k){\nq = std::get<2>(*e);\nbreak;\n}\n}\n}\nstd::cout << a << ' ' << q << '\\n';\n}\n\nint main() {\nstd::ios_base::sync_with_stdio(false);\nstd::cout << std::setiosflags(std::ios::fixed) << std::setprecision(0);\nstd::size_t t;\nfor (std::cin >> t; t > 0; --t) solve();\n}",
    "link": "https://expert.ethz.ch/solve/SwnHxpCjxd8AoTWvE"
  },
  {
    "name": "DHL",
    "aka": "Two-sequence partition DP with paired moves and separable batch cost",
    "week": "Week 10",
    "methods": "Dynamic Programming, Prefix sum",
    "status": "Rewrite it",
    "problemModel": "You have two stacks A and B, each with n parcels (values given bottom→top). In each round you must take at least 1 from A and at least 1 from B, and both stacks must become empty in the same round.\nIf in a round you take ka parcels from the top of A (sum Sa) and kb parcels from the top of B (sum Sb), the round cost is:(Sa − ka) * (Sb − kb).\nGoal: minimize total cost over all rounds.",
    "solutionShort": "\n1. Precompute suffix prefix-sums (top-access in O(1))\n\nYou store cumulative sums from the top so that the sum of the next takeA parcels when remA remain is:\nsumA = prefA[remA - takeA] - prefA[remA] (same for B).\n\nThen (Sa−ka) and (Sb−kb) are computed in O(1).\n2. DP state\ndp[i][j] = minimum total cost to empty the stacks when i parcels remain in A and j remain in B (i,j measured from the top as “remaining”).\n\nAnswer is dp[n][n].\n3. Transitions (structural restriction)\n\nThe code only considers moves where one side takes exactly 1 parcel, and the other side takes any positive amount:\n• takeA = 1, takeB = 1..j−1\n• takeB = 1, takeA = 1..i−1\n\nUpdate:\ndp[i][j] = min( (costBatchA * costBatchB) + dp[i-takeA][j-takeB] )\nThis relies on the known property for this task: there exists an optimal schedule where every round takes 1 from at least one stack (so you don’t need to consider takeA≥2 AND takeB≥2 at the same time).\n1. Initialization\n\nYou prefill the “border” cases dp[1][x] and dp[x][1] by forcing the last round to empty both stacks together (because you must take from both each round, so you can’t leave one stack empty early). dp[0][0]=0.",
    "solution": "#include <iostream>\n#include <vector>\n#include <climits>\n\nint main(){\nstd::ios_base::sync_with_stdio(false);\n\nint t;\nstd::cin>>t;\nwhile(t--){\nint n;  //n = parcels\nstd::cin>>n;\n\n//Values are represented from the bottom, but it's necessary to take from the top\nstd::vector<int> values_A(n+1);\nfor(int i = 0; i < n; i++){\nint a;\nstd::cin>>a;\n\nvalues_A[i] = a;\n}\nvalues_A[n] = 0;  //Easier calculations later\n\nstd::vector<int> values_B(n+1);\nfor(int i = 0; i < n; i++){\nint b;\nstd::cin>>b;\n\nvalues_B[i] = b;\n}\nvalues_B[n] = 0;\n\n//In order to avoid doing sums for every iteration, the sums are already stored in the array\n//To get the boxes from i to j included, with i on the top of j (so i >= j), it's necessary to take\n//values[j] - values[i+1]\nfor(int i = n-1; i >= 0; i--){\nvalues_A[i] = values_A[i] + values_A[i+1];\nvalues_B[i] = values_B[i] + values_B[i+1];\n}\n\n//dp[i][j] contains the minimum value when there are still i boxes A and j boxes B\n//This means that the answer is dp[n][n], that is the case when all boxes are still present\nstd::vector<std::vector<long>> dp(n+1, std::vector<long>(n+1, LONG_MAX));\n\n//Initialise the DP table considering that it's necessary to get all the last boxes at the same time\nfor(int i = n-1; i >= 1; i--){\n//1 box A (boxes with index from 0 to 0), i boxes B (boxes with index from 0 to i-1)\n//There can be a maximum of n-1 box B remaining because, to reach the case where only one box\n//Remains in A, it was necessary to take at least one box from B\n//Remember that 0 is the last box at the bottom\nlong cost_A = values_A[0]-values_A[1]-1;\nlong cost_B = values_B[0]-values_B[i]-i;\n\ndp[1][i] = cost_A * cost_B;\n\n//1 box B (boxes with index from 0 to 0), i boxes A (boxes with index from 0 to i-1)\n//There can be a maximum of n-1 box A remaining because, to reach the case where only one box\n//Remains in B, it was necessary to take at least one box from A\n//Remember that 0 is the last box at the bottom\ncost_A = values_A[0]-values_A[i]-i;\ncost_B = values_B[0]-values_B[1]-1;\n\n//Using min to avoid problems in the case dp[1][1] where both cases want to set a value\ndp[i][1] = std::min(dp[i][1], cost_A * cost_B);\n}\n\n//No boxes remaining to take, no value\ndp[0][0] = 0;\n\nfor(int rem_A = 2; rem_A <= n; rem_A++){\nfor(int rem_B = 2; rem_B <= n; rem_B++){\nint take_A, take_B;\n\n//The best strategy considers only taking 1 box from a pile and any amount from the other\ntake_A = 1;\nfor(int take_B = 1; take_B < rem_B; take_B++){\nlong cost_A = values_A[rem_A-take_A]-values_A[rem_A]-take_A;\nlong cost_B = values_B[rem_B-take_B]-values_B[rem_B]-take_B;\n\ndp[rem_A][rem_B] = std::min(dp[rem_A][rem_B], cost_Acost_B + dp[rem_A-take_A][rem_B-take_B]);\n}\n\ntake_B = 1;\nfor(int take_A = 1; take_A < rem_A; take_A++){\nlong cost_A = values_A[rem_A-take_A]-values_A[rem_A]-take_A;\nlong cost_B = values_B[rem_B-take_B]-values_B[rem_B]-take_B;\n\ndp[rem_A][rem_B] = std::min(dp[rem_A][rem_B], cost_Acost_B + dp[rem_A-take_A][rem_B-take_B]);\n}\n}\n}\n\nstd::cout<<dp[n][n]<<\"\\n\";\n}\n}",
    "link": "https://expert.ethz.ch/solve/ph23TeYZ5yzWtPstg"
  },
  {
    "name": "Hong Kong",
    "aka": "Bottleneck reachability in a planar geometric dual graph (max–min path)",
    "week": "Week 10",
    "methods": "Delaunay triangulation",
    "status": "Learn&ShutUp",
    "problemModel": "Trees are disks of radius r in the plane. Each balloon starts at a point (x,y) with radius s. After inflation, the balloon is an open disk; it may move continuously without ever overlapping any tree disk (touching is allowed). A balloon is “successful” if it can be moved to some position where it has takeoff clearance: its center is at distance at least r+s from every tree. For each balloon, output y/n. Constraints are large: n up to 4e4, m up to 9e4, t up to 30.",
    "solutionShort": "\n1. Model the motion as moving the balloon center in “free space” of inflated obstacles\n\nFor a balloon of radius s, inflate every tree disk by r+s. Then the balloon center must stay outside all these inflated disks. A path to a valid takeoff spot exists iff the center can reach “far away” (infinity) through corridors that are wide enough, and the starting point is not already inside an inflated disk. \nthis (18)\n2. Build Delaunay triangulation on tree centers\n\nDelaunay gives the relevant “narrow passages”: the limiting corridors are always between neighboring trees in the triangulation.\n3. Build a dual graph on faces (plus an outside node 0)\n• Each finite face becomes a node; the outside is node 0.\n• Between adjacent faces across a Delaunay edge (u,v), add an undirected edge with weight dist(u,v)^2 (this represents corridor width squared between those two trees).\n• Also connect each finite face to node 0 with weight equal to the squared circumradius of that triangle (this represents how much clearance that face provides relative to “open space”).\n1. Compute, for every face, the best possible bottleneck clearance to reach outside\n\nRun a “widest path” search from node 0:\n• distances[f] = maximum over all paths from 0 to f of (minimum edge weight along the path)\n\nThis is exactly Dijkstra with a max-heap, and relaxation new = min(curr, edgeWeight).\n1. Answer each balloon query in O(log n)\n\nFor balloon center p and radius s:\n• Let R = r+s, compare squared values.\n• If nearest tree center is closer than R, balloon already intersects an inflated tree ⇒ n.\n• Otherwise locate the Delaunay face containing p. If that face’s stored bottleneck value is at least 4*R^2, then there is a path to outside through edges with length ≥ 2R (since corridor condition is dist(u,v) ≥ 2R) ⇒ y, else n.",
    "solution": "",
    "link": "https://expert.ethz.ch/solve/gZ88cQbMfExHN9nZF"
  },
  {
    "name": "Targaryen",
    "aka": "max matching with 2 layers",
    "week": "Week 10",
    "methods": "Dijkstra, Maximum matching",
    "status": "Completed",
    "problemModel": "N intersections and M roads of le, we need to count the max number of road to save.\n\na road is saved if i put a barricade from both starting and ending node.\nSo each node is an intersection, but at each normal intersection we can put MAX 1 barricade for all the roads.\nExcept for the plazas, where i can put 2.\n\nTo put a barricate ad a certain intersection we need to reach it from at least one of B special intersections within a distance d.",
    "solutionShort": "Dijkstra to find all reachable intersections (PAY ATTENTION TO THE ROADS → undirected weighted graph).\n\n",
    "solution": "",
    "link": "https://expert.ethz.ch/solve/ww7CHJrKgSAHNhzFA"
  },
  {
    "name": "Fleetrace",
    "aka": "Min-Cost Max-Flow with Bypass",
    "week": "Week 10",
    "methods": "MinCostMaxFlow",
    "status": "Rewrite it",
    "problemModel": "N boats, M sailors\n\nhow to match all or a subset of them so that we get the maximum excitement (the excitement of a pair boat/sailor is given with an edge bi,si,excitemet_i)",
    "solutionShort": "We need a way to skip connection to avoid the objective of max flow, because we prefer min cost\n\nso from each boat add an edge directly to the sink with the MAX cost so that it skips if using it’s worse than skipping it",
    "solution": "",
    "link": "https://expert.ethz.ch/solve/EdbGzSmXMQq4juvw7"
  },
  {
    "name": "Augean Stables",
    "aka": "Monotone parameter search over LP feasibility (bounded-variable LP)",
    "week": "Week 10",
    "methods": "Linear Programming, Sliding Window, Two Pointers",
    "status": "Completed",
    "problemModel": "There are n stalls. Stall i starts with filth fi and must end with filth ≤ ci. Hercules chooses three hole sizes h1,h2,h3 (real numbers in [0,1]). With redirected river flows a and p, the removed filth in stall i is:\nh1*(ki + a^2) + h2*(li + p^2) + h3*(mi + a*p)\nA stall is clean if removed filth ≥ fi − ci. Hercules can spend 0..24 whole hours digging each trench; each hour adds some flow increment, so a and p are prefix sums of 24 given integers. Find the minimum total hours (hoursA + hoursB) that makes all stalls clean; else print Impossible!. ",
    "solutionShort": "\n1. Precompute redirected flows as prefix sums\nwaterA[h] = sum_{i=1..h} ai, waterB[h] = sum_{i=1..h} pi for h=0..24. \nthis (16)\n2. For a fixed (workA, workB), build an LP feasibility test\n\nVariables: h1,h2,h3 ∈ [0,1].\n\nFor each stall i define updated coefficients:\n• k' = ki + a^2\n• l' = li + p^2\n• m' = mi + a*p\nCleanliness requirement:\nh1*k' + h2*l' + h3*m' ≥ fi − ci\nCGAL uses A x ≤ b, so you multiply by −1:\n−k' h1 − l' h2 − m' h3 ≤ ci − fi\nThat is exactly what your code sets:\n• coefficients (-k, -l, -m)\n• RHS (ci - fi)\n\nFeasible ⇔ all stalls can be cleaned with some hole sizes in [0,1].\n1. Search minimal hours using a monotone frontier (two pointers)\n\nStart at (workA=0, workB=24) and maintain:\n• If infeasible: increase workA (more A-water makes constraints easier because k′, m′ increase).\n• If feasible: try decreasing workB (less B-work reduces total hours; may break feasibility).\n\nTrack the minimum workA + workB found.\nThis works because you only move in one direction on each axis, so you visit O(25+25) states instead of all 625.",
    "solution": "#include <iostream>\n#include <vector>\n#include <algorithm>\n\n#include <CGAL/QP_models.h>\n#include <CGAL/QP_functions.h>\n#include <CGAL/Gmpz.h>\n\n// CRITICAL FIX: Use long long to handle values up to 2^50 (a^2)\n// 'int' overflows and causes TLE/Wrong Answer.\ntypedef long IT;\ntypedef CGAL::Gmpz ET;\n\ntypedef CGAL::Quadratic_program<IT> Program;\ntypedef CGAL::Quadratic_program_solution<ET> Solution;\n\nstruct stall_t {\nint f;\nint c;\nlong long k; // Use long long\nlong long l;\nlong long m;\n};\n\nvoid solve() {\nint n;\nif (!(std::cin >> n)) return;\n\nstd::vector<stall_t> stalls(n);\nfor(int i = 0; i < n; i++){\nint f, c;\nlong long k, l, m;\nstd::cin >> f >> c >> k >> l >> m;\nstalls[i] = {f, c, k, l, m};\n}\n\n// Cumulative water A\nstd::vector<long long> waterA(25, 0);\nfor(int i = 1; i < 25; i++){\nint a; std::cin >> a;\nwaterA[i] = waterA[i-1] + a;\n}\n\n// Cumulative water P\nstd::vector<long long> waterB(25, 0);\nfor(int i = 1; i < 25; i++){\nint b; std::cin >> b;\nwaterB[i] = waterB[i-1] + b;\n}\n\n// Constants for the LP variables\nconst int h1 = 0;\nconst int h2 = 1;\nconst int h3 = 2;\n\n// Initialize LP outside the loop to save allocation time\n// Variables h1, h2, h3 are in [0, 1]\nProgram lp(CGAL::SMALLER, true, 0, true, 1);\n\n// Pre-set the constant RHS (b) part of the constraints\n// Constraint: h1*... + h2*... + h3*... >= f - c\n// LP (SMALLER): -h1*... - h2*... - h3*... <= c - f\nfor(int i = 0; i < n; i++){\nlp.set_b(i, stalls[i].c - stalls[i].f);\n}\n\nint workA = 0;\nint workB = 24;\nint min_hours = -1; // -1 indicates impossible so far\n\n// \"Sliding Window\" / \"Two Pointer\" search\n// We start at (0, 24).\n// If feasible: try to reduce sum (workB--)\n// If infeasible: try to add resources (workA++)\nwhile(workA <= 24 && workB >= 0){\n\n// Optimization: If the current sum is already worse than or equal to\n// a known solution, we don't need to solve the LP. We just need to reduce cost.\nif(min_hours != -1 && workA + workB >= min_hours){\nworkB--;\ncontinue;\n}\n\nlong long a = waterA[workA];\nlong long p = waterB[workB];\nlong long a2 = a * a;\nlong long p2 = p * p;\nlong long ap = a * p;\n\n// Update only the coefficients (A matrix)\nfor(int i = 0; i < n; i++){\n// Calculate coefficients using long long to avoid overflow\nlong long k_coeff = stalls[i].k + a2;\nlong long l_coeff = stalls[i].l + p2;\nlong long m_coeff = stalls[i].m + ap;\n\n// Negate because we transformed >= to <=\nlp.set_a(h1, i, -k_coeff);\nlp.set_a(h2, i, -l_coeff);\nlp.set_a(h3, i, -m_coeff);\n}\n\nSolution s = CGAL::solve_linear_program(lp, ET());\n\nif(s.is_infeasible()){\n// Need more water -> increase workA\nworkA++;\n} else {\n// Feasible! Record solution and try to reduce workB\nmin_hours = workA + workB;\nworkB--;\n}\n}\n\nif(min_hours == -1){\nstd::cout << \"Impossible!\\n\";\n} else {\nstd::cout << min_hours << \"\\n\";\n}\n}\n\nint main(){\nstd::ios_base::sync_with_stdio(false);\nint t; std::cin >> t;\nwhile(t--){\nsolve();\n}\nreturn 0;\n}",
    "link": "https://expert.ethz.ch/solve/X8Mwp8XF8WCb67ZNB"
  },
  {
    "name": "Lions vs Hyenas",
    "aka": "Cut graph (MinCut)",
    "week": "Week 11",
    "methods": "Minimum Cut",
    "status": "Rewrite it",
    "problemModel": "N nodes, 2 groups.\n\neach node has an affinity to one of the groups (positive and negative).\nEach unordered pair of nodes has an affinity ≥ 0.\n\nTwo nodes in particular must be in 2 different groups.\n\nFind minimum dissatisfaction (you get dissatisfaction = affinity if you put a node in the opposite group or if you put two friends in opposite group)\n\nand finde max happines",
    "solutionShort": "Basically we need the MinCut (MaxFlow) from two groups.\n\nWe get dissatisfaction by removing edges with affinity, so we put only the edges that represent  a positive affinity, if we cut it we will sum to dissatisfaction.\n\nTo force one element in one group you connect to source/sink with max edge capacity.\n\nyou trie both combinations",
    "solution": "",
    "link": "https://expert.ethz.ch/solve/nYpBy99WMHGW86WDA"
  },
  {
    "name": "Asterix and the Chariot Race",
    "aka": "Minimum Weight Dominating Set on a tree",
    "week": "Week 11",
    "methods": "Dynamic Programming",
    "status": "Completed",
    "problemModel": "We have a tree ad we need to cover each node.\nYou cover a node is “repaired” of one of its neighbour is repaired.\n\nAt each node is assigned a cost for repairing.\n\nFind minimum cost",
    "solutionShort": "DP:\nbase case:\n- we have a leaf node, if the parent is repaired return 0, if not repaired return the cost[leaf], else if the parent needed one of the leaf child to repair it, return INFINITY\n\nthen, for each node we have 3 state:\n1. repair it\n2. you father is repaired\n3. at least one of your children need to repair itself\n\nSo, if you are in state 0, repair + let free choice to all children (take min of all 3 states)\n\nif state == 1,\nyou can either repair it and let children do anything\nelse NOT repair but children must repair or ask to their children\n\nif state == 2,\nlook for the best child to force to repair, for the others let them do what they want.\nHow to find the node to sacrifice?\nCheck how much they pay if they repair, and how much they pay if another children do their job.\n\nTake the one with the minimun difference.",
    "solution": "",
    "link": "https://expert.ethz.ch/solve/TvJRhGQsXzzuGdZxS"
  },
  {
    "name": "Return of the Jedi",
    "aka": "2nd MST",
    "week": "Week 11",
    "methods": "Minimum Spanning Tree",
    "status": "Rewrite it",
    "problemModel": "Compute 2nd MST",
    "solutionShort": "How?\nFor sure we need to add an edge not in the MST, and remove one edge from the MST to avoid adding a cycle.\nThe main idea is that, if we add a new edge (u,v), and remove any other edge on the UNIQUE path from u → v, we obtain again a tree.\nBut we want the 2nd MST so we remove the edge with the highest cost (local optimum).\n\nNow we do it for each other edge (global optimum).",
    "solution": "",
    "link": "https://expert.ethz.ch/solve/CeXm4CiLMgGQzyy5R"
  },
  {
    "name": "Sith",
    "aka": "Max size of a component in a graph with all indices ≥ x ",
    "week": "Week 11",
    "methods": "Binary Search, Delaunay triangulation, Union Find",
    "status": "Rewrite it",
    "problemModel": "You are given $N$ points in a 2D plane, indexed from $0$ to $N-1$.\nAt each time step $k$ (starting from $k=0$), the node with index $k$ is removed (or becomes \"infected/untouchable\"). Two nodes can be connected if their Euclidean distance is at most $R$.\nGoal: Find the maximum integer $k$ such that there exists a connected component of size at least $k$ consisting entirely of nodes with indices $\\ge k$.\n\nIn other words: How long can a group of size $k$ survive if nodes $0, 1, \\dots, k-1$ are destroyed?",
    "solutionShort": "The problem asks for the maximum $k$ satisfying a condition. Since the condition is monotonic (if a solution works for $k$, it definitely works for $k-1$ because the required size is smaller and more nodes are available), we can use Binary Search on the Answer.\n\nSo we do binary search on the max number to look for the max time after that one of our nodes get touched.\n\nso for each binarysearch step, we select only nodes with index ≥ mid and we find max size component via union find.\n\nThen if max size ≥ mid it means we can do better: avoid using the most left nodes so we can have more time to connect.\nso\nif(best ≥ mid) left = mid+1\nelse right = mid-1\n\n\nreturn left-1",
    "solution": "// ETH AlgoLab example code: Compute a Euclidean minimum spanning tree (EMST)\n// for n points p_0,...,p_{n-1} in O(n log n) time. Output the edges as ordered\n// pairs of vertex indices (smaller first) together with the squared length; for\n// instance, an edge between p_4=(0,0) and p_2=(1,2) is printed as \"2 4 5\".\n\n#include <CGAL/Exact_predicates_inexact_constructions_kernel.h>\n#include <CGAL/Delaunay_triangulation_2.h>\n#include <CGAL/Triangulation_vertex_base_with_info_2.h>\n#include <CGAL/Triangulation_face_base_2.h>\n#include <boost/pending/disjoint_sets.hpp>\n#include <vector>\n#include <tuple>\n#include <algorithm>\n#include <iostream>\n#include <bits/stdc++.h>\nusing namespace std;\n\n// Epic kernel is enough, no constructions needed, provided the squared distance\n// fits into a double (!)\ntypedef CGAL::Exact_predicates_inexact_constructions_kernel K;\n// we want to store an index with each vertex\ntypedef std::size_t                                            Index;\ntypedef CGAL::Triangulation_vertex_base_with_info_2<Index,K>   Vb;\ntypedef CGAL::Triangulation_face_base_2<K>                     Fb;\ntypedef CGAL::Triangulation_data_structure_2<Vb,Fb>            Tds;\ntypedef CGAL::Delaunay_triangulation_2<K,Tds>                  Delaunay;\n\n// As edges are not explicitly represented in the triangulation, we extract them\n// from the triangulation to be able to sort and process them. We store the\n// indices of the two endpoints, first the smaller, second the larger, and third\n// the squared length of the edge. The i-th entry, for i=0,... of a tuple t can\n// be accessed using std::get<i>(t).\ntypedef std::tuple<Index,Index,K::FT> Edge;\ntypedef std::vector<Edge> EdgeV;\n\n\n\nvoid compute_emst() {\nIndex n;\nstd::cin >> n;\nIndex r; cin >> r;\n\n// read points: first, we read all points and store them into a vector,\n// together with their indices\ntypedef std::pair<K::Point_2,Index> IPoint;\nstd::vector<IPoint> points;\npoints.reserve(n);\nfor (Index i = 0; i < n; ++i) {\nint x, y;\nstd::cin >> x >> y;\npoints.emplace_back(K::Point_2(x, y), i);\n}\n\n\nIndex left = 2, right = n/2;\nwhile(left <= right){\nIndex mid = left + (right-left)/2;\nDelaunay t;\nt.insert(points.begin()+mid, points.end());\n\nEdgeV edges;\nedges.reserve(3n); // there can be no more in a planar graph\nfor (auto e = t.finite_edges_begin(); e != t.finite_edges_end(); ++e) {\nIndex i1 = e->first->vertex((e->second+1)%3)->info();\nIndex i2 = e->first->vertex((e->second+2)%3)->info();\n// ensure smaller index comes first\nif (i1 > i2) std::swap(i1, i2);\nif(t.segment(e).squared_length() <= rr) edges.emplace_back(i1, i2, t.segment(e).squared_length());\n}\n\n\n// setup and initialize union-find data structure\nboost::disjoint_sets_with_storage<> uf(n);\nvector<Index> sizes(n,1);\nIndex curr_best = 0;\nfor (EdgeV::const_iterator e = edges.begin(); e != edges.end(); ++e) {\n// determine components of endpoints\nIndex c1 = uf.find_set(std::get<0>(*e));\nIndex c2 = uf.find_set(std::get<1>(*e));\nif (c1 != c2) {\nIndex old1 = sizes[c1], old2 = sizes[c2];\nuf.link(c1, c2);\nIndex c3 = uf.find_set(std::get<0>(*e));\nsizes[c3] = old1 + old2;\ncurr_best = max(curr_best, sizes[c3]);\n}\n}\n\nif(curr_best >= mid) {\nleft = mid + 1;\n}\nelse {\nright = mid - 1;\n}\n}\ncout << left-1 << \"\\n\";\n\n\n}\n\nint main()\n{\nstd::ios_base::sync_with_stdio(false);\nstd::size_t t;\nfor (std::cin >> t; t > 0; --t) compute_emst();\nreturn 0;\n}",
    "link": "https://expert.ethz.ch/solve/QGBqTJuHvwrD6PmeF"
  },
  {
    "name": "Legions",
    "aka": "LP of v = s/t",
    "week": "Week 11",
    "methods": "Linear Programming",
    "status": "Completed",
    "problemModel": "We have a point inside a convex hull defined by n lines.\n\neach line is moving pointing the dot each with different speed.\n\nFind the max time before one line reaches it",
    "solutionShort": "Simply equation of time\n\nthe variable time to maximize is less than the distance to any other line / speed of line",
    "solution": "",
    "link": "https://expert.ethz.ch/solve/CB3uJChdaXBc7PyPp"
  },
  {
    "name": "Alice and the Hurried Rabbit Clan",
    "aka": "Shortest path with cumulative cost",
    "week": "Week 12",
    "methods": "Dynamic Programming, Prefix sum",
    "status": "Rewrite it",
    "problemModel": "You are given an $N \\times M$ grid where each cell $(i, j)$ contains a number of rabbits, denoted as $r_{i,j}$1. Alice starts at $(0,0)$ and must reach the caterpillar at $(N-1, M-1)$ by moving only East (Right) or South (Down)2.+1\n\nThe rabbits also move only East or South. A rabbit at $(i, j)$ travels the minimum distance to reach any cell occupied by Alice's path3.\n\n\nGoal: Find a path $P$ for Alice that minimizes the total distance traveled by all rabbits in the grid4.",
    "solutionShort": "Instead of simulating individual rabbit paths, we calculate the \"penalty cost\" incurred by Alice's movements. We model this as finding the shortest path (minimum cost) on a DAG from $(0,0)$ to $(N-1, M-1)$.\nIf Alice is at cell $(i, j)$, she has two choices:\n1. Go Right ($j \\to j+1$):\n    ◦ Effect: Alice moves away horizontally.\n    ◦ Cost: All rabbits located in the Bottom-Left relative to Alice (Rows $i+1 \\dots N-1$, Columns $0 \\dots j$) must now travel at least one extra step East to intercept the path later.\n    ◦ Calculation: Sum of rabbits in the rectangle defined by top-left $(i+1, 0)$ and bottom-right $(N-1, j)$.\n2. Go Down ($i \\to i+1$):\n    ◦ Effect: Alice moves away vertically.\n    ◦ Cost: All rabbits located in the Top-Right relative to Alice (Rows $0 \\dots i$, Columns $j+1 \\dots M-1$) are left \"waiting\" above. They must travel extra distance to catch the path as it descends.\n    ◦ Calculation: Sum of rabbits in the rectangle defined by top-left $(0, j+1)$ and bottom-right $(i, M-1)$.\nAlgorithm:\n• Precomputation: Build a 2D Prefix Sum array to calculate the rectangular sums in $O(1)$ time.\n• Dynamic Programming:\nLet $DP[i][j]$ be the minimum cost to reach $(N-1, M-1)$ from $(i, j)$.\n$$DP[i][j] = \\min \\begin{cases} DP[i][j+1] + \\text{Sum}(\\text{Bottom-Left}) & (\\text{Right Move}) \\\\ DP[i+1][j] + \\text{Sum}(\\text{Top-Right}) & (\\text{Down Move}) \\end{cases}$$\n• Result: The value at $DP[0][0]$.",
    "solution": "",
    "link": "https://expert.ethz.ch/solve/nDExBRMeNFhbyZNac"
  },
  {
    "name": "Harry Potter",
    "aka": "",
    "week": "Week 12",
    "methods": "Binary Search, Linear Programming",
    "status": "Rewrite it",
    "problemModel": "Harry Potter must deliver a truth potion to Slughorn ($p_1$) from himself ($p_2$) via a network of friends ($p_3 \\dots p_n$)1.\n\n• \nFlow: Transfers ($i \\to j$) have efficiency $e_{ij}$ (loss of volume) and generate suspicion $d_{ij}$ per unit2.\n\n• Constraints: Harry starts with $a$ units; Slughorn needs $\\ge b$ units; total suspicion of all transfers must be $\\le c$3.\n\n• Goal:\n    1. Find the smallest index $k$ (subset of friends $p_1 \\dots p_k$) that makes the delivery possible4.\n\n    2. For that $k$, minimize the maximum suspicion $s$ generated by any single link5.",
    "solutionShort": "This is a Linear Programming (LP) problem.\n1. Find Min $k$: Iterate or binary search $k$ ($2 \\to n$). Construct an LP using only nodes $1 \\dots k$ with flow conservation, efficiency losses, and the total suspicion constraint ($\\sum d_{ij}x_{ij} \\le c$). The first feasible $k$ is the answer.\n2. Find Min $s$: Fix $k$. Add constraints $d_{ij} x_{ij} \\le S$ for every edge. Set the objective to Minimize $S$.\n3. \nOutput: If infeasible for all $k$, output \"Busted!\"6. Otherwise, print $k$ and $\\lceil S \\rceil$ using exact arithmetic types7.",
    "solution": "",
    "link": "https://expert.ethz.ch/solve/Z73T7urzu99sZZQ2t"
  },
  {
    "name": "Evolution",
    "aka": "Binary Lifting",
    "week": "Week 12",
    "methods": "Binary Lifting",
    "status": "Rewrite it",
    "problemModel": "We have a tree with n nodes, each node represent a specie with a string name and age.\n\nYou are given n-1 connection specie → direct ancestor.\n\nAnswer to q queries: given a name of a specie and an age, find the highest ancestor with age ≤ age_given",
    "solutionShort": "Binary Lifting",
    "solution": "",
    "link": "https://expert.ethz.ch/solve/NmivTM3xmEv4cxHjG"
  },
  {
    "name": "Marathon",
    "aka": "MaxFlow in ONLY all shortest path of a graph",
    "week": "Week 12",
    "methods": "Dijkstra, MaxFlow",
    "status": "Completed",
    "problemModel": "We have n nodes and m undirected streets, one node represent the start of the race and another the end.\n\nEach street has a max capacity and a length.\n\nFind the max number of runners that can join the race by running only in a shortest path of the graph.",
    "solutionShort": "Basically we would like to do max flow but we need to discard the streets not in a shortest path.\n\nSo how to know if a street is in a shortest path?\nIf dist_from_start(u) + length(u,b) + distace_from_end(v) == LEGTH_SHORTEST_PATH.\n\nBut be careful: dist_from_start(u) ≤ dist_from_start(v), so swap them if not.",
    "solution": "",
    "link": "https://expert.ethz.ch/solve/Rx5ixdhmDAtKsX7v9"
  },
  {
    "name": "The Stymphalian Birds",
    "aka": "Scheduling tasks with deadlines respecting a tree order",
    "week": "Week 12",
    "methods": "Constraint Propagation, Greedy",
    "status": "Completed",
    "problemModel": "We have $n$ birds ($b_0 \\dots b_{n-1}$), each with a specific deadline $t_i$ before they attack2222.\nThey form a hierarchical formation where bird $b_i$ is physically behind $b_{2i+1}$ and $b_{2i+2}$, meaning the two \"children\" must be shot before the \"parent\" $b_i$3.\nHercules shoots 1 bird per second4. Can he clear them all in time? | This is a Single Machine Scheduling problem with precedence constraints.",
    "solutionShort": "We can encode the dependencies ($children \\to parent$) into the deadlines: a child must be shot at least 1 second before its parent.\n1. Propagate Deadlines: Iterate from $0$ to $n$ (top-down). Update $t_{child} = \\min(t_{child}, t_{parent} - 1)$.\n2. Greedy (EDF): Sort all birds by their new deadlines. Check if the $i$-th bird in the sorted list satisfies $i < t_{new}$ (strictly before deadline).",
    "solution": "",
    "link": "https://expert.ethz.ch/solve/Q69M3M2YSnWJP3Kfv"
  },
  {
    "name": "Surveillance Photograph",
    "aka": "Maximum flow on a directed graph with node-splitting (2-layer graph)",
    "week": "Week 13",
    "methods": "2-layer Graph, MaxFlow",
    "status": "Completed",
    "problemModel": "You have a directed road network with n intersections and m one-way streets. There are k police stations (each provides one policeman + one safe) and ℓ photographs at intersections (multiple can be at the same intersection).\nEach policeman can collect at most one photograph: travel from a station to a photo location (empty-handed), then travel (carrying the photo) to some station to store it.\nSecurity rule: each street can be used by at most one policeman while carrying a photograph, but streets can be reused arbitrarily by policemen who are not carrying a photo.\nGoal: compute the maximum number of photographs that can be safely collected.",
    "solutionShort": "The code models this as a max-flow problem using node-splitting:\n• Build a flow graph with 2 copies of each intersection: u_in = u, u_out = u+n.\n• Add a super source S and sink T.\n• For each police-station location x (k entries, duplicates allowed):\n    ◦ Add S -> x_in capacity 1 (each policeman can start once).\n    ◦ Add x_out -> T capacity 1 (each safe can store one photo).\n• For each photograph location x (ℓ entries, duplicates allowed):\n    ◦ Add x_in -> x_out capacity 1 (at most one collected photo can “pass through” that photo token).\n• For each street x -> y:\n    ◦ Add x_in -> y_in capacity (k+ℓ) (moving without a photo: effectively unlimited).\n    ◦ Add x_out -> y_out capacity 1 (moving while carrying a photo: limited to one, enforcing the security rule).\nThen it runs push_relabel_max_flow(G, S, T).\n\nEach unit of flow corresponds to one policeman successfully routing:\nS -> (start station)_in -> ... -> (photo)_in -> (photo)_out -> ... -> (end station)_out -> T\n\nThe max flow value is exactly the maximum number of photos that can be collected under the constraints.",
    "solution": "",
    "link": "https://expert.ethz.ch/solve/MAvJkfxkq23FRBYND"
  },
  {
    "name": "Queen of Hearts",
    "aka": "MinCut with node capacity",
    "week": "Week 13",
    "methods": "Dijkstra, Minimum Cut, NodeCapacity",
    "status": "Completed",
    "problemModel": "Remove (steal) the fewest carrots (and on grumpy days pay the fewest rabbits) so the Queen cannot traverse the garden from entrance (0) to exit (r+1), given that every additional path step after the first requires eating one carrot available at rabbit openings.",
    "solutionShort": "For each rabbit compute deliverable carrots res = c_i − dist(0, n_i−1) via Dijkstra on its burrow, build a node-split flow network with split-edge capacity res (or 1 for coin mode) and infinite-capacity garden arcs, then output the min-cut value via push_relabel_max_flow (twice if d=1).",
    "solution": "",
    "link": "https://expert.ethz.ch/solve/sa79JHPf7Mjc4BntP"
  },
  {
    "name": "Rapunzel",
    "aka": "Return all nodes in a tree where starts a branch of size m with max(branch) - min(branch) ≤ k",
    "week": "Week 13",
    "methods": "Backtracking, Tree Traversal",
    "status": "Completed",
    "problemModel": "You are given a rooted directed tree (hair ties), where for every node u there is exactly one path (rope) from the root 0 to u. Each node i has a brightness value hᵢ. For a fixed length m, you must find all start nodes s such that the path segment of length m starting at s (i.e., m consecutive nodes on some root→leaf path) has contrast ≤ k, where contrast is max(h) − min(h) over those m nodes. If none exist, print “Abort mission”.",
    "solutionShort": "The code runs a DFS from the root while maintaining the current root→node path in a stack. Along this path it keeps a multiset of brightness values for the last m nodes (a sliding window).\nAt each visited node:\n• Insert its brightness into the multiset and push the node onto the path stack.\n• Once the path length reaches m, compute min and max from the multiset in O(1) (begin/rbegin).\n• The window corresponds to the last m nodes; the start of that length-m segment is the node at index path_size - m. If max - min ≤ k, that start node is added to the answer set.\n• Then it “slides” the window by temporarily removing the start node’s brightness before going deeper, and restores it when backtracking.",
    "solution": "#include <bits/stdc++.h>\nusing namespace std;\n\nint m, k;\nvoid dfs(const vector<vector<int>>& tree,\nconst vector<int>& br, int u,\nmultiset<int>& ms,\nvector<int>& vStack,\nset<int>& res){\nvStack.push_back(u);\nms.insert(br[u]);\n//cout << \"in node: \"<<u<<\"\\n\";\nint removed_elem = -1;\nif(int(ms.size()) == m){\nint min_val = *ms.begin();\nint max_val = *ms.rbegin();\n//cout <<min_val <<\" - \"<<max_val<<\"\\n\";\nint first_node = vStack[vStack.size()-m];\n//cout << \"first_node: \"<<first_node<<\"\\n\";\nif(max_val - min_val <= k) res.insert(first_node);\nms.erase(ms.find(br[first_node]));\nremoved_elem = br[first_node];\n}\nfor(int v: tree[u]){\ndfs(tree, br, v, ms, vStack, res);\n}\nif(removed_elem != -1) ms.insert(removed_elem);\nms.erase(ms.find(br[u]));\nvStack.pop_back();\n}\n\nvoid solve(){\nint n;\ncin >> n >> m >> k;\nvector<int> br(n);\nfor(int i = 0; i < n; ++i){\ncin >> br[i];\n}\nvector<vector<int>> tree(n);\nfor(int i = 0; i < n-1; ++i){\nint u, v; cin >> u >> v;\ntree[u].push_back(v);\n}\nmultiset<int> ms;\nvector<int> vStack;\nset<int> res;\ndfs(tree, br, 0, ms, vStack, res);\nfor(int num: res) cout << num << \" \";\nif((int)res.size() == 0) cout << \"Abort mission\";\n}\n\nint main(){\nios_base::sync_with_stdio(false);\nint t; cin >> t;\nwhile(t--){\nsolve(); cout << \"\\n\";\n}\nif(cin >> t) cout << \"j<nci\\n\";\n}",
    "link": "https://expert.ethz.ch/solve/aScTGF8THFXDPZ86o"
  },
  {
    "name": "Croquet",
    "aka": "Hop-limited reachability in a unit-disk graph using proximity structure",
    "week": "Week 13",
    "methods": "Delaunay triangulation",
    "status": "Learn&ShutUp",
    "problemModel": "There are n safe locations (points), and the last one is the target t. A shot can move the ball by distance at most d (q = d^2). Alice may start from any of m starting points (not necessarily safe for the first placement), but after that every landing point must be a safe location. For each start point s_i, decide if Alice can reach t in at most k shots. \n",
    "solutionShort": "\n1. Build Delaunay triangulation of the safe points\n\nThis gives a sparse proximity structure to search neighbors and (in one regime) to preserve connectivity.\n2. Mark which safe points can reach the target within the allowed hops\n\nA safe-to-safe shot is allowed if squared distance ≤ q.\n• Regime A: k ≥ n (hop limit effectively irrelevant)\n\nIf you can take at least n shots, then “reachable within k shots” collapses to “in the same connected component as t” (you can’t need more than n−1 hops on a connected n-vertex graph if you allow revisits).\n\nYour code builds a graph using only Delaunay edges with length² ≤ q, and marks all vertices connected to t as reachable.\n• Regime B: k < n (hop-limited)\n\nYou run a BFS from t over the implicit UDG, stopping expansion once distance (in hops) reaches k−1 (because the first shot is from the start point to some safe location).\n\nFor expanding a node u, you try to discover all safe points v with dist²(u,v) ≤ q by doing a local traversal over Delaunay adjacency starting from u’s vertex handle, only continuing locally through vertices that are within radius d from u.\n1. Answer each query start point s_i\n\nIf there exists any reachable safe point within distance d of the start point, then s_i is “y”, else “n”. You build a second triangulation containing only reachable safe points and do a nearest-neighbor query; if nearest reachable point is within d, print “y”.",
    "solution": "",
    "link": "https://expert.ethz.ch/solve/gtPibhk3aRkzxbuMR"
  },
  {
    "name": "The Empire Strikes Back",
    "aka": "Distributing radiation intensity from constrained sources to targets while respecting proximity limits",
    "week": "Week 13",
    "methods": "Delaunay triangulation, Linear Programming",
    "status": "Rewrite it",
    "problemModel": "You have 'a' radioactive particles (sources) with limited capacity and 's' shooting points (targets) that require radiation. There are also 'n' healthy cells (obstacles). Radiation intensity decays with the inverse squared distance. A particle can only irradiate a target if the target is closer to that particle than to any healthy cell. We need to determine if it is possible to power the targets.",
    "solutionShort": "1. Visibility Check (Delaunay): Construct a Delaunay Triangulation of the 'n' healthy cells. For each shooting point, find the distance to the nearest healthy cell. A particle only contributes to a shooting point if the distance between them is smaller than this \"nearest healthy cell\" distance.\n2. Linear Program (LP): Formulate the flow constraints.\n• Variables: Intensity output for each particle.\n• Constraints: Sum of (Intensity / distance^2) for valid pairs must meet demand; Individual particle intensity <= capacity.\n• Solve using an exact LP solver (Rational arithmetic) to handle the precision of inverse squared distances correctly.",
    "solution": "",
    "link": "https://expert.ethz.ch/solve/7wDAGGyqGpkfH32ne"
  },
  {
    "name": "Rumpelstitskin",
    "aka": "2source → Single-flow pairing via reversed right source",
    "week": "Week 14",
    "methods": "Flow Conservation, MaxFlow",
    "status": "Rewrite it",
    "problemModel": "There are two independent supplies (West/Wheat and East/Barley) that must be paired 1-to-1 at islands to produce gold; each island can be used at most once and has a score, and the goal is to maximize the number of gold units and, among those, the total score.",
    "solutionShort": "We have a problem with the flow conservation, because we have 2 flows combined in 1 sink that count 1+1 → 1.\n\nTransform the two-source problem into a single-source–single-sink flow by reversing the East network so its supply becomes demand; route flow asSource → West → Islands → East (reversed) → Sink, where flow conservation enforces the 1-to-1 pairing, island capacity-1 edges limit usage, and min-cost max-flow with cost (BIG − score) selects the highest-score islands while maximizing flow.",
    "solution": "",
    "link": "https://expert.ethz.ch/solve/zFi8hdy7t2oLaGFke"
  },
  {
    "name": "James Bond's sovereign",
    "aka": "",
    "week": "",
    "methods": "",
    "status": "Not Started",
    "problemModel": "",
    "solutionShort": "",
    "solution": "",
    "link": "https://github.com/tommasocerruti/algolab-2024/blob/main/src/week03/james_bonds_sovereign"
  },
  {
    "name": "Nemean Lion",
    "aka": "",
    "week": "",
    "methods": "",
    "status": "Not Started",
    "problemModel": "",
    "solutionShort": "",
    "solution": "",
    "link": "https://github.com/tommasocerruti/algolab-2024/blob/main/src/week12/nemean_lion"
  },
  {
    "name": "Alastor Moody",
    "aka": "",
    "week": "",
    "methods": "",
    "status": "Not Started",
    "problemModel": "",
    "solutionShort": "",
    "solution": "",
    "link": "https://github.com/tommasocerruti/algolab-2024/blob/main/src/week12/alastor_moody"
  },
  {
    "name": "Hermione Granger",
    "aka": "",
    "week": "",
    "methods": "",
    "status": "Not Started",
    "problemModel": "",
    "solutionShort": "",
    "solution": "",
    "link": "https://github.com/tommasocerruti/algolab-2024/blob/main/src/week10/hermione_granger"
  },
  {
    "name": "Pied Piper",
    "aka": "",
    "week": "",
    "methods": "",
    "status": "Not Started",
    "problemModel": "",
    "solutionShort": "",
    "solution": "",
    "link": "https://github.com/tommasocerruti/algolab-2024/blob/main/src/week12/pied_piper"
  },
  {
    "name": "Lernaean Hydra",
    "aka": "",
    "week": "",
    "methods": "",
    "status": "Not Started",
    "problemModel": "",
    "solutionShort": "",
    "solution": "",
    "link": "https://github.com/tommasocerruti/algolab-2024/blob/main/src/week11/lernaean_hydra"
  },
  {
    "name": "Schneewittchen",
    "aka": "",
    "week": "",
    "methods": "",
    "status": "Not Started",
    "problemModel": "",
    "solutionShort": "",
    "solution": "",
    "link": "https://github.com/tommasocerruti/algolab-2024/blob/main/src/week13/schneewittchen"
  },
  {
    "name": "Ceryneian Hind",
    "aka": "",
    "week": "",
    "methods": "",
    "status": "Not Started",
    "problemModel": "",
    "solutionShort": "",
    "solution": "",
    "link": "https://github.com/tommasocerruti/algolab-2024/blob/main/src/week11/ceryneian_hind"
  },
  {
    "name": "Hand",
    "aka": "",
    "week": "",
    "methods": "",
    "status": "Not Started",
    "problemModel": "",
    "solutionShort": "",
    "solution": "",
    "link": "https://github.com/simon-hrabec/Algolab2020/tree/main/problems/Week%2011%20-%20Hand"
  },
  {
    "name": "Surveillance Photograph",
    "aka": "",
    "week": "",
    "methods": "",
    "status": "Not Started",
    "problemModel": "",
    "solutionShort": "",
    "solution": "",
    "link": "https://github.com/simon-hrabec/Algolab2020/tree/main/problems/Week%2008%20PotW%20-%20Surveillance%20Photograph"
  },
  {
    "name": "What is the Maximum",
    "aka": "",
    "week": "",
    "methods": "",
    "status": "Not Started",
    "problemModel": "",
    "solutionShort": "",
    "solution": "",
    "link": "https://github.com/simon-hrabec/Algolab2020/tree/main/problems/Week%2007%20-%20What%20is%20the%20Maximum"
  },
  {
    "name": "Build the sum",
    "aka": "",
    "week": "",
    "methods": "",
    "status": "Not Started",
    "problemModel": "",
    "solutionShort": "",
    "solution": "",
    "link": "https://github.com/haeggee/algolab/blob/main/problems/week01-build_the_sum"
  },
  {
    "name": "Defensive Line",
    "aka": "",
    "week": "",
    "methods": "",
    "status": "Not Started",
    "problemModel": "",
    "solutionShort": "",
    "solution": "",
    "link": "https://github.com/haeggee/algolab/blob/main/problems/week02-defensive_line"
  },
  {
    "name": "Tracking",
    "aka": "",
    "week": "",
    "methods": "",
    "status": "Not Started",
    "problemModel": "",
    "solutionShort": "",
    "solution": "",
    "link": "https://github.com/simon-hrabec/Algolab2020/tree/main/problems/Week%2006%20PotW%20-%20Tracking"
  },
  {
    "name": "Radiation",
    "aka": "",
    "week": "",
    "methods": "",
    "status": "Not Started",
    "problemModel": "",
    "solutionShort": "",
    "solution": "",
    "link": "https://github.com/simon-hrabec/Algolab2020/tree/main/problems/Week%2007%20-%20Radiation"
  },
  {
    "name": "GoldenEye",
    "aka": "",
    "week": "",
    "methods": "",
    "status": "Not Started",
    "problemModel": "",
    "solutionShort": "",
    "solution": "",
    "link": "https://github.com/haeggee/algolab/blob/main/problems/week10-potw-goldeneye"
  },
  {
    "name": "Bonus Level",
    "aka": "",
    "week": "",
    "methods": "",
    "status": "Not Started",
    "problemModel": "",
    "solutionShort": "",
    "solution": "",
    "link": "https://github.com/haeggee/algolab/blob/main/problems/week12-bonus_level"
  },
  {
    "name": "The Great Game",
    "aka": "",
    "week": "",
    "methods": "",
    "status": "Not Started",
    "problemModel": "",
    "solutionShort": "",
    "solution": "",
    "link": "https://github.com/haeggee/algolab/blob/main/problems/week02-the_great_game"
  },
  {
    "name": "Deck of Cards",
    "aka": "",
    "week": "",
    "methods": "",
    "status": "Not Started",
    "problemModel": "",
    "solutionShort": "",
    "solution": "",
    "link": "https://github.com/haeggee/algolab/blob/main/problems/week02-potw-deck_of_cards"
  },
  {
    "name": "The Iron Islands",
    "aka": "",
    "week": "",
    "methods": "",
    "status": "Not Started",
    "problemModel": "",
    "solutionShort": "",
    "solution": "",
    "link": "https://github.com/haeggee/algolab/blob/main/problems/week11-the_iron_islands"
  },
  {
    "name": "From Russia with Love",
    "aka": "",
    "week": "",
    "methods": "",
    "status": "Not Started",
    "problemModel": "",
    "solutionShort": "",
    "solution": "",
    "link": "https://github.com/haeggee/algolab/blob/main/problems/week03-potw-from_russia_with_love"
  },
  {
    "name": "Beach Bars",
    "aka": "",
    "week": "",
    "methods": "",
    "status": "Not Started",
    "problemModel": "",
    "solutionShort": "",
    "solution": "",
    "link": "https://github.com/haeggee/algolab/blob/main/problems/week02-beach_bars"
  },
  {
    "name": "India",
    "aka": "",
    "week": "",
    "methods": "",
    "status": "Not Started",
    "problemModel": "",
    "solutionShort": "",
    "solution": "",
    "link": "https://github.com/haeggee/algolab/blob/main/problems/week14-potw-india"
  },
  {
    "name": "Lannister",
    "aka": "",
    "week": "",
    "methods": "",
    "status": "Not Started",
    "problemModel": "",
    "solutionShort": "",
    "solution": "",
    "link": "https://github.com/haeggee/algolab/blob/main/problems/week06-lannister"
  },
  {
    "name": "Phantom Menace",
    "aka": "",
    "week": "",
    "methods": "",
    "status": "Not Started",
    "problemModel": "",
    "solutionShort": "",
    "solution": "",
    "link": "https://github.com/haeggee/algolab/blob/main/problems/week11-potw-phantom_menace"
  },
  {
    "name": "Strikesback",
    "aka": "",
    "week": "",
    "methods": "",
    "status": "Not Started",
    "problemModel": "",
    "solutionShort": "",
    "solution": "",
    "link": "https://github.com/jlscheerer/AlgoLab2022/blob/main/statements/week13/strikesback.pdf"
  },
  {
    "name": "Ludo Bagman",
    "aka": "",
    "week": "",
    "methods": "",
    "status": "Not Started",
    "problemModel": "",
    "solutionShort": "",
    "solution": "",
    "link": "https://github.com/jlscheerer/AlgoLab2022/blob/main/statements/week14/ludo_bagman.pdf"
  },
  {
    "name": "Rubeus Hagrid",
    "aka": "",
    "week": "",
    "methods": "",
    "status": "Not Started",
    "problemModel": "",
    "solutionShort": "",
    "solution": "",
    "link": "https://github.com/jlscheerer/AlgoLab2022/blob/main/statements/week12/rubeus_hagrid.pdf"
  },
  {
    "name": "Nemean Lion",
    "aka": "",
    "week": "",
    "methods": "",
    "status": "Not Started",
    "problemModel": "",
    "solutionShort": "",
    "solution": "",
    "link": "https://github.com/jlscheerer/AlgoLab2022/blob/main/statements/week12/nemean_lion.pdf"
  },
  {
    "name": "Marathon",
    "aka": "",
    "week": "",
    "methods": "",
    "status": "Not Started",
    "problemModel": "",
    "solutionShort": "",
    "solution": "",
    "link": "https://github.com/jlscheerer/AlgoLab2022/blob/main/statements/week13/marathon.pdf"
  },
  {
    "name": "Worldcup",
    "aka": "",
    "week": "",
    "methods": "",
    "status": "Not Started",
    "problemModel": "",
    "solutionShort": "",
    "solution": "",
    "link": "https://github.com/jlscheerer/AlgoLab2022/blob/main/statements/week11/worldcup.pdf"
  },
  {
    "name": "Car Sharing",
    "aka": "",
    "week": "",
    "methods": "",
    "status": "Not Started",
    "problemModel": "",
    "solutionShort": "",
    "solution": "",
    "link": "https://github.com/jlscheerer/AlgoLab2022/blob/main/statements/week12/car_sharing.pdf"
  },
  {
    "name": "Punch",
    "aka": "",
    "week": "",
    "methods": "",
    "status": "Not Started",
    "problemModel": "",
    "solutionShort": "",
    "solution": "",
    "link": "https://github.com/haeggee/algolab/blob/main/problems/week13-punch"
  },
  {
    "name": "On Her Majesty's Secret Service",
    "aka": "",
    "week": "",
    "methods": "",
    "status": "Not Started",
    "problemModel": "",
    "solutionShort": "",
    "solution": "",
    "link": "https://github.com/jlscheerer/AlgoLab2022/blob/main/statements/week12/majestys_service.pdf"
  },
  {
    "name": "Hagrid",
    "aka": "",
    "week": "",
    "methods": "",
    "status": "Not Started",
    "problemModel": "",
    "solutionShort": "",
    "solution": "",
    "link": "https://github.com/haeggee/algolab/blob/main/problems/week13-hagrid"
  },
  {
    "name": "Suez",
    "aka": "",
    "week": "",
    "methods": "",
    "status": "Not Started",
    "problemModel": "",
    "solutionShort": "",
    "solution": "",
    "link": "https://github.com/jlscheerer/AlgoLab2022/blob/main/statements/week06/suez.pdf"
  },
  {
    "name": "The Hand's Tourney",
    "aka": "",
    "week": "",
    "methods": "",
    "status": "Not Started",
    "problemModel": "",
    "solutionShort": "",
    "solution": "",
    "link": "https://github.com/jlscheerer/AlgoLab2022/blob/main/statements/week10/hand.pdf"
  },
  {
    "name": "New York",
    "aka": "",
    "week": "",
    "methods": "",
    "status": "Not Started",
    "problemModel": "",
    "solutionShort": "",
    "solution": "",
    "link": "https://github.com/jlscheerer/AlgoLab2022/blob/main/statements/week10/new_york.pdf"
  },
  {
    "name": "Light the Stage",
    "aka": "",
    "week": "",
    "methods": "",
    "status": "Not Started",
    "problemModel": "",
    "solutionShort": "",
    "solution": "",
    "link": "https://github.com/jlscheerer/AlgoLab2022/blob/main/statements/week08/light_the_stage.pdf"
  },
  {
    "name": "Extra Exercise: New Tiles",
    "aka": "",
    "week": "",
    "methods": "",
    "status": "Not Started",
    "problemModel": "",
    "solutionShort": "",
    "solution": "",
    "link": "https://github.com/jlscheerer/AlgoLab2022/blob/main/statements/week10/new_tiles.pdf"
  },
  {
    "name": "Asterix in Switzerland",
    "aka": "",
    "week": "",
    "methods": "",
    "status": "Not Started",
    "problemModel": "",
    "solutionShort": "",
    "solution": "",
    "link": "https://github.com/jlscheerer/AlgoLab2022/blob/main/statements/week11/asterix_in_switzerland.pdf"
  },
  {
    "name": "Shopping Trip",
    "aka": "",
    "week": "",
    "methods": "",
    "status": "Not Started",
    "problemModel": "",
    "solutionShort": "",
    "solution": "",
    "link": "https://github.com/jlscheerer/AlgoLab2022/blob/main/statements/week07/shopping_trip.pdf"
  },
  {
    "name": "Octopussy",
    "aka": "",
    "week": "",
    "methods": "",
    "status": "Not Started",
    "problemModel": "",
    "solutionShort": "",
    "solution": "",
    "link": "https://github.com/jlscheerer/AlgoLab2022/blob/main/statements/week07/octopussy.pdf"
  },
  {
    "name": "Ceryneian Hind",
    "aka": "",
    "week": "",
    "methods": "",
    "status": "Not Started",
    "problemModel": "",
    "solutionShort": "",
    "solution": "",
    "link": "https://github.com/jlscheerer/AlgoLab2022/blob/main/statements/week11/ceryneian_hind.pdf"
  },
  {
    "name": "Casino Royale",
    "aka": "",
    "week": "",
    "methods": "",
    "status": "Not Started",
    "problemModel": "",
    "solutionShort": "",
    "solution": "",
    "link": "https://github.com/jlscheerer/AlgoLab2022/blob/main/statements/week09/casino_royale.pdf"
  },
  {
    "name": "Deck of cards",
    "aka": "",
    "week": "",
    "methods": "",
    "status": "Not Started",
    "problemModel": "",
    "solutionShort": "",
    "solution": "",
    "link": "https://github.com/jlscheerer/AlgoLab2022/blob/main/statements/week02/deck_of_cards.pdf"
  },
  {
    "name": "The Great Game",
    "aka": "",
    "week": "",
    "methods": "",
    "status": "Not Started",
    "problemModel": "",
    "solutionShort": "",
    "solution": "",
    "link": "https://github.com/jlscheerer/AlgoLab2022/blob/main/statements/week02/the_great_game.pdf"
  },
  {
    "name": "Defensive Line",
    "aka": "“Lord Voldemort” → max sum of length of non-overlapping subarrays with each subarray having a sum of exactly K.",
    "week": "",
    "methods": "",
    "status": "Not Started",
    "problemModel": "",
    "solutionShort": "",
    "solution": "",
    "link": "https://github.com/giacomocamposampiero/algolab/tree/main/problems/defensive-line"
  },
  {
    "name": "Beach Bars",
    "aka": "",
    "week": "",
    "methods": "",
    "status": "Not Started",
    "problemModel": "",
    "solutionShort": "",
    "solution": "",
    "link": "https://github.com/jlscheerer/AlgoLab2022/blob/main/statements/week02/beach_bars.pdf"
  }
];
